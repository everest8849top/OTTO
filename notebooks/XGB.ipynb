{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About :** Trains XGBoost models.\n",
    "\n",
    "**TODO**:\n",
    "- better neg sampling technique ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/kaggle_otto_rs/src\n"
     ]
    }
   ],
   "source": [
    "cd ../src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import cudf\n",
    "import json\n",
    "import glob\n",
    "import numba\n",
    "import xgboost\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from data.fe import load_sessions\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from params import *\n",
    "\n",
    "from data.candidates import load_parquets\n",
    "from model_zoo import TRAIN_FCTS\n",
    "\n",
    "from utils.metrics import get_coverage\n",
    "from utils.plot import plot_importances\n",
    "from utils.load import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = \"v2.3\"\n",
    "# VERSION = \"v2.4\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "POS_RATIO = 0.1\n",
    "TARGET = \"gt_orders\"   # \"gt_clicks\", \"gt_carts\", \"gt_orders\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = load_parquets_cudf(\n",
    "    f\"../output/features/fts_train_{VERSION}/*\",\n",
    "    pos_ratio=POS_RATIO,\n",
    "    target=TARGET\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols = ['clicks_popularity', 'carts_popularity', 'orders_popularity', 'clicks_popularity_w', 'carts_popularity_w', 'orders_popularity_w', 'clicks_popularity_old', 'carts_popularity_old', 'orders_popularity_old']\n",
    "# cudf.DataFrame(df_train[cols].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_val_c = load_parquets_cudf(f\"../output/features/fts_val_c_{VERSION}/*\")\n",
    "\n",
    "# if POS_RATIO:\n",
    "#     n_neg = int(df_val_c[TARGET].sum() / POS_RATIO)\n",
    "#     pos = df_val_c.index[df_val_c[TARGET] == 1]\n",
    "# #     neg = df_val_c[[TARGET]][df_val_c[TARGET] == 0].sample(n_neg).index\n",
    "# #     df_val_c = df_val_c.iloc[cudf.concat([pos, neg])]\n",
    "#     df_val_c = df_val_c.iloc[pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = cudf.concat([df_train, df_val_c], ignore_index=True)\n",
    "\n",
    "# del df_val_c\n",
    "# numba.cuda.current_context().deallocations.clear()\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = df_train.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Val data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_regex = f\"../output/features/fts_val_{VERSION}/*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# df_val = pd.read_csv(f'../output/fts_train_{VERSION}.csv', nrows=10_000_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for c in df_train.columns[5:]:\n",
    "#     plt.figure(figsize=(10, 4))\n",
    "#     sns.kdeplot(df_train.head(10000)[c].values, label=\"train\")\n",
    "#     sns.kdeplot(df_val.head(10000)[c].values, label=\"val\")\n",
    "#     plt.legend()\n",
    "#     plt.title(c)\n",
    "#     plt.show()\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import optuna\n",
    "import cuml\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from numerize.numerize import numerize\n",
    "from utils.torch import seed_everything\n",
    "\n",
    "\n",
    "def train(df_train, val_regex, config, log_folder=None, optimize=False):\n",
    "    seed_everything(config.seed)\n",
    "\n",
    "    txt = f\"{'Optimizing' if optimize else 'Training'} {config.model.upper()} Model\"\n",
    "    print(f\"\\n-------------   {txt}   -------------\\n\")\n",
    "\n",
    "#     if config.pos_ratio:\n",
    "#         n_neg = int(df_train[config.target].sum() / config.pos_ratio)\n",
    "#         pos = df_train.index[df_train[config.target] == 1]\n",
    "#         neg = df_train[[config.target]][df_train[config.target] == 0].sample(n_neg).index\n",
    "#         df_train = df_train.iloc[cudf.concat([pos, neg])]\n",
    "\n",
    "    if optimize:  # TODO\n",
    "        study = optuna.create_study(direction=\"minimize\")\n",
    "        objective = lambda x: objective_xgb(x, df_train, val_regex, features, target)\n",
    "        study.optimize(objective, n_trials=50)\n",
    "        print(study.best_params)\n",
    "        return study.best_params\n",
    "\n",
    "    val_candids = sum([len(cudf.read_parquet(f, columns=['gt_orders'])) for f in glob.glob(val_regex)])\n",
    "    print(f\"    -> {numerize(len(df_train))} training candidates\")\n",
    "    print(f\"    -> {numerize(val_candids)} validation candidates\\n\")\n",
    "    \n",
    "    train_fct = TRAIN_FCTS[config.model]\n",
    "    df_val, model = train_fct(\n",
    "        df_train,\n",
    "        val_regex,\n",
    "        features=config.features,\n",
    "        target=config.target,\n",
    "        params=config.params,\n",
    "        n_candidates_es=config.n_candidates_es,\n",
    "    )\n",
    "    \n",
    "    # Score\n",
    "    try:\n",
    "        auc = roc_auc_score(df_val[config.target], df_val[\"pred\"])\n",
    "    except:\n",
    "        auc = cuml.metrics.roc_auc_score(df_val[config.target].astype('int32'), df_val[\"pred\"].values)\n",
    "    \n",
    "    print(f'\\n -> AUC : {auc:.4f}\\n')\n",
    "\n",
    "    # Feature importance\n",
    "    if config.model == \"xgb\":\n",
    "        ft_imp = model.get_score()\n",
    "    else:\n",
    "        ft_imp = model.feature_importances_  # TODO\n",
    "    try:\n",
    "        ft_imp = pd.DataFrame(\n",
    "            pd.Series(ft_imp, index=config.features), columns=[\"importance\"]\n",
    "        )\n",
    "    except:\n",
    "        ft_imp = None\n",
    "  \n",
    "    if log_folder is None:\n",
    "        return df_val, ft_imp, model\n",
    "\n",
    "    # Save stuff\n",
    "    if config.model == \"xgb\":\n",
    "        model.save_model(log_folder + f\"{config.model}_{fold}.json\")\n",
    "    elif config.model == \"lgbm\":\n",
    "        try:\n",
    "            model.booster_.save_model(log_folder + f\"{config.model}_{fold}.txt\")\n",
    "        except Exception:\n",
    "            model.save_model(log_folder + f\"{config.model}_{fold}.txt\")\n",
    "    else:   # catboost, verif\n",
    "        model.save_model(log_folder + f\"{config.model}_{fold}.txt\")\n",
    "\n",
    "    ft_imp.to_csv(log_folder + \"ft_imp.csv\")\n",
    "    df_val.to_csv(log_folder + \"df_val.csv\", index=False)\n",
    "    \n",
    "    return df_val, ft_imp, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMS = {\n",
    "    \"xgb\":\n",
    "    {\n",
    "        \"learning_rate\": 0.01,\n",
    "        'max_depth': 8,\n",
    "        \"subsample\": 0.25,\n",
    "        'colsample_bytree': 0.9,\n",
    "        'reg_alpha': 0.1,\n",
    "        'reg_lambda': 1,\n",
    "#         \"min_child_weight\": 0.01,\n",
    "#         \"gamma\": 0.01,\n",
    "        'eval_metric':'auc',  # map\n",
    "        'objective':'binary:logistic',  # 'rank:pairwise',\n",
    "        'tree_method':'gpu_hist',\n",
    "        'predictor':'gpu_predictor',\n",
    "    },\n",
    "    \"catboost\":\n",
    "        {\n",
    "        'depth': 12,\n",
    "        \"l2_leaf_reg\": 0.1,\n",
    "        \"min_data_in_leaf\": 2000,\n",
    "        'reg_lambda': 0.1,\n",
    "        \"model_size_reg\": 0.5,\n",
    "        \"border_count\": 256,\n",
    "        },\n",
    "    \"lgbm\": {\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"num_leaves\": 511,\n",
    "        \"colsample_bytree\": 0.5,\n",
    "        \"reg_alpha\": 1,\n",
    "        \"reg_lambda\": 70,\n",
    "        \"min_child_samples\": 2000,  # MODIF  # 2000\n",
    "        \"min_split_gain\": 0.02,\n",
    "        \"min_child_weight\": 0.03,\n",
    "        \"path_smooth\": 0.2,\n",
    "#             \"min_data_in_bin\": 32,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    seed = 100\n",
    "    version = VERSION\n",
    "\n",
    "    features = [\n",
    "        'logspace_w', 'linspace_w', 'linspace_w_t163', 'logspace_w_t163', 'linspace_w_t191', 'logspace_w_t191',\n",
    "\n",
    "        'matrix_123_temporal_20_mean', 'matrix_123_temporal_20_sum', 'matrix_123_temporal_20_max',\n",
    "        'matrix_123_temporal_20_logspace_mean', 'matrix_123_temporal_20_logspace_sum', 'matrix_123_temporal_20_logspace_max',\n",
    "        'matrix_123_temporal_20_linspace_mean', 'matrix_123_temporal_20_linspace_sum', 'matrix_123_temporal_20_linspace_max',\n",
    "        'matrix_123_type136_20_mean', 'matrix_123_type136_20_sum', 'matrix_123_type136_20_max',\n",
    "        'matrix_123_type136_20_logspace_mean', 'matrix_123_type136_20_logspace_sum', 'matrix_123_type136_20_logspace_max',\n",
    "        'matrix_123_type136_20_linspace_mean', 'matrix_123_type136_20_linspace_sum', 'matrix_123_type136_20_linspace_max',\n",
    "        'matrix_12__20_mean', 'matrix_12__20_sum', 'matrix_12__20_max',\n",
    "        'matrix_12__20_logspace_mean', 'matrix_12__20_logspace_sum', 'matrix_12__20_logspace_max',\n",
    "        'matrix_12__20_linspace_mean', 'matrix_12__20_linspace_sum', 'matrix_12__20_linspace_max',\n",
    "        'matrix_123_type0.590.5_20_mean', 'matrix_123_type0.590.5_20_sum', 'matrix_123_type0.590.5_20_max',\n",
    "        'matrix_123_type0.590.5_20_logspace_mean', 'matrix_123_type0.590.5_20_logspace_sum', 'matrix_123_type0.590.5_20_logspace_max',\n",
    "        'matrix_123_type0.590.5_20_linspace_mean', 'matrix_123_type0.590.5_20_linspace_sum', 'matrix_123_type0.590.5_20_linspace_max',\n",
    "        \n",
    "        'clicks_popularity_w',  # 'clicks_popularity_lin_w', 'clicks_popularity_log_w',\n",
    "        'carts_popularity_w',  # 'carts_popularity_lin_w', 'carts_popularity_log_w',\n",
    "        'orders_popularity_w',  # 'orders_popularity_lin_w', 'orders_popularity_log_w',\n",
    "    \n",
    "        'clicks_popularity',  # 'clicks_popularity_lin', 'clicks_popularity_log',\n",
    "        'carts_popularity',  # 'carts_popularity_lin', 'carts_popularity_log',\n",
    "        'orders_popularity',  # 'orders_popularity_lin', 'orders_popularity_log',\n",
    "        \n",
    "#         'clicks_popularity_old',  # 'clicks_popularity_lin_old', 'clicks_popularity_log_old',\n",
    "#         'carts_popularity_old',  # 'carts_popularity_lin_old', 'carts_popularity_log_old',\n",
    "#         'orders_popularity_old',  # 'orders_popularity_lin_old', 'orders_popularity_log_old',\n",
    "        \n",
    "#         'clicks_popularity', 'carts_popularity', 'orders_popularity',\n",
    "#         'clicks_popularity_w', 'carts_popularity_w', 'orders_popularity_w',\n",
    "\n",
    "#         'candidate_clicks_before', 'candidate_carts_before', 'candidate_orders_before', 'candidate_*_before'\n",
    "        'n_views', 'n_clicks', 'n_carts', 'n_orders'\n",
    "    ]\n",
    "\n",
    "    cat_features = []\n",
    "\n",
    "    target = TARGET  # \"gt_orders\", \"gt_clicks\", \"gt_orders\"\n",
    "    pos_ratio = POS_RATIO\n",
    "    model = \"xgb\"\n",
    "\n",
    "    params = PARAMS[model]\n",
    "    n_candidates_es = 10_000_000\n",
    "\n",
    "    use_es = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPTIMIZE = False\n",
    "TRAIN = True\n",
    "DEBUG = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.01,\n",
       " 'max_depth': 8,\n",
       " 'subsample': 0.25,\n",
       " 'colsample_bytree': 0.9,\n",
       " 'reg_alpha': 0.1,\n",
       " 'reg_lambda': 1,\n",
       " 'eval_metric': 'auc',\n",
       " 'objective': 'binary:logistic',\n",
       " 'tree_method': 'gpu_hist',\n",
       " 'predictor': 'gpu_predictor'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Config.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------   Training XGB Model   -------------\n",
      "\n",
      "    -> 3M training candidates\n",
      "    -> 54.97M validation candidates\n",
      "\n",
      "[0]\tval-auc:0.94906\n",
      "[100]\tval-auc:0.95595\n",
      "[200]\tval-auc:0.95799\n",
      "[300]\tval-auc:0.95957\n",
      "[400]\tval-auc:0.96064\n",
      "[500]\tval-auc:0.96143\n",
      "[600]\tval-auc:0.96203\n",
      "[700]\tval-auc:0.96243\n",
      "[800]\tval-auc:0.96268\n",
      "[900]\tval-auc:0.96283\n",
      "[1000]\tval-auc:0.96293\n",
      "[1100]\tval-auc:0.96301\n",
      "[1200]\tval-auc:0.96307\n",
      "[1300]\tval-auc:0.96313\n",
      "[1400]\tval-auc:0.96317\n",
      "[1500]\tval-auc:0.96320\n",
      "[1600]\tval-auc:0.96322\n",
      "[1700]\tval-auc:0.96323\n",
      "[1800]\tval-auc:0.96324\n",
      "[1900]\tval-auc:0.96326\n",
      "[2000]\tval-auc:0.96326\n",
      "[2100]\tval-auc:0.96328\n",
      "[2200]\tval-auc:0.96328\n",
      "[2249]\tval-auc:0.96328\n",
      "\n",
      "[Infering]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:35<00:00,  1.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -> AUC : 0.9644\n",
      "\n",
      "CPU times: user 3min 13s, sys: 15.7 s, total: 3min 28s\n",
      "Wall time: 3min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# if TRAIN:\n",
    "log_folder = None\n",
    "if not DEBUG:\n",
    "    log_folder = prepare_log_folder(LOG_PATH + f\"lvl_{LEVEL}/\")\n",
    "    print(f'Logging results to {log_folder}')\n",
    "    save_config(Config, log_folder + 'config')\n",
    "    create_logger(directory=log_folder, name=\"logs.txt\")\n",
    "\n",
    "df_val, ft_imp, model = train(df_train, val_regex, Config, log_folder=log_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_importances(ft_imp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = pd.read_parquet(\"../output/val_labels.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds = cudf.from_pandas(df_val)\n",
    "\n",
    "preds = df_val[['session', 'candidates', 'pred']].copy()\n",
    "\n",
    "preds = preds.sort_values(['session', 'pred'], ascending=[True, False])\n",
    "preds = preds[['session', 'candidates', 'pred']].groupby('session').agg(list).reset_index()\n",
    "\n",
    "preds = preds.to_pandas()\n",
    "preds['candidates'] = preds['candidates'].apply(lambda x: x[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = load_sessions(\"../output/val_parquet/*\")\n",
    "\n",
    "if Config.target == \"gt_carts\":\n",
    "    top = dfs.loc[dfs[\"type\"] == 1, \"aid\"].value_counts().index.values[:20].tolist()\n",
    "elif Config.target == \"gt_orders\":\n",
    "    top = dfs.loc[dfs[\"type\"] == 2, \"aid\"].value_counts().index.values[:20].tolist()\n",
    "else:\n",
    "    top = dfs.loc[dfs[\"type\"] == 0, \"aid\"].value_counts().index.values[:20].tolist()\n",
    "\n",
    "preds['candidates'] = preds['candidates'].apply(lambda x: list(x) + top[: 20 - len(x)])\n",
    "\n",
    "del dfs\n",
    "numba.cuda.current_context().deallocations.clear()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- orders\t-  Found 204.86K GTs\t-  Recall : 0.6540\n"
     ]
    }
   ],
   "source": [
    "recalls = []\n",
    "for col in CLASSES:\n",
    "    if \"gt_\" + col not in [Config.target]:\n",
    "        continue\n",
    "\n",
    "    if f\"gt_{col}\" not in preds.columns:\n",
    "        preds = preds.merge(gt[gt[\"type\"] == col].drop(\"type\", axis=1), how=\"left\").rename(\n",
    "            columns={\"ground_truth\": f\"gt_{col}\"}\n",
    "        )\n",
    "\n",
    "    n_preds, n_gts, n_found = get_coverage(\n",
    "        preds[\"candidates\"].values, preds[f\"gt_{col}\"].values\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"- {col}\\t-  Found {numerize(n_found)} GTs\\t-  Recall : {n_found / n_gts :.4f}\"\n",
    "    )\n",
    "    recalls.append(n_found / n_gts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- orders\t-  Found 204.86K GTs\t-  Recall : 0.6540\n",
    "- carts\t-  Found 238.4K GTs\t-  Recall : 0.4139\n",
    "- clicks\t-  Found 888.07K GTs\t-  Recall : 0.5059"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> CV : 0.5692\n"
     ]
    }
   ],
   "source": [
    "cv = np.average([0.5260, 0.4139, 0.6540], weights=WEIGHTS)\n",
    "# cv = np.average([0.5059, 0.4139, 0.6540], weights=WEIGHTS)\n",
    "print(f\"-> CV : {cv:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To beat :** CV = 5643\n",
    "- clicks recall = 0.5260\n",
    "- carts recall = 0.4094\n",
    "- orders recall = 0.6482"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
