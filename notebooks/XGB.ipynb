{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About :** Trains XGBoost models.\n",
    "\n",
    "**TODO**:\n",
    "- better neg sampling technique ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import cudf\n",
    "import json\n",
    "import glob\n",
    "import numba\n",
    "import xgboost\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from data.fe import load_sessions\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "pd.options.display.max_columns = 500\n",
    "pd.options.display.max_rows = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from params import *\n",
    "\n",
    "from model_zoo import TRAIN_FCTS\n",
    "\n",
    "from utils.metrics import get_coverage\n",
    "from utils.plot import plot_importances\n",
    "from utils.load import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = \"v3.5\"\n",
    "# VERSION = \"v2.5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train data\n",
    "- neg sampling could use candidates from lower versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POS_RATIO = 0.1\n",
    "TARGET = \"gt_orders\"   # \"gt_clicks\", \"gt_carts\", \"gt_orders\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = load_parquets_cudf_chunks(\n",
    "    f\"../output/features/fts_train_{VERSION}/*\",\n",
    "    pos_ratio=POS_RATIO,\n",
    "    target=TARGET,\n",
    "    n_chunks=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = cudf.concat([  # not working ??\n",
    "#     load_parquets_cudf_chunks(\n",
    "#         f\"../output/features/fts_train_v3.5/*\",\n",
    "#         pos_ratio=0.1,\n",
    "#         target=TARGET,\n",
    "#         n_chunks=5,\n",
    "#     ),\n",
    "#     load_parquets_cudf_chunks(\n",
    "#         f\"../output/features/fts_train_v4.5/*\",\n",
    "#         pos_ratio=0.,\n",
    "#         target=TARGET,\n",
    "#         n_chunks=5,\n",
    "#     ),\n",
    "# ], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c = df_train.sort_values(['session', 'candidates']).head().copy()\n",
    "# ref = df_train.sort_values(['session', 'candidates']).head().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diff = c[[col for col in ref.columns if col in c.columns]] - ref[[col for col in ref.columns if col in c.columns]]\n",
    "# for i, c in cudf.DataFrame(diff.max()).to_pandas().iterrows():\n",
    "#     if c.values:\n",
    "#         print(i, c.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols = ['clicks_popularity', 'carts_popularity', 'orders_popularity', 'clicks_popularity_w', 'carts_popularity_w', 'orders_popularity_w', 'clicks_popularity_old', 'carts_popularity_old', 'orders_popularity_old']\n",
    "# cudf.DataFrame(df_train[[c for c in cols if c in df_train.columns]].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_val_c = load_parquets_cudf(f\"../output/features/fts_val_c_{VERSION}/*\")\n",
    "\n",
    "# if POS_RATIO:\n",
    "#     n_neg = int(df_val_c[TARGET].sum() / POS_RATIO)\n",
    "#     pos = df_val_c.index[df_val_c[TARGET] == 1]\n",
    "# #     neg = df_val_c[[TARGET]][df_val_c[TARGET] == 0].sample(n_neg).index\n",
    "# #     df_val_c = df_val_c.iloc[cudf.concat([pos, neg])]\n",
    "#     df_val_c = df_val_c.iloc[pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = cudf.concat([df_train, df_val_c], ignore_index=True)\n",
    "\n",
    "# del df_val_c\n",
    "# numba.cuda.current_context().deallocations.clear()\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = df_train.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Val data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_regex = f\"../output/features/fts_val_{VERSION}/*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glob.glob(val_regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# df_val = pd.read_csv(f'../output/fts_train_{VERSION}.csv', nrows=10_000_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for c in df_train.columns[5:]:\n",
    "#     plt.figure(figsize=(10, 4))\n",
    "#     sns.kdeplot(df_train.head(10000)[c].values, label=\"train\")\n",
    "#     sns.kdeplot(df_val.head(10000)[c].values, label=\"val\")\n",
    "#     plt.legend()\n",
    "#     plt.title(c)\n",
    "#     plt.show()\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO_REMOVE = [\n",
    "#     \"clicks_popularity_lin\", \"carts_popularity_lin\", \"orders_popularity_lin\", \"views_popularity_lin\",\n",
    "#     \"clicks_popularity_lin_w\", \"carts_popularity_lin_w\", \"orders_popularity_lin_w\", \"views_popularity_lin_w\",\n",
    "#     \"clicks_popularity_lin_old\", \"carts_popularity_lin_old\", \"orders_popularity_lin_old\", \"views_popularity_lin_old\",\n",
    "#     \"clicks_popularity\", \"carts_popularity\", \"orders_popularity\", \"views_popularity\"\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corr = df_train[df_train.columns[5:]].corr().to_pandas()\n",
    "\n",
    "# corr.values[np.triu_indices_from(corr.values)] = 0\n",
    "# corr = corr * (1 - np.eye(len(corr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TH = 0.99\n",
    "\n",
    "# cols = list(corr.columns[corr.max() > TH])\n",
    "\n",
    "# for i in cols:\n",
    "#     for j in cols:\n",
    "#         if i not in TO_REMOVE and j not in TO_REMOVE:\n",
    "#             if corr.loc[i, j] > TH:\n",
    "#                 print(f'{i} - {j} : {corr.loc[i, j] :.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import optuna\n",
    "import cuml\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from numerize.numerize import numerize\n",
    "from utils.torch import seed_everything\n",
    "\n",
    "\n",
    "def train(df_train, val_regex, config, log_folder=None, optimize=False):\n",
    "    seed_everything(config.seed)\n",
    "\n",
    "    txt = f\"{'Optimizing' if optimize else 'Training'} {config.model.upper()} Model\"\n",
    "    print(f\"\\n-------------   {txt}   -------------\\n\")\n",
    "\n",
    "#     if config.pos_ratio:\n",
    "#         n_neg = int(df_train[config.target].sum() / config.pos_ratio)\n",
    "#         pos = df_train.index[df_train[config.target] == 1]\n",
    "#         neg = df_train[[config.target]][df_train[config.target] == 0].sample(n_neg).index\n",
    "#         df_train = df_train.iloc[cudf.concat([pos, neg])]\n",
    "\n",
    "    if optimize:  # TODO\n",
    "        study = optuna.create_study(direction=\"minimize\")\n",
    "        objective = lambda x: objective_xgb(x, df_train, val_regex, features, target)\n",
    "        study.optimize(objective, n_trials=50)\n",
    "        print(study.best_params)\n",
    "        return study.best_params\n",
    "\n",
    "    val_candids = sum([len(cudf.read_parquet(f, columns=['gt_orders'])) for f in glob.glob(val_regex)])\n",
    "    print(f\"    -> {numerize(len(df_train))} training candidates\")\n",
    "    print(f\"    -> {numerize(val_candids)} validation candidates\\n\")\n",
    "    \n",
    "    train_fct = TRAIN_FCTS[config.model]\n",
    "    df_val, model = train_fct(\n",
    "        df_train,\n",
    "        val_regex,\n",
    "        features=config.features,\n",
    "        target=config.target,\n",
    "        params=config.params,\n",
    "        n_candidates_es=config.n_candidates_es,\n",
    "    )\n",
    "    \n",
    "    # Score\n",
    "    try:\n",
    "        auc = roc_auc_score(df_val[config.target], df_val[\"pred\"])\n",
    "    except:\n",
    "        auc = cuml.metrics.roc_auc_score(df_val[config.target].astype('int32'), df_val[\"pred\"].values)\n",
    "    \n",
    "    print(f'\\n -> AUC : {auc:.4f}\\n')\n",
    "\n",
    "    # Feature importance\n",
    "    if config.model == \"xgb\":\n",
    "        ft_imp = model.get_score()\n",
    "    else:\n",
    "        ft_imp = model.feature_importances_  # TODO\n",
    "    try:\n",
    "        ft_imp = pd.DataFrame(\n",
    "            pd.Series(ft_imp, index=config.features), columns=[\"importance\"]\n",
    "        )\n",
    "    except:\n",
    "        ft_imp = None\n",
    "  \n",
    "    if log_folder is None:\n",
    "        return df_val, ft_imp, model\n",
    "\n",
    "    # Save stuff\n",
    "    if config.model == \"xgb\":\n",
    "        model.save_model(log_folder + f\"{config.model}_{fold}.json\")\n",
    "    elif config.model == \"lgbm\":\n",
    "        try:\n",
    "            model.booster_.save_model(log_folder + f\"{config.model}_{fold}.txt\")\n",
    "        except Exception:\n",
    "            model.save_model(log_folder + f\"{config.model}_{fold}.txt\")\n",
    "    else:   # catboost, verif\n",
    "        model.save_model(log_folder + f\"{config.model}_{fold}.txt\")\n",
    "\n",
    "    ft_imp.to_csv(log_folder + \"ft_imp.csv\")\n",
    "    df_val.to_csv(log_folder + \"df_val.csv\", index=False)\n",
    "    \n",
    "    return df_val, ft_imp, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMS = {\n",
    "    \"xgb\":\n",
    "    {\n",
    "        \"learning_rate\": 0.01,\n",
    "        'max_depth': 5,\n",
    "        \"subsample\": 0.25,\n",
    "        'colsample_bytree': 0.9,\n",
    "        'reg_alpha': 0.01,\n",
    "        'reg_lambda': 0.1,\n",
    "#         \"min_child_weight\": 0.01,\n",
    "#         \"gamma\": 0.01,\n",
    "        'eval_metric':'auc',  # map\n",
    "        'objective':'binary:logistic',  # 'rank:pairwise',\n",
    "        'tree_method':'gpu_hist',\n",
    "        'predictor':'gpu_predictor',\n",
    "    },\n",
    "    \"catboost\":\n",
    "        {\n",
    "        'depth': 12,\n",
    "        \"l2_leaf_reg\": 0.1,\n",
    "        \"min_data_in_leaf\": 2000,\n",
    "        'reg_lambda': 0.1,\n",
    "        \"model_size_reg\": 0.5,\n",
    "        \"border_count\": 256,\n",
    "        },\n",
    "    \"lgbm\": {\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"num_leaves\": 511,\n",
    "        \"colsample_bytree\": 0.5,\n",
    "        \"reg_alpha\": 1,\n",
    "        \"reg_lambda\": 70,\n",
    "        \"min_child_samples\": 2000,  # MODIF  # 2000\n",
    "        \"min_split_gain\": 0.02,\n",
    "        \"min_child_weight\": 0.03,\n",
    "        \"path_smooth\": 0.2,\n",
    "#             \"min_data_in_bin\": 32,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    seed = 100\n",
    "    version = VERSION\n",
    "\n",
    "    features = [\n",
    "        'logspace_w', 'linspace_w', 'linspace_w_t163', 'logspace_w_t163', 'linspace_w_t191', 'logspace_w_t191',\n",
    "\n",
    "        'matrix_123_temporal_20_mean', 'matrix_123_temporal_20_sum', 'matrix_123_temporal_20_max',\n",
    "        'matrix_123_temporal_20_logspace_mean', 'matrix_123_temporal_20_logspace_sum', 'matrix_123_temporal_20_logspace_max',\n",
    "        'matrix_123_temporal_20_linspace_mean', 'matrix_123_temporal_20_linspace_sum', 'matrix_123_temporal_20_linspace_max',\n",
    "        'matrix_123_type136_20_mean', 'matrix_123_type136_20_sum', 'matrix_123_type136_20_max',\n",
    "        'matrix_123_type136_20_logspace_mean', 'matrix_123_type136_20_logspace_sum', 'matrix_123_type136_20_logspace_max',\n",
    "        'matrix_123_type136_20_linspace_mean', 'matrix_123_type136_20_linspace_sum', 'matrix_123_type136_20_linspace_max',\n",
    "        'matrix_12__20_mean', 'matrix_12__20_sum', 'matrix_12__20_max',\n",
    "        'matrix_12__20_logspace_mean', 'matrix_12__20_logspace_sum', 'matrix_12__20_logspace_max',\n",
    "        'matrix_12__20_linspace_mean', 'matrix_12__20_linspace_sum', 'matrix_12__20_linspace_max',\n",
    "        'matrix_123_type0.590.5_20_mean', 'matrix_123_type0.590.5_20_sum', 'matrix_123_type0.590.5_20_max',\n",
    "        'matrix_123_type0.590.5_20_logspace_mean', 'matrix_123_type0.590.5_20_logspace_sum', 'matrix_123_type0.590.5_20_logspace_max',\n",
    "        'matrix_123_type0.590.5_20_linspace_mean', 'matrix_123_type0.590.5_20_linspace_sum', 'matrix_123_type0.590.5_20_linspace_max',\n",
    "        \n",
    "        'clicks_popularity_w', 'carts_popularity_w', 'orders_popularity_w',\n",
    "        'view_popularity_log_w', 'view_popularity_lin_w', \n",
    "    \n",
    "        'clicks_popularity', 'carts_popularity', 'orders_popularity',\n",
    "        'view_popularity_log', 'view_popularity_lin',\n",
    "        \n",
    "        'clicks_popularity_old', 'carts_popularity_old', 'orders_popularity_old',\n",
    "        'view_popularity_log_old', 'view_popularity_lin_old',\n",
    "\n",
    "        'candidate_clicks_before', 'candidate_carts_before', 'candidate_orders_before', 'candidate_*_before',\n",
    "        'n_views', 'n_clicks', 'n_carts', 'n_orders',\n",
    "    ]\n",
    "\n",
    "    cat_features = []\n",
    "\n",
    "    target = TARGET  # \"gt_orders\", \"gt_clicks\", \"gt_orders\"\n",
    "    pos_ratio = POS_RATIO\n",
    "    model = \"xgb\"\n",
    "\n",
    "    params = PARAMS[model]\n",
    "    n_candidates_es = 10_000_000\n",
    "\n",
    "    use_es = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPTIMIZE = False\n",
    "TRAIN = True\n",
    "DEBUG = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Config.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# if TRAIN:\n",
    "log_folder = None\n",
    "if not DEBUG:\n",
    "    log_folder = prepare_log_folder(LOG_PATH + f\"lvl_{LEVEL}/\")\n",
    "    print(f'Logging results to {log_folder}')\n",
    "    save_config(Config, log_folder + 'config')\n",
    "    create_logger(directory=log_folder, name=\"logs.txt\")\n",
    "\n",
    "df_val, ft_imp, model = train(df_train, val_regex, Config, log_folder=log_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_importances(ft_imp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = pd.read_parquet(\"../output/val_labels.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds = cudf.from_pandas(df_val)\n",
    "\n",
    "preds = df_val[['session', 'candidates', 'pred']].copy()\n",
    "\n",
    "preds = preds.sort_values(['session', 'pred'], ascending=[True, False])\n",
    "preds = preds[['session', 'candidates', 'pred']].groupby('session').agg(list).reset_index()\n",
    "\n",
    "preds = preds.to_pandas()\n",
    "preds['candidates'] = preds['candidates'].apply(lambda x: x[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = load_sessions(\"../output/val_parquet/*\")\n",
    "\n",
    "if Config.target == \"gt_carts\":\n",
    "    top = dfs.loc[dfs[\"type\"] == 1, \"aid\"].value_counts().index.values[:20].tolist()\n",
    "elif Config.target == \"gt_orders\":\n",
    "    top = dfs.loc[dfs[\"type\"] == 2, \"aid\"].value_counts().index.values[:20].tolist()\n",
    "else:\n",
    "    top = dfs.loc[dfs[\"type\"] == 0, \"aid\"].value_counts().index.values[:20].tolist()\n",
    "\n",
    "preds['candidates'] = preds['candidates'].apply(lambda x: list(x) + top[: 20 - len(x)])\n",
    "\n",
    "del dfs\n",
    "numba.cuda.current_context().deallocations.clear()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recalls = []\n",
    "for col in CLASSES:\n",
    "    if \"gt_\" + col not in [Config.target]:\n",
    "        continue\n",
    "\n",
    "    if f\"gt_{col}\" not in preds.columns:\n",
    "        preds = preds.merge(gt[gt[\"type\"] == col].drop(\"type\", axis=1), how=\"left\").rename(\n",
    "            columns={\"ground_truth\": f\"gt_{col}\"}\n",
    "        )\n",
    "\n",
    "    n_preds, n_gts, n_found = get_coverage(\n",
    "        preds[\"candidates\"].values, preds[f\"gt_{col}\"].values\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"- {col}\\t-  Found {numerize(n_found)} GTs\\t-  Recall : {n_found / n_gts :.4f}\"\n",
    "    )\n",
    "    recalls.append(n_found / n_gts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- orders\t-  Found 205.96K GTs\t-  Recall : 0.6578\n",
    "- carts\t-  Found 238.4K GTs\t-  Recall : 0.4203\n",
    "- clicks\t-  Found 888.07K GTs\t-  Recall : 0.5059"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = np.average([0.5273, 0.4203, 0.6578], weights=WEIGHTS)\n",
    "# cv = np.average([0.5059, 0.4139, 0.6540], weights=WEIGHTS)\n",
    "print(f\"-> CV : {cv:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To beat :** CV = 5643\n",
    "- clicks recall = 0.5260\n",
    "- carts recall = 0.4094\n",
    "- orders recall = 0.6482"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
