{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About :** Blend & evaluate models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import cudf\n",
    "import json\n",
    "import glob\n",
    "import numba\n",
    "import xgboost\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from numerize.numerize import numerize\n",
    "from pandarallel import pandarallel\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "pd.options.display.max_columns = 500\n",
    "pd.options.display.max_rows = 500\n",
    "pandarallel.initialize(nb_workers=32, progress_bar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from params import *\n",
    "\n",
    "from utils.metrics import get_coverage, evaluate\n",
    "from utils.plot import plot_importances\n",
    "from utils.load import *\n",
    "from utils.logger import *\n",
    "\n",
    "from inference.boosting import inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference\n",
    "- Not needed if done during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_FOLDER = \"your exp\"\n",
    "\n",
    "VERSION = \"cv7+-tv5.12\"\n",
    "\n",
    "REGEX = f\"../output/features/fts_val_{VERSION}/*\"\n",
    "TEST_REGEX = f\"../output/features/fts_test_{VERSION}/*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference(REGEX, TEST_REGEX, EXP_FOLDER, debug=False, save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiments\n",
    " - Use your own folders here ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_FOLDERS = [  # Clicks - 0.5593\n",
    "    [\"Fold 0\", \"Fold 1\", \"Fold 2 & 3\"],  # Model 1\n",
    "    [\"Fold 0 & 1\", \"Fold 2 & 3\"],  # Model 2\n",
    "]\n",
    "WEIGHTS = [1, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val_ = None\n",
    "dfs_val_list = []\n",
    "for exp_folders, w in zip(EXP_FOLDERS, WEIGHTS):\n",
    "    \n",
    "    if not isinstance(exp_folders, list):\n",
    "        exp_folders = [exp_folders]\n",
    "\n",
    "    dfs_val = []\n",
    "    for exp_folder in exp_folders:\n",
    "        config = Config(json.load(open(exp_folder + \"config.json\", \"r\")))\n",
    "        print(f'\\t === Exp {exp_folder}\\t Target {config.target} ===\\n')\n",
    "        TARGET = config.target\n",
    "        try:\n",
    "            print(f\"{config.version} - Pos ratio {config.pos_ratio} - Extra_prop {config.extra_prop if config.use_extra else None}\\n\")\n",
    "        except:\n",
    "            print(f\"{config.version} - Pos ratio {config.pos_ratio} - Extra_prop None\\n\")\n",
    "\n",
    "        for fold in range(config.k):\n",
    "            try:\n",
    "                df_val = cudf.read_parquet(exp_folder + f\"df_val_{fold}.parquet\")\n",
    "                df_val['pred'] *= w\n",
    "\n",
    "                dfs_val.append(df_val)\n",
    "                if len(EXP_FOLDERS) == 1:\n",
    "                    print(f'-> Retrieved fold {fold}', end=\"\")\n",
    "                    evaluate(df_val, TARGET)\n",
    "            except FileNotFoundError:\n",
    "                pass\n",
    "\n",
    "    dfs_val = cudf.concat(dfs_val, ignore_index=True)\n",
    "    dfs_val_list.append(dfs_val.sort_values(['session', 'candidates'], ignore_index=True))\n",
    "\n",
    "    print('\\n ===> CV :')\n",
    "    cv = evaluate(dfs_val, TARGET)\n",
    "\n",
    "    if df_val_ is None: \n",
    "        df_val_ = dfs_val.copy()\n",
    "    else:\n",
    "        df_val_ = df_val_.set_index(['session', 'candidates']).add(\n",
    "            dfs_val.set_index(['session', 'candidates']), fill_value=0\n",
    "        ).reset_index()\n",
    "        \n",
    "    \n",
    "\n",
    "    del dfs_val\n",
    "    numba.cuda.current_context().deallocations.clear()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = evaluate(df_val_, TARGET, verbose=0)\n",
    "print(f' ===> CV : {score:.7f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = None\n",
    "for exp_folders, w  in zip(EXP_FOLDERS, WEIGHTS):\n",
    "    dfs_test = None\n",
    "\n",
    "    if not isinstance(exp_folders, list):\n",
    "        exp_folders = [exp_folders]\n",
    "    \n",
    "    for exp_folder in exp_folders:\n",
    "        config = Config(json.load(open(exp_folder + \"config.json\", \"r\")))\n",
    "        print(f'\\t === Exp {exp_folder}\\t Target {config.target} ===\\n')\n",
    "        TARGET = config.target\n",
    "\n",
    "        for fold in range(config.k):\n",
    "            try:\n",
    "                df_test_ = cudf.read_parquet(exp_folder + f\"df_test_{fold}.parquet\")\n",
    "                df_test_['pred'] *= (w / 4)\n",
    "                print(f'-> Retrieved fold {fold}\\n')\n",
    "                \n",
    "                if dfs_test is None:\n",
    "                    dfs_test = df_test_\n",
    "                else:\n",
    "                    dfs_test = dfs_test.set_index(['session', 'candidates']).add(\n",
    "                        df_test_.set_index(['session', 'candidates']), fill_value=0\n",
    "                    ).reset_index()\n",
    "                \n",
    "                del df_test_\n",
    "                numba.cuda.current_context().deallocations.clear()\n",
    "                gc.collect()\n",
    "\n",
    "            except FileNotFoundError:\n",
    "                pass\n",
    "\n",
    "    print(f'- Retrieved {len(dfs_test)} test candidates.\\n')\n",
    "\n",
    "    if df_test is None:\n",
    "        df_test = dfs_test\n",
    "    else:\n",
    "        df_test = df_test.set_index(['session', 'candidates']).add(\n",
    "            dfs_test.set_index(['session', 'candidates']), fill_value=0\n",
    "        ).reset_index()\n",
    "\n",
    "    del dfs_test\n",
    "    numba.cuda.current_context().deallocations.clear()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = df_test[['session', 'candidates', 'pred']].copy()\n",
    "\n",
    "preds = preds.sort_values(['session', 'pred'], ascending=[True, False])\n",
    "preds = preds[['session', 'candidates', 'pred']].groupby('session').agg(list).reset_index()\n",
    "\n",
    "preds = preds.to_pandas()\n",
    "preds['candidates'] = preds['candidates'].apply(lambda x: x[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = load_sessions(f\"../output/test_parquet/*\")\n",
    "\n",
    "if config.target == \"gt_carts\":\n",
    "    top = dfs.loc[dfs[\"type\"] == 1, \"aid\"].value_counts().index.values[:20].tolist()\n",
    "elif config.target == \"gt_orders\":\n",
    "    top = dfs.loc[dfs[\"type\"] == 2, \"aid\"].value_counts().index.values[:20].tolist()\n",
    "else:\n",
    "    top = dfs.loc[dfs[\"type\"] == 0, \"aid\"].value_counts().index.values[:20].tolist()\n",
    "\n",
    "preds['candidates'] = preds['candidates'].apply(lambda x: list(x) + top[: 20 - len(x)])\n",
    "\n",
    "del dfs\n",
    "numba.cuda.current_context().deallocations.clear()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FT_VERSION = \"cv7+-tv5.11\"\n",
    "MODEL_VERSION = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_folder_2 = LOG_PATH + f\"{FT_VERSION}.{MODEL_VERSION}/\"\n",
    "\n",
    "os.makedirs(log_folder_2, exist_ok=True)\n",
    "save_config(config, log_folder_2 + 'config')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = preds[['session', 'candidates']].copy()\n",
    "assert len(sub) == 1671803\n",
    "\n",
    "sub['candidates'] = sub['candidates'].parallel_apply(lambda x: \" \".join(map(str, x)))\n",
    "sub['session'] =  sub['session'].astype(str) + \"_\" + TARGET[3:]\n",
    "sub.columns = [\"session_type\", \"labels\"]\n",
    "\n",
    "sub.to_csv(log_folder_2 + f'sub_{TARGET}.csv', index=False)\n",
    "print(f\"-> Saved sub to {log_folder_2 + f'sub_{TARGET}.csv'}\\n\")\n",
    "\n",
    "display(sub.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if all([os.path.exists(log_folder_2 + f'sub_gt_{c}.csv') for c in CLASSES]):\n",
    "    sub_final = cudf.concat([\n",
    "        cudf.read_csv(log_folder_2 + f'sub_gt_{c}.csv') for c in CLASSES\n",
    "    ], ignore_index=True)\n",
    "\n",
    "    assert len(sub_final) == 5015409\n",
    "    sub_final.to_csv(log_folder_2 + f\"submission.csv\", index=False)\n",
    "\n",
    "    print(f\"\\n-> Saved final sub to {log_folder_2 + f'submission.csv'}\\n\")\n",
    "\n",
    "    display(sub_final.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaggle competitions submit -c otto-recommender-system -f submission.csv -m \"Message\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done !"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "f7241b2af102f7e024509099765066b36197b195077f7bfac6e5bc041ba17c8c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
