{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About :** Generates candidates.\n",
    "\n",
    "**TODO**:\n",
    "- Matrices from optimized notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import cudf\n",
    "import json\n",
    "import glob\n",
    "import pickle\n",
    "import warnings\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "from pandarallel import pandarallel\n",
    "from numerize.numerize import numerize\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "\n",
    "pandarallel.initialize(nb_workers=32, progress_bar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from params import *\n",
    "\n",
    "from data.covisitation import compute_covisitation_matrix\n",
    "from data.candidates import load_parquets, create_candidates, explode, matrix_to_candids_dict\n",
    "\n",
    "from utils.metrics import get_coverage\n",
    "from utils.chris import suggest_clicks, suggest_buys, read_file_to_cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covisitation matrices\n",
    "- Recompute on train without using val ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cache = {}\n",
    "type_labels = {\"clicks\": 0, \"carts\": 1, \"orders\": 2}\n",
    "\n",
    "# files = glob.glob(\"../input/chris/*_parquet/*\")\n",
    "\n",
    "files = glob.glob(\"../output/full_train_parquet/*\") +  glob.glob(\"../output/val_parquet/*\")\n",
    "\n",
    "for f in tqdm(files):\n",
    "    data_cache[f] = read_file_to_cache(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mins = []\n",
    "# maxs = []\n",
    "# st = 0\n",
    "# sv = 0\n",
    "# nv = 0\n",
    "# nt = 0\n",
    "\n",
    "# for k in data_cache.keys():\n",
    "#     if \"val\" in k or \"test\" in k:\n",
    "#         mins.append(data_cache[k]['ts'].min())\n",
    "#         sv += len(data_cache[k]['session'].unique())\n",
    "#         nv += len(data_cache[k])\n",
    "#     else:\n",
    "#         maxs.append(data_cache[k]['ts'].max())\n",
    "#         st += len(data_cache[k]['session'].unique())\n",
    "#         nt += len(data_cache[k])\n",
    "        \n",
    "# np.min(mins) > np.max(maxs), st, sv, nt, nv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_covisitation_matrix(\n",
    "    files,\n",
    "    data_cache,\n",
    "    weighting=\"temporal\",\n",
    "    n=20,\n",
    "    save_folder=\"../output/matrices/\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_covisitation_matrix(\n",
    "    files,\n",
    "    data_cache,\n",
    "    weighting=\"type\",\n",
    "    type_weight={0: 1, 1: 3, 2: 6},\n",
    "    n=20,\n",
    "    save_folder=\"../output/matrices/\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_covisitation_matrix(\n",
    "    files,\n",
    "    data_cache,\n",
    "    considered_types=[1, 2],\n",
    "    weighting=\"\",\n",
    "    n=20,\n",
    "    save_folder=\"../output/matrices/\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chris Rerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_val = load_parquets(\"../input/chris/test_parquet/*\")\n",
    "\n",
    "# top_clicks = df_val.loc[df_val[\"type\"] == 0, \"aid\"].value_counts().index.values[:20]\n",
    "# top_carts = df_val.loc[df_val[\"type\"] == 1, \"aid\"].value_counts().index.values[:20]\n",
    "# top_orders = df_val.loc[df_val[\"type\"] == 2, \"aid\"].value_counts().index.values[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicks_candids = matrix_to_candids_dict(\n",
    "#     cudf.read_parquet(\"../output/matrices/matrix_123_temporal_20.pqt\")\n",
    "# )\n",
    "# type_weighted_candids = matrix_to_candids_dict(\n",
    "#     cudf.read_parquet(\"../output/matrices/matrix_123_type_15.pqt\")\n",
    "# )\n",
    "# cartbuy_candids = matrix_to_candids_dict(\n",
    "#     cudf.read_parquet(\"../output/matrices/matrix_12__15.pqt\")\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# pred_df_clicks = df_val.groupby([\"session\"]).apply(\n",
    "#     lambda x: suggest_clicks(x, clicks_candids, top_clicks)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# pred_df_buys = df_val.groupby([\"session\"]).apply(\n",
    "#     lambda x: suggest_buys(x, type_weighted_candids, cartbuy_candids, top_orders)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# try:\n",
    "#     clicks_pred_df = pd.DataFrame(pred_df_clicks.add_suffix(\"_clicks\"), columns=[\"labels\"]).reset_index()\n",
    "# except:\n",
    "#     clicks_pred_df = pd.DataFrame(pred_df_buys.add_suffix(\"_clicks\"), columns=[\"labels\"]).reset_index()\n",
    "\n",
    "# orders_pred_df = pd.DataFrame(pred_df_buys.add_suffix(\"_orders\"), columns=[\"labels\"]).reset_index()\n",
    "# carts_pred_df = pd.DataFrame(pred_df_buys.add_suffix(\"_carts\"), columns=[\"labels\"]).reset_index()\n",
    "\n",
    "# pred_df = pd.concat([clicks_pred_df, orders_pred_df, carts_pred_df])\n",
    "# pred_df.columns = [\"session_type\", \"labels_l\"]\n",
    "# pred_df[\"labels\"] = pred_df[\"labels_l\"].apply(lambda x: \" \".join(map(str, x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gt = pd.read_parquet(\"../input/chris/test_labels.parquet\")\n",
    "\n",
    "\n",
    "# df_pred = pred_df[[\"session_type\", \"labels_l\"]].copy()\n",
    "# df_pred.columns = [\"session_type\", \"candidates\"]\n",
    "# df_pred[\"session\"] = (\n",
    "#     df_pred[\"session_type\"].apply(lambda x: x.split(\"_\")[0]).astype(int)\n",
    "# )\n",
    "# df_pred[\"type\"] = df_pred[\"session_type\"].apply(lambda x: x.split(\"_\")[1])\n",
    "\n",
    "# df_pred = df_pred.merge(gt, on=[\"session\", \"type\"], how=\"left\")\n",
    "\n",
    "# for col in CLASSES:\n",
    "#     df_pred_c = df_pred[df_pred[\"type\"] == col]\n",
    "\n",
    "#     n_preds, n_gts, n_found = get_coverage(\n",
    "#         df_pred_c[\"candidates\"].values, df_pred_c[\"ground_truth\"].values\n",
    "#     )\n",
    "#     print(\n",
    "#         f\"{col}\\t- Found {numerize(n_found)} GTs with {numerize(n_preds)} candidates (pos_prop={n_found / n_preds * 100 :.2f}%)\\t-  Highest reachable Recall : {n_found / n_gts :.3f}\"\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- clicks\t- Found 574.14K GTs with 36.03M candidates (pos_prop=1.59%)\t-  Highest reachable Recall : 0.327\n",
    "- carts\t- Found 181.3K GTs with 36.03M candidates (pos_prop=0.50%)\t-  Highest reachable Recall : 0.314\n",
    "- orders\t- Found 186.38K GTs with 36.03M candidates (pos_prop=0.52%)\t-  Highest reachable Recall : 0.595"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- clicks\t- Found 922.64K (52.56%) GTs with 35.74M candidates (pos_prop=2.58%)\n",
    "- carts\t- Found 236.14K (40.96%) GTs with 32.3M candidates (pos_prop=0.73%)\n",
    "- orders\t- Found 203.32K (64.90%) GTs with 32.3M candidates (pos_prop=0.63%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Val candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_MATRIX = 10\n",
    "MAX_COOC = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = load_parquets(\"../output/val_parquet/*\")\n",
    "# df_val = load_parquets(\"../input/chris/test_parquet/*\")\n",
    "df_val = df_val.sort_values([\"session\", \"ts\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_val = create_candidates(df_val, n_matrix=N_MATRIX, max_cooc=MAX_COOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_candid = df_val[\"candidates\"].apply(len)\n",
    "sns.histplot(np.clip(n_candid, 0, 150))\n",
    "\n",
    "plt.title(f\"Proportion of sessions with <20 candidates : {(n_candid < 20).mean() :.3f}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gt = pd.read_parquet(\"../input/chris/test_labels.parquet\")\n",
    "gt = pd.read_parquet(\"../output/val_labels.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recalls = []\n",
    "for col in CLASSES:\n",
    "    if f\"gt_{col}\" not in df_val.columns:\n",
    "        df_val = df_val.merge(gt[gt[\"type\"] == col].drop(\"type\", axis=1), how=\"left\").rename(\n",
    "            columns={\"ground_truth\": f\"gt_{col}\"}\n",
    "        )\n",
    "\n",
    "    n_preds, n_gts, n_found = get_coverage(\n",
    "        df_val[\"candidates\"].values, df_val[f\"gt_{col}\"].values\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"{col}\\t- Found {numerize(n_found)} GTs with {numerize(n_preds)} candidates (pos_prop={n_found / n_preds * 100 :.2f}%)\\t-  Highest reachable Recall : {n_found / n_gts :.3f}\"\n",
    "    )\n",
    "    recalls.append(n_found / n_gts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = np.average(recalls, weights=WEIGHTS)\n",
    "print(f\"-> Highest reachable CV : {cv:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -> Highest reachable CV : 0.577"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explode & saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = explode(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val.to_parquet(\n",
    "    f\"../output/candidates_val_{int(np.round(cv, 3) * 1000)}.parquet\", index=False\n",
    ")\n",
    "print(f\"Saved to ../output/candidates_val_{int(np.round(cv, 3) * 1000)}.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_val\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Candidates\n",
    "- this is leaky ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = pd.read_parquet(\"../output/train_labels.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = load_parquets(\"../output/train_parquet/*\")\n",
    "df_train = df_train.sort_values([\"session\", \"ts\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_train = create_candidates(df_train, n_matrix=N_MATRIX, max_cooc=MAX_COOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recalls = []\n",
    "for col in CLASSES:\n",
    "    if f\"gt_{col}\" not in df_train.columns:\n",
    "        df_train = df_train.merge(gt[gt[\"type\"] == col].drop(\"type\", axis=1), how=\"left\").rename(\n",
    "            columns={\"ground_truth\": f\"gt_{col}\"}\n",
    "        )\n",
    "\n",
    "    n_preds, n_gts, n_found = get_coverage(\n",
    "        df_train[\"candidates\"].values, df_train[f\"gt_{col}\"].values\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"{col}\\t- Found {numerize(n_found)} GTs with {numerize(n_preds)} candidates (pos_prop={n_found / n_preds * 100 :.2f}%)\\t-  Highest reachable Recall : {n_found / n_gts :.3f}\"\n",
    "    )\n",
    "    recalls.append(n_found / n_gts)\n",
    "    \n",
    "cv_ = np.average(recalls, weights=WEIGHTS)\n",
    "print(f\"\\n-> Highest reachable CV : {cv_:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = explode(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_parquet(\n",
    "    f\"../output/candidates_train_{int(np.round(cv, 3) * 1000)}.parquet\", index=False\n",
    ")\n",
    "print(f\"Saved to ../output/candidates_train_{int(np.round(cv, 3) * 1000)}.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Val cropped candidates\n",
    "- leaky as well !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = pd.read_parquet(\"../output/val_c_labels.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val_c = load_parquets(\"../output/val_c_parquet/*\")\n",
    "df_val_c = df_val_c.sort_values([\"session\", \"ts\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_val_c = create_candidates(df_val_c, n_matrix=N_MATRIX, max_cooc=MAX_COOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recalls = []\n",
    "for col in CLASSES:\n",
    "    if f\"gt_{col}\" not in df_val_c.columns:\n",
    "        df_val_c = df_val_c.merge(gt[gt[\"type\"] == col].drop(\"type\", axis=1), how=\"left\").rename(\n",
    "            columns={\"ground_truth\": f\"gt_{col}\"}\n",
    "        )\n",
    "\n",
    "    n_preds, n_gts, n_found = get_coverage(\n",
    "        df_val_c[\"candidates\"].values, df_val_c[f\"gt_{col}\"].values\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"{col}\\t- Found {numerize(n_found)} GTs with {numerize(n_preds)} candidates (pos_prop={n_found / n_preds * 100 :.2f}%)\\t-  Highest reachable Recall : {n_found / n_gts :.3f}\"\n",
    "    )\n",
    "    recalls.append(n_found / n_gts)\n",
    "    \n",
    "cv_ = np.average(recalls, weights=WEIGHTS)\n",
    "print(f\"\\n-> Highest reachable CV : {cv_:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val_c = explode(df_val_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val_c.to_parquet(\n",
    "    f\"../output/candidates_val_c_{int(np.round(cv, 3) * 1000)}.parquet\", index=False\n",
    ")\n",
    "print(f\"Saved to ../output/candidates_val_c_{int(np.round(cv, 3) * 1000)}.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
