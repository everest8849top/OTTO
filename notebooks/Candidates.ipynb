{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About :** Generates candidates.\n",
    "\n",
    "**TODO**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import cudf\n",
    "import json\n",
    "import glob\n",
    "import pickle\n",
    "import warnings\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "from pandarallel import pandarallel\n",
    "from numerize.numerize import numerize\n",
    "\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "pandarallel.initialize(nb_workers=16, progress_bar=False, use_memory_fs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from params import *\n",
    "\n",
    "from data.covisitation import compute_covisitation_matrix\n",
    "from data.candidates import (\n",
    "    load_parquets,\n",
    "    create_candidates,\n",
    "    explode,\n",
    "    matrix_to_candids_dict,\n",
    ")\n",
    "\n",
    "from utils.metrics import get_coverage\n",
    "from utils.chris import suggest_clicks, suggest_buys, read_file_to_cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODE = \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODE == \"val\":\n",
    "    REGEX = \"../output/val_parquet/*\"\n",
    "elif MODE == \"test\":\n",
    "    REGEX = \"../output/test_parquet/*\"\n",
    "else:\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_cache = {}\n",
    "# for f in tqdm(files):\n",
    "#     data_cache[f] = read_file_to_cache(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ITEM_CT = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MATRIX_FOLDER = \"../output/matrices/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLICKS = True\n",
    "MULTIPLIER = 1\n",
    "\n",
    "if CLICKS:\n",
    "    SUFFIX = \"c-clicks-v3\"  # 50\n",
    "#     SUFFIX = \"c-clicks-v4\"  # 75\n",
    "else:\n",
    "    SUFFIX = \"c-orders-v3\"  # 50\n",
    "    SUFFIX = \"c-orders-v4\"  # 75\n",
    "    SUFFIX = \"c-orders-v5\"  # 50, 1.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_to_candids_dict(matrix):\n",
    "    matrix = matrix.sort_values([\"aid_x\", \"wgt\"], ascending=[True, False])\n",
    "\n",
    "    candids = matrix[[\"aid_x\", \"aid_y\"]].groupby(\"aid_x\").agg(list)\n",
    "\n",
    "    try:\n",
    "        candids = candids.to_pandas()\n",
    "    except AttributeError:\n",
    "        pass\n",
    "\n",
    "    candids[\"aid_y\"] = candids[\"aid_y\"].apply(lambda x: x.tolist())\n",
    "    candids_dict = candids.to_dict()[\"aid_y\"]\n",
    "\n",
    "    return candids_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_parquets(regex):\n",
    "    dfs = []\n",
    "    for e, chunk_file in enumerate(glob.glob(regex)):\n",
    "        chunk = cudf.read_parquet(chunk_file)\n",
    "        chunk[\"d\"] = cudf.to_datetime(chunk.ts * 1e6).dt.day.astype(\"int8\")\n",
    "        chunk.ts = (chunk.ts / 1000).astype(\"int32\")\n",
    "        chunk[\"type\"] = chunk[\"type\"].map(TYPE_LABELS).astype(\"int8\")\n",
    "\n",
    "        dfs.append(chunk)\n",
    "\n",
    "    return (\n",
    "        cudf.concat(dfs).sort_values([\"session\", \"ts\"], ignore_index=True).to_pandas()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gt = cudf.read_parquet(\"../output/val_labels.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gt_clicks = gt[gt[\"type\"] == \"clicks\"].explode(\"ground_truth\")\n",
    "# gt_clicks = gt_clicks.drop(\"type\", axis=1).rename(\n",
    "#     columns={\"ground_truth\": \"candidates\"}\n",
    "# )\n",
    "# gt_clicks[\"gt_clicks\"] = 1\n",
    "# gt_clicks[\"gt_carts\"] = 0\n",
    "# gt_clicks[\"gt_orders\"] = 0\n",
    "\n",
    "# gt_carts = gt[gt[\"type\"] == \"carts\"].explode(\"ground_truth\")\n",
    "# gt_carts = gt_carts.drop(\"type\", axis=1).rename(columns={\"ground_truth\": \"candidates\"})\n",
    "# gt_carts[\"gt_clicks\"] = 0\n",
    "# gt_carts[\"gt_carts\"] = 1\n",
    "# gt_carts[\"gt_orders\"] = 0\n",
    "\n",
    "# gt_orders = gt[gt[\"type\"] == \"orders\"].explode(\"ground_truth\")\n",
    "# gt_orders = gt_orders.drop(\"type\", axis=1).rename(\n",
    "#     columns={\"ground_truth\": \"candidates\"}\n",
    "# )\n",
    "# gt_orders[\"gt_clicks\"] = 0\n",
    "# gt_orders[\"gt_carts\"] = 0\n",
    "# gt_orders[\"gt_orders\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# candidates_gt = cudf.concat([gt_clicks, gt_carts, gt_orders], ignore_index=True)\n",
    "\n",
    "# candidates_gt = (\n",
    "#     candidates_gt.groupby([\"session\", \"candidates\"])\n",
    "#     .max()\n",
    "#     .reset_index()\n",
    "#     .sort_values([\"session\", \"candidates\"])\n",
    "# )\n",
    "\n",
    "# candidates_gt.to_parquet(f\"../output/candidates/candidates_gt.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = load_parquets(REGEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(df_val[\"session\"].unique()) * 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Popular Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_clicks = (\n",
    "    df_val.loc[df_val[\"type\"] == 0, \"aid\"].value_counts().index.values[:100].tolist()\n",
    ")\n",
    "top_carts = (\n",
    "    df_val.loc[df_val[\"type\"] == 1, \"aid\"].value_counts().index.values[:100].tolist()\n",
    ")\n",
    "top_orders = (\n",
    "    df_val.loc[df_val[\"type\"] == 2, \"aid\"].value_counts().index.values[:100].tolist()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_buy2buy = matrix_to_candids_dict(\n",
    "    cudf.read_parquet(MATRIX_FOLDER + f\"matrix_cpu-90_{MODE}.pqt\")\n",
    ")\n",
    "\n",
    "top_20_buy2buy2 = matrix_to_candids_dict(\n",
    "    cudf.read_parquet(MATRIX_FOLDER + f\"matrix_cpu-99_{MODE}.pqt\")\n",
    ")\n",
    "\n",
    "top_20_orders = matrix_to_candids_dict(\n",
    "    cudf.read_parquet(MATRIX_FOLDER + f\"matrix_cpu-95_{MODE}.pqt\")\n",
    ")\n",
    "top_20_carts = top_20_orders\n",
    "\n",
    "top_20_test = matrix_to_candids_dict(\n",
    "    cudf.read_parquet(MATRIX_FOLDER + f\"matrix_gpu-116_{MODE}.pqt\")\n",
    ")\n",
    "\n",
    "top_20_test2 = matrix_to_candids_dict(\n",
    "    cudf.read_parquet(MATRIX_FOLDER + f\"matrix_gpu-115_{MODE}.pqt\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20 = matrix_to_candids_dict(\n",
    "    cudf.read_parquet(MATRIX_FOLDER + f\"matrix_gpu-93_{MODE}.pqt\")\n",
    ")\n",
    "\n",
    "top_20b = matrix_to_candids_dict(\n",
    "    cudf.read_parquet(MATRIX_FOLDER + f\"matrix_gpu-217_{MODE}.pqt\")\n",
    ")\n",
    "\n",
    "top_20c = matrix_to_candids_dict(\n",
    "    cudf.read_parquet(MATRIX_FOLDER + f\"matrix_gpu-220_{MODE}.pqt\")\n",
    ")\n",
    "\n",
    "top_20d = matrix_to_candids_dict(\n",
    "    cudf.read_parquet(MATRIX_FOLDER + f\"matrix_gpu-226_{MODE}.pqt\")\n",
    ")\n",
    "\n",
    "top_20e = matrix_to_candids_dict(\n",
    "    cudf.read_parquet(MATRIX_FOLDER + f\"matrix_gpu-232_{MODE}.pqt\")\n",
    ")\n",
    "\n",
    "top_20f = matrix_to_candids_dict(\n",
    "    cudf.read_parquet(MATRIX_FOLDER + f\"matrix_gpu-235_{MODE}.pqt\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_buy = matrix_to_candids_dict(\n",
    "    cudf.read_parquet(MATRIX_FOLDER + f\"matrix_gpu-239_{MODE}.pqt\")\n",
    ")\n",
    "\n",
    "top_20_new = matrix_to_candids_dict(\n",
    "    cudf.read_parquet(MATRIX_FOLDER + f\"matrix_gpu-700_{MODE}.pqt\")\n",
    ")\n",
    "\n",
    "top_20_new2 = matrix_to_candids_dict(\n",
    "    cudf.read_parquet(MATRIX_FOLDER + f\"matrix_gpu-701_{MODE}.pqt\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chris Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_weight_multipliers = {0: 1, 1: 6, 2: 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def suggest_orders(df, mul=1):\n",
    "    aids = df.aid.tolist()\n",
    "    types = df.type.tolist()\n",
    "    unique_aids = list(dict.fromkeys(aids[::-1]))\n",
    "\n",
    "    mx = df.d.max()\n",
    "    aids2 = df.loc[df.d == mx].aid.tolist()\n",
    "    unique_aids4 = list(dict.fromkeys(aids2[::-1]))\n",
    "\n",
    "    mx = df.ts.max()\n",
    "    aids2 = df.loc[df.ts >= mx - 60 * 60 / 2].aid.tolist()\n",
    "    unique_aids5 = list(dict.fromkeys(aids2[::-1]))  # recent 1 hour\n",
    "\n",
    "    df2 = df.drop_duplicates(\"d\")\n",
    "    aids2 = df2.aid.tolist()\n",
    "    unique_aids2 = list(dict.fromkeys(aids2[::-1]))  # first of each session\n",
    "\n",
    "    df2 = df.sort_values(\"ts\", ascending=False).drop_duplicates(\"d\")\n",
    "    aids2 = df2.aid.tolist()\n",
    "    unique_aids3 = list(dict.fromkeys(aids2))  # last of each session\n",
    "\n",
    "    df = df.loc[df[\"type\"].isin([1, 2])]\n",
    "    unique_buys = list(dict.fromkeys(df.aid.tolist()[::-1]))\n",
    "\n",
    "    if len(unique_aids) >= 20:\n",
    "        weights = np.logspace(0.5, 1, len(aids), base=2, endpoint=True) - 1\n",
    "        aids_temp = Counter()\n",
    "        for aid, w, t in zip(aids, weights, types):\n",
    "            aids_temp[aid] += w * type_weight_multipliers[t]\n",
    "        for aid in unique_aids2:\n",
    "            aids_temp[aid] += 0.5\n",
    "        for aid in unique_aids3:\n",
    "            aids_temp[aid] += 0.5\n",
    "\n",
    "        aids3 = list(\n",
    "            itertools.chain(\n",
    "                *[\n",
    "                    top_20_buy2buy[aid][:int(40 * mul)]\n",
    "                    for aid in unique_buys\n",
    "                    if aid in top_20_buy2buy\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "        for i, aid in enumerate(aids3):\n",
    "            aids_temp[aid] += 0.05\n",
    "            if i % 40 == 0:\n",
    "                aids_temp[aid] += 0.05\n",
    "        aids3 = list(\n",
    "            itertools.chain(\n",
    "                *[\n",
    "                    top_20_buy2buy2[aid][:int(40 * mul)]\n",
    "                    for aid in unique_buys\n",
    "                    if aid in top_20_buy2buy2\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "        for i, aid in enumerate(aids3):\n",
    "            aids_temp[aid] += 0.1\n",
    "            if i % 40 == 0:\n",
    "                aids_temp[aid] += 0.1\n",
    "\n",
    "        aids4 = list(\n",
    "            itertools.chain(\n",
    "                *[top_20_test[aid][:int(40 * mul)] for aid in unique_aids if aid in top_20_test]\n",
    "            )\n",
    "        )\n",
    "        for i, aid in enumerate(aids4):\n",
    "            aids_temp[aid] += 0.05\n",
    "            if i % 40 == 0:\n",
    "                aids_temp[aid] += 0.05\n",
    "        aids5 = list(\n",
    "            itertools.chain(\n",
    "                *[top_20c[aid][:int(20 * mul)] for aid in unique_aids[:1] if aid in top_20c]\n",
    "            )\n",
    "        )\n",
    "        for i, aid in enumerate(aids5):\n",
    "            aids_temp[aid] += 0.05\n",
    "            if i % 20 == 0:\n",
    "                aids_temp[aid] += 0.05\n",
    "        aids6 = list(\n",
    "            itertools.chain(\n",
    "                *[top_20d[aid][:int(20 * mul)] for aid in unique_buys[:1] if aid in top_20d]\n",
    "            )\n",
    "        )\n",
    "        for i, aid in enumerate(aids6):\n",
    "            aids_temp[aid] += 0.05\n",
    "            if i % 20 == 0:\n",
    "                aids_temp[aid] += 0.05\n",
    "\n",
    "        aids7 = list(\n",
    "            itertools.chain(\n",
    "                *[top_20b[aid][:int(5 * mul)] for aid in unique_aids3 if aid in top_20b]\n",
    "            )\n",
    "        )\n",
    "        for i, aid in enumerate(aids7):\n",
    "            aids_temp[aid] += 0.25\n",
    "            if i % 5 == 0:\n",
    "                aids_temp[aid] += 0.25\n",
    "        aids7 = list(\n",
    "            itertools.chain(\n",
    "                *[top_20b[aid][:int(5 * mul)] for aid in unique_aids2 if aid in top_20b]\n",
    "            )\n",
    "        )\n",
    "        for i, aid in enumerate(aids7):\n",
    "            aids_temp[aid] += 0.125\n",
    "            if i % 5 == 0:\n",
    "                aids_temp[aid] += 0.125\n",
    "\n",
    "        result = [k for k, v in aids_temp.most_common(ITEM_CT)]\n",
    "\n",
    "        if len(result) < 1:\n",
    "            result += top_orders[: 20 - len(result)]\n",
    "\n",
    "        return result[:ITEM_CT]\n",
    "\n",
    "    weights = [2, 2] + [1] * 8  # + [0]*30\n",
    "    weights2 = [2, 2] + [1] * 53  # + [0]*25\n",
    "    weights3 = [2, 2] + [1] * 18  # + [0]*70\n",
    "    weights4 = [2, 2] + [1] * 38  # + [0]*70\n",
    "\n",
    "    ln = len(unique_aids)\n",
    "\n",
    "    aids_temp = Counter()\n",
    "    aids2 = list(\n",
    "        itertools.chain(\n",
    "            *[top_20_orders[aid][:int(10 * mul)] for aid in unique_aids if aid in top_20_orders]\n",
    "        )\n",
    "    )\n",
    "    w2 = weights * int(len(aids2) // 10)\n",
    "    aids3 = list(\n",
    "        itertools.chain(\n",
    "            *[top_20_buy2buy[aid][:int(10 * mul)] for aid in unique_buys if aid in top_20_buy2buy]\n",
    "        )\n",
    "    )\n",
    "    w3 = weights * int(len(aids3) // 10)\n",
    "    aids4 = list(\n",
    "        itertools.chain(\n",
    "            *[top_20_test[aid][:int(10 * mul)] for aid in unique_aids if aid in top_20_test]\n",
    "        )\n",
    "    )\n",
    "    w4 = weights * int(len(aids4) // 10)\n",
    "    aids5 = list(\n",
    "        itertools.chain(\n",
    "            *[\n",
    "                top_20_buy2buy2[aid][:int(10 * mul)]\n",
    "                for aid in unique_buys\n",
    "                if aid in top_20_buy2buy2\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "    w5 = weights * int(len(aids5) // 10)\n",
    "    for i, (aid, w) in enumerate(zip(aids2, w2)):\n",
    "        m = 0.25 + 0.75 * (ln - (i // 10)) / ln\n",
    "        aids_temp[aid] += w * m\n",
    "    for i, (aid, w) in enumerate(zip(aids3, w3)):\n",
    "        aids_temp[aid] += w / 2\n",
    "    for i, (aid, w) in enumerate(zip(aids4, w4)):\n",
    "        m = 0.25 + 0.75 * (ln - (i // 10)) / ln\n",
    "        aids_temp[aid] += w * m\n",
    "    for i, (aid, w) in enumerate(zip(aids5, w5)):\n",
    "        aids_temp[aid] += w / 2\n",
    "\n",
    "    aids5 = list(\n",
    "        itertools.chain(\n",
    "            *[top_20c[aid][:55] for aid in unique_aids[:1] if aid in top_20c]\n",
    "        )\n",
    "    )\n",
    "    w5 = weights2 * int(len(aids5) // 55)\n",
    "    for aid, w in zip(aids5, w5):\n",
    "        aids_temp[aid] += w\n",
    "\n",
    "    # NEW\n",
    "    if len(unique_aids) == 1:\n",
    "        aids5 = list(\n",
    "            itertools.chain(\n",
    "                *[\n",
    "                    top_20_new2[aid][:int(20 * mul)]\n",
    "                    for aid in unique_aids[-1:]\n",
    "                    if aid in top_20_new2\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "        w5 = weights3 * int(len(aids5) // 20)\n",
    "        for aid, w in zip(aids5, w5):\n",
    "            aids_temp[aid] += w\n",
    "        aids5 = list(\n",
    "            itertools.chain(\n",
    "                *[top_20_new[aid][:int(20 * mul)] for aid in unique_aids[-1:] if aid in top_20_new]\n",
    "            )\n",
    "        )\n",
    "        w5 = weights3 * int(len(aids5) // 20)\n",
    "        for aid, w in zip(aids5, w5):\n",
    "            aids_temp[aid] += w\n",
    "\n",
    "    aids5 = list(\n",
    "        itertools.chain(\n",
    "            *[top_20d[aid][:int(20 * mul)] for aid in unique_buys[:1] if aid in top_20d]\n",
    "        )\n",
    "    )\n",
    "    w5 = weights3 * int(len(aids5) // 20)\n",
    "    for aid, w in zip(aids5, w5):\n",
    "        aids_temp[aid] += w\n",
    "\n",
    "    ln2 = len(unique_aids5)\n",
    "    aids5 = list(\n",
    "        itertools.chain(\n",
    "            *[top_20_buy[aid][:int(20 * mul)] for aid in unique_aids5 if aid in top_20_buy]\n",
    "        )\n",
    "    )\n",
    "    w5 = weights3 * int(len(aids5) // 20)\n",
    "    for aid, w in zip(aids5, w5):\n",
    "        aids_temp[aid] += 2 * w / ln2\n",
    "\n",
    "    aids4 = list(\n",
    "        itertools.chain(*[top_20f[aid][:int(5 * mul)] for aid in unique_aids4 if aid in top_20f])\n",
    "    )\n",
    "    for i, aid in enumerate(aids4):\n",
    "        w = i // 5\n",
    "        aids_temp[aid] += 1 / 2 - w * 0.05\n",
    "        if i % 5 == 0:\n",
    "            aids_temp[aid] += 1 / 2 - w * 0.05\n",
    "    aids5 = list(\n",
    "        itertools.chain(*[top_20e[aid][:55] for aid in unique_aids3 if aid in top_20e])\n",
    "    )\n",
    "    w5 = weights2 * int(len(aids5) // 55)\n",
    "    for i, (aid, w) in enumerate(zip(aids5, w5)):\n",
    "        w2 = i // 55\n",
    "        aids_temp[aid] += w - w2 * 0.1\n",
    "    aids5 = list(\n",
    "        itertools.chain(*[top_20e[aid][:int(10 * mul)] for aid in unique_aids2 if aid in top_20e])\n",
    "    )\n",
    "    w5 = weights * int(len(aids5) // 10)\n",
    "    for i, (aid, w) in enumerate(zip(aids5, w5)):\n",
    "        w2 = i // 10\n",
    "        aids_temp[aid] += w / 2.0 - w2 * 0.05\n",
    "\n",
    "    sorted_aids = [k for k, v in aids_temp.most_common(ITEM_CT) if k not in unique_aids]\n",
    "\n",
    "    result = unique_aids + sorted_aids[: ITEM_CT - len(unique_aids)]\n",
    "\n",
    "    if len(result) < 1:\n",
    "        result += top_orders[: 20 - len(result)]\n",
    "\n",
    "    return result[:ITEM_CT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def suggest_clicks(df):\n",
    "    aids = df.aid.tolist()\n",
    "    types = df.type.tolist()\n",
    "    unique_aids = list(dict.fromkeys(aids[::-1]))\n",
    "\n",
    "    df2 = df.sort_values(\"ts\", ascending=False).drop_duplicates(\"d\")\n",
    "    aids2 = df2.aid.tolist()\n",
    "    unique_aids3 = list(dict.fromkeys(aids2[::-1]))  # last of each session\n",
    "\n",
    "    mx = df.d.max()\n",
    "    aids2 = df.loc[df.d == mx].aid.tolist()\n",
    "    unique_aids4 = list(dict.fromkeys(aids2[::-1]))\n",
    "\n",
    "    df = df.loc[df[\"type\"].isin([1, 2])]\n",
    "    unique_buys = list(dict.fromkeys(df.aid.tolist()[::-1]))\n",
    "\n",
    "    ln = len(unique_aids)\n",
    "\n",
    "    if len(unique_aids) >= 15:\n",
    "        weights = np.logspace(0.1, 1, len(aids), base=2, endpoint=True) - 1\n",
    "        aids_temp = Counter()\n",
    "        for aid, w, t in zip(aids, weights, types):\n",
    "            aids_temp[aid] += w * type_weight_multipliers[t]\n",
    "        aids3 = list(\n",
    "            itertools.chain(\n",
    "                *[top_20c[aid][:40] for aid in unique_aids[:2] if aid in top_20c]\n",
    "            )\n",
    "        )\n",
    "        for i, aid in enumerate(aids3):\n",
    "            aids_temp[aid] += 0.6\n",
    "        aids3 = list(\n",
    "            itertools.chain(\n",
    "                *[top_20b[aid][:30] for aid in unique_aids3 if aid in top_20b]\n",
    "            )\n",
    "        )\n",
    "        for i, aid in enumerate(aids3):\n",
    "            aids_temp[aid] += 0.3\n",
    "        aids3 = list(\n",
    "            itertools.chain(\n",
    "                *[\n",
    "                    top_20_test2[aid][:40]\n",
    "                    for aid in unique_aids[:2]\n",
    "                    if aid in top_20_test2\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "        for i, aid in enumerate(aids3):\n",
    "            aids_temp[aid] += 0.6\n",
    "\n",
    "        result = [k for k, v in aids_temp.most_common(ITEM_CT)]\n",
    "\n",
    "        if len(result) < 1:\n",
    "            result += top_clicks[: 20 - len(result)]\n",
    "        return result[:ITEM_CT]\n",
    "    #         return (result + top_clicks[: ITEM_CT - len(result)])[:ITEM_CT]\n",
    "    # return sorted_aids\n",
    "\n",
    "    aids_temp = Counter()\n",
    "\n",
    "    # NEW\n",
    "    weights3 = [2, 2] + [1] * 28\n",
    "    if len(unique_aids) == 1:\n",
    "        aids5 = list(\n",
    "            itertools.chain(\n",
    "                *[\n",
    "                    top_20_new2[aid][:60]\n",
    "                    for aid in unique_aids[-1:]\n",
    "                    if aid in top_20_new2\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "        w5 = weights3 * int(len(aids5) // 30)\n",
    "        for aid, w in zip(aids5, w5):\n",
    "            aids_temp[aid] += w\n",
    "\n",
    "    aids2 = list(\n",
    "        itertools.chain(*[top_20[aid][:40] for aid in unique_aids if aid in top_20])\n",
    "    )\n",
    "    for i, aid in enumerate(aids2):\n",
    "        m = 0.1 + 0.9 * (ln - (i // 20)) / ln\n",
    "        aids_temp[aid] += m\n",
    "        if i % 20 == 0:\n",
    "            aids_temp[aid] += m\n",
    "\n",
    "    aids3 = list(\n",
    "        itertools.chain(\n",
    "            *[top_20b[aid][:40] for aid in unique_aids[:2] if aid in top_20b]\n",
    "        )\n",
    "    )\n",
    "    for i, aid in enumerate(aids3):\n",
    "        aids_temp[aid] += 1\n",
    "        if i % 20 == 0:\n",
    "            aids_temp[aid] += 1\n",
    "\n",
    "    aids3 = list(\n",
    "        itertools.chain(\n",
    "            *[top_20_test2[aid][:40] for aid in unique_aids[:2] if aid in top_20_test2]\n",
    "        )\n",
    "    )\n",
    "    for i, aid in enumerate(aids3):\n",
    "        aids_temp[aid] += 1\n",
    "        if i % 20 == 0:\n",
    "            aids_temp[aid] += 1\n",
    "\n",
    "    aids4 = list(\n",
    "        itertools.chain(*[top_20f[aid][:20] for aid in unique_aids4 if aid in top_20f])\n",
    "    )\n",
    "    for i, aid in enumerate(aids4):\n",
    "        w = i // 10\n",
    "        aids_temp[aid] += 1 - w * 0.1\n",
    "        if i % 10 == 0:\n",
    "            aids_temp[aid] += 1 - w * 0.1\n",
    "\n",
    "    aids5 = list(\n",
    "        itertools.chain(*[top_20e[aid][:40] for aid in unique_aids3 if aid in top_20e])\n",
    "    )\n",
    "    for i, aid in enumerate(aids5):\n",
    "        aids_temp[aid] += 1\n",
    "        if i % 20 == 0:\n",
    "            aids_temp[aid] += 1\n",
    "    top_aids2 = [k for k, v in aids_temp.most_common(1) if k not in unique_aids]\n",
    "\n",
    "    aids3 = list(\n",
    "        itertools.chain(*[top_20c[aid][:20] for aid in top_aids2 if aid in top_20c])\n",
    "    )\n",
    "    for i, aid in enumerate(aids3):\n",
    "        aids_temp[aid] += 1\n",
    "        if i % 10 == 0:\n",
    "            aids_temp[aid] += 1\n",
    "    top_aids2 = [k for k, v in aids_temp.most_common(ITEM_CT) if k not in unique_aids]\n",
    "    \n",
    "    \n",
    "\n",
    "    result = unique_aids + top_aids2[: ITEM_CT - len(unique_aids)]\n",
    "    #     return (result + top_clicks[: ITEM_CT - len(result)])[:ITEM_CT]\n",
    "\n",
    "    \n",
    "    if len(result) < 1:\n",
    "        result += top_clicks[: 20 - len(result)]\n",
    "\n",
    "    return result[:ITEM_CT]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val[\"chunk\"] = df_val[\"session\"] // 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "preds = []\n",
    "pbar = tqdm(df_val.groupby(\"chunk\"), total=len(df_val[\"chunk\"].unique()))\n",
    "\n",
    "for i, (_, dfg) in enumerate(pbar):\n",
    "    pbar.set_description(f\"Chunk size {len(dfg)}\")\n",
    "    \n",
    "    if CLICKS:\n",
    "        pred_df = dfg.groupby([\"session\"]).parallel_apply(\n",
    "            lambda x: suggest_clicks(x)\n",
    "        )\n",
    "    else:\n",
    "        pred_df = dfg.groupby([\"session\"]).parallel_apply(\n",
    "            lambda x: suggest_orders(x, mul=MULTIPLIER)\n",
    "        )\n",
    "    preds.append(pred_df)\n",
    "    \n",
    "#     if i > 2:\n",
    "#         break\n",
    "    \n",
    "pred_df = pd.concat(preds)\n",
    "\n",
    "del preds\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clicks_pred_df = pd.DataFrame(pred_df.add_suffix(\"_clicks\"), columns=[\"labels\"]).reset_index()\n",
    "orders_pred_df = pd.DataFrame(pred_df.add_suffix(\"_orders\"), columns=[\"labels\"]).reset_index()\n",
    "carts_pred_df = pd.DataFrame(pred_df.add_suffix(\"_carts\"), columns=[\"labels\"]).reset_index()\n",
    "\n",
    "pred_df = pd.concat([clicks_pred_df, orders_pred_df, carts_pred_df], ignore_index=True)\n",
    "pred_df.columns = [\"session_type\", \"labels_l\"]\n",
    "pred_df[\"labels\"] = pred_df[\"labels_l\"].apply(lambda x: \" \".join(map(str, x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODE != \"test\":\n",
    "    gt = pd.read_parquet(\"../output/val_labels.parquet\")\n",
    "\n",
    "    recs = []\n",
    "    df_pred = pred_df[[\"session_type\", \"labels_l\"]].copy()\n",
    "    df_pred.columns = [\"session_type\", \"candidates\"]\n",
    "    df_pred[\"session\"] = (\n",
    "        df_pred[\"session_type\"].apply(lambda x: x.split(\"_\")[0]).astype(int)\n",
    "    )\n",
    "    df_pred[\"type\"] = df_pred[\"session_type\"].apply(lambda x: x.split(\"_\")[1])\n",
    "\n",
    "    df_pred = df_pred.merge(gt, on=[\"session\", \"type\"], how=\"left\")\n",
    "\n",
    "    for col in CLASSES:\n",
    "        df_pred_c = df_pred[df_pred[\"type\"] == col]\n",
    "\n",
    "        n_preds, n_gts, n_found = get_coverage(\n",
    "            df_pred_c[\"candidates\"].values, df_pred_c[\"ground_truth\"].values\n",
    "        )\n",
    "        print(\n",
    "            f\"- {col} \\t- Found {numerize(n_found)} GTs with {numerize(n_preds)} candidates (pos_prop={n_found / n_preds * 100 :.2f}%)\\t-  Highest reachable Recall : {n_found / n_gts :.4f}\"\n",
    "        )\n",
    "\n",
    "        recs.append(n_found / n_gts)\n",
    "\n",
    "    cv = np.average(recs, weights=WEIGHTS)\n",
    "    print(f\"\\n-> CV : {cv:.4f}\")\n",
    "\n",
    "    del clicks_pred_df, orders_pred_df, carts_pred_df, df_pred\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 20\n",
    " - clicks \t- Found 908.67K GTs with 36.03M candidates (pos_prop=2.52%)\t-  Highest reachable Recall : 0.5405 (bad)\n",
    " - carts \t- Found 245.23K GTs with 36.03M candidates (pos_prop=0.68%)\t-  Highest reachable Recall : 0.4257\n",
    " - orders \t- Found 206.18K GTs with 36.03M candidates (pos_prop=0.57%)\t-  Highest reachable Recall : 0.6582\n",
    "- 50\n",
    " - clicks \t- Found 1.09M GTs with 89.62M candidates (pos_prop=1.21%)\t-  Highest reachable Recall : 0.6191  (recomputed)\n",
    " - carts \t- Found 275.95K GTs with 87.44M candidates (pos_prop=0.32%)\t-  Highest reachable Recall : 0.4790\n",
    " - orders \t- Found 216.38K GTs with 87.44M candidates (pos_prop=0.25%)\t-  Highest reachable Recall : 0.6908\n",
    "- 75\n",
    " - clicks \t- Found 1.11M GTs with 127.24M candidates (pos_prop=0.87%)\t-  Highest reachable Recall : 0.6317 (bad)\n",
    " - carts \t- Found 287.71K GTs with 127.24M candidates (pos_prop=0.23%)\t-  Highest reachable Recall : 0.4995\n",
    " - orders \t- Found 220.08K GTs with 127.24M candidates (pos_prop=0.17%)\t-  Highest reachable Recall : 0.7026"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_candids = pred_df[[\"session_type\", \"labels_l\"]].copy()\n",
    "df_candids.columns = [\"session\", \"candidates\"]\n",
    "df_candids['session'] = df_candids['session'].apply(lambda x: x.split('_')[0]).astype(\"int32\")\n",
    "df_candids = df_candids.drop_duplicates(keep='first', subset='session').reset_index(drop=True)\n",
    "df_candids = df_candids.sort_values('session', ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODE != \"test\":\n",
    "    gt = pd.read_parquet(f\"../output/{MODE}_labels.parquet\")\n",
    "    gt[\"ground_truth\"] = gt[\"ground_truth\"].apply(lambda x: x.tolist())\n",
    "\n",
    "    for col in CLASSES:\n",
    "        if f\"gt_{col}\" not in df_candids.columns:\n",
    "            df_candids = df_candids.merge(\n",
    "                gt[gt[\"type\"] == col].drop(\"type\", axis=1), how=\"left\"\n",
    "            ).rename(columns={\"ground_truth\": f\"gt_{col}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explode(df, test=False):\n",
    "    if \"aid\" in df.columns:\n",
    "        df.drop([\"aid\", \"type\"], axis=1, inplace=True)\n",
    "\n",
    "    df = cudf.from_pandas(df)\n",
    "    df = df.explode(\"candidates\")\n",
    "    df = df.drop_duplicates(keep=\"first\", subset=[\"session\", \"candidates\"])\n",
    "\n",
    "    df[\"candidates\"] = df[\"candidates\"].astype(\"uint32\")\n",
    "    df[\"session\"] = df[\"session\"].astype(\"uint32\")\n",
    "\n",
    "    df = df.sort_values([\"session\", \"candidates\"]).reset_index(drop=True)\n",
    "\n",
    "    if not test:\n",
    "        for col in [\"gt_clicks\", \"gt_carts\", \"gt_orders\"]:\n",
    "            df_tgt = (\n",
    "                df[[\"session\", \"candidates\", col]].explode(col).reset_index(drop=True)\n",
    "            ).fillna(-1)\n",
    "            df_tgt[col] = df_tgt[col].astype(\"int64\") == df_tgt[\"candidates\"].astype(\n",
    "                \"int64\"\n",
    "            )\n",
    "\n",
    "            assert not df_tgt.isna().any().max()\n",
    "\n",
    "            df_tgt = df_tgt.groupby([\"session\", \"candidates\"]).max().reset_index()\n",
    "            df_tgt = df_tgt.sort_values([\"session\", \"candidates\"]).reset_index(\n",
    "                drop=True\n",
    "            )\n",
    "\n",
    "            assert not df_tgt.isna().any().max()\n",
    "\n",
    "            df[col] = df_tgt[col].astype(\"uint8\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_candids = explode(df_candids, test=(MODE == \"test\"))\n",
    "\n",
    "df_candids.to_parquet(\n",
    "    f\"../output/candidates/candidates_{SUFFIX}_{MODE}.parquet\", index=False\n",
    ")\n",
    "print(f\"Saved to ../output/candidates/candidates_{SUFFIX}_{MODE}.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theo's version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODE = \"val\"\n",
    "SUFFIX = \"v5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_MATRIX = 20\n",
    "MAX_COOC = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODE == \"val\":\n",
    "    PARQUET_FILES = \"../output/val_parquet/*\"\n",
    "elif MODE == \"test\":\n",
    "    PARQUET_FILES = \"../output/test_parquet/*\"\n",
    "else:\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_parquets(PARQUET_FILES)\n",
    "df = df.sort_values([\"session\", \"ts\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.candidates import (\n",
    "    load_parquets,\n",
    "    create_candidates,\n",
    "    explode,\n",
    "    matrix_to_candids_dict,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clicks_candids = matrix_to_candids_dict(\n",
    "    cudf.read_parquet(f\"../output/matrices/matrix_123_temporal_{N_MATRIX}_{MODE}.pqt\")\n",
    ")\n",
    "type_weighted_candids = matrix_to_candids_dict(\n",
    "    cudf.read_parquet(\n",
    "        f\"../output/matrices/matrix_123_type0.590.5_{N_MATRIX}_{MODE}.pqt\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df = create_candidates(df, clicks_candids, type_weighted_candids, max_cooc=MAX_COOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del clicks_candids, type_weighted_candids\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODE != \"test\":\n",
    "    recalls = []\n",
    "    gt = pd.read_parquet(f\"../output/val_labels.parquet\")\n",
    "\n",
    "    for col in CLASSES:\n",
    "        if f\"gt_{col}\" not in df.columns:\n",
    "            df = df.merge(\n",
    "                gt[gt[\"type\"] == col].drop(\"type\", axis=1), how=\"left\"\n",
    "            ).rename(columns={\"ground_truth\": f\"gt_{col}\"})\n",
    "\n",
    "        n_preds, n_gts, n_found = get_coverage(\n",
    "            df[\"candidates\"].values, df[f\"gt_{col}\"].values\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            f\"- {col} \\t- Found {numerize(n_found)} GTs with {numerize(n_preds)} candidates (pos_prop={n_found / n_preds * 100 :.2f}%)\\t-  Highest reachable Recall : {n_found / n_gts :.4f}\"\n",
    "        )\n",
    "        recalls.append(n_found / n_gts)\n",
    "\n",
    "    cv = np.average(recalls, weights=WEIGHTS)\n",
    "    print(f\"\\n-> Highest reachable CV : {cv:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- clicks \t- Found 1.02M GTs with 89.04M candidates (pos_prop=1.14%)\t-  Highest reachable Recall : 0.5806\n",
    "- carts \t- Found 277.39K GTs with 89.04M candidates (pos_prop=0.31%)\t-  Highest reachable Recall : 0.4816\n",
    "- orders \t- Found 217.5K GTs with 89.04M candidates (pos_prop=0.24%)\t-  Highest reachable Recall : 0.6944\n",
    "\n",
    "-> Highest reachable CV : 0.619"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explode & saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = explode(df, test=(MODE == \"test\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(f\"../output/candidates/candidates_{SUFFIX}_{MODE}.parquet\", index=False)\n",
    "print(f\"Saved to ../output/candidates/candidates_{SUFFIX}_{MODE}.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blend Candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODE = \"val\"\n",
    "CLICKS = True\n",
    "\n",
    "SUFFIX = \"cv3-tv5\"\n",
    "\n",
    "if CLICKS:\n",
    "    SUFFIX = \"clicks_\" + SUFFIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CLICKS:\n",
    "    chris_candids = cudf.read_parquet(\n",
    "        f\"../output/candidates/candidates_c-clicks-v3_{MODE}.parquet\"\n",
    "    )\n",
    "else:\n",
    "    chris_candids = cudf.read_parquet(\n",
    "        f\"../output/candidates/candidates_c-orders-v3_{MODE}.parquet\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theo_candids = cudf.read_parquet(f\"../output/candidates/candidates_v5_{MODE}.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candids = (\n",
    "    cudf.concat([chris_candids, theo_candids])\n",
    "    .drop_duplicates(keep=\"first\", subset=[\"session\", \"candidates\"])\n",
    "    .reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candids.to_parquet(\n",
    "    f\"../output/candidates/candidates_{SUFFIX}_{MODE}.parquet\", index=False\n",
    ")\n",
    "print(f\"Saved to ../output/candidates/candidates_{SUFFIX}_{MODE}.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODE != \"test\":\n",
    "    df = candids[[\"session\", \"candidates\"]].groupby(\"session\").agg(list)\n",
    "    df = df.reset_index().to_pandas()\n",
    "\n",
    "    recalls = []\n",
    "    gt = pd.read_parquet(f\"../output/val_labels.parquet\")\n",
    "\n",
    "    for col in CLASSES:\n",
    "        if f\"gt_{col}\" not in df.columns:\n",
    "            df = df.merge(\n",
    "                gt[gt[\"type\"] == col].drop(\"type\", axis=1), how=\"left\"\n",
    "            ).rename(columns={\"ground_truth\": f\"gt_{col}\"})\n",
    "\n",
    "        n_preds, n_gts, n_found = get_coverage(\n",
    "            df[\"candidates\"].values, df[f\"gt_{col}\"].values\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            f\"- {col} \\t- Found {numerize(n_found)} GTs with {numerize(n_preds)} candidates (pos_prop={n_found / n_preds * 100 :.2f}%)\\t-  Highest reachable Recall : {n_found / n_gts :.4f}\"\n",
    "        )\n",
    "        recalls.append(n_found / n_gts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clicks Chris v3 + Theo v5**\n",
    "- clicks \t- Found 1.12M GTs with 129M candidates (pos_prop=0.87%)\t-  Highest reachable Recall : **0.6361**\n",
    "- carts \t- Found 293.98K GTs with 129M candidates (pos_prop=0.23%)\t-  Highest reachable Recall : **0.5104**\n",
    "- orders \t- Found 222.29K GTs with 129M candidates (pos_prop=0.17%)\t-  Highest reachable Recall : **0.7097**\n",
    "\n",
    "**Chris v3 + Theo v5**\n",
    "- clicks\t- Found 1.11M GTs with 128.42M candidates (pos_prop=0.86%)\t-  Highest reachable Recall : 0.6298\n",
    "- carts\t- Found 292.58K GTs with 128.42M candidates (pos_prop=0.23%)\t-  Highest reachable Recall : 0.5079\n",
    "- orders\t- Found 222.05K GTs with 128.42M candidates (pos_prop=0.17%)\t-  Highest reachable Recall : 0.7089\n",
    "\n",
    "**Chris v4 + Theo v5**\n",
    "- clicks \t- Found 1.14M GTs with 161.5M candidates (pos_prop=0.70%)\t-  Highest reachable Recall : 0.6471\n",
    "- carts \t- Found 299.54K GTs with 161.5M candidates (pos_prop=0.19%)\t-  Highest reachable Recall : 0.5200\n",
    "- orders \t- Found 224.13K GTs with 161.5M candidates (pos_prop=0.14%)\t-  Highest reachable Recall : 0.7155"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
