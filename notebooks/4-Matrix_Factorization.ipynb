{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About :** Computes matrix factorization embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import cudf\n",
    "import json\n",
    "import glob\n",
    "import pickle\n",
    "import warnings\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "from numerize.numerize import numerize\n",
    "\n",
    "from merlin.io import Dataset\n",
    "from torch.optim import SparseAdam\n",
    "from merlin.loader.torch import Loader\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from params import *\n",
    "\n",
    "from utils.load import load_sessions\n",
    "from utils.metrics import get_coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODE = \"val\"\n",
    "NO_CLICKS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODE == \"val\":\n",
    "    files = glob.glob(\"../output/full_train_parquet/*\") + glob.glob(\n",
    "        \"../output/val_parquet/*\"\n",
    "    )\n",
    "elif MODE == \"test\":\n",
    "    files = glob.glob(\"../output/full_train_val_parquet/*\") + glob.glob(\n",
    "        \"../output/test_parquet/*\"\n",
    "    )\n",
    "else:\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pairs = cudf.concat([cudf.read_parquet(f) for f in files], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if NO_CLICKS:\n",
    "    train_pairs = train_pairs[train_pairs['type'] != \"clicks\"].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single shift\n",
    "\n",
    "SHIFT = 1  # this can be modified\n",
    "SHIFTS = None\n",
    "\n",
    "train_pairs['aid_next'] = train_pairs.groupby('session').aid.shift(-1 * SHIFT)\n",
    "train_pairs = train_pairs[['aid', 'aid_next']].dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Several Shifts \n",
    "\n",
    "# SHIFTS =  [1, 2, 3, 4, 5]  # this can be modified\n",
    "# SHIFT = \"1-5\"  # this can be modified\n",
    "\n",
    "# train_pairs_ = []\n",
    "\n",
    "# for shift in tqdm(SHIFTS):\n",
    "#     train_pairs['aid_next'] = train_pairs.groupby('session').aid.shift(-1 * shift)\n",
    "#     train_pairs_.append(train_pairs[['aid', 'aid_next']].dropna().reset_index(drop=True).to_pandas())\n",
    "\n",
    "# train_pairs = cudf.from_pandas(pd.concat(train_pairs_, ignore_index=True).drop_duplicates(keep=\"first\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of pairs', numerize(len(train_pairs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pairs.to_pandas().to_parquet(\n",
    "    f\"../output/matrix_factorization/{MODE}_pairs.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pairs.tail(10_000_000).to_parquet(\n",
    "    f\"../output/matrix_factorization/{MODE}_pairs_val.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class MatrixFactorization(nn.Module):\n",
    "    def __init__(self, n_aids, n_factors):\n",
    "        super().__init__()\n",
    "        self.aid_factors = nn.Embedding(n_aids, n_factors, sparse=True)\n",
    "\n",
    "    def forward(self, aid1, aid2):\n",
    "        aid1 = self.aid_factors(aid1)\n",
    "        aid2 = self.aid_factors(aid2)\n",
    "\n",
    "        return (aid1 * aid2).sum(dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self, name, fmt=\":f\"):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = \"{name} {val\" + self.fmt + \"} ({avg\" + self.fmt + \"})\"\n",
    "        return fmtstr.format(**self.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = Dataset(f\"../output/matrix_factorization/{MODE}_pairs.parquet\")\n",
    "train_dl_merlin = Loader(train_ds, 65536, True)\n",
    "\n",
    "valid_ds = Dataset(f\"../output/matrix_factorization/{MODE}_pairs_val.parquet\")\n",
    "valid_dl_merlin = Loader(valid_ds, 65536, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM = 64\n",
    "\n",
    "N_AIDS = 1855602\n",
    "EPOCHS = 20\n",
    "LR = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MatrixFactorization(N_AIDS + 1, DIM)\n",
    "model.to(\"cuda\")\n",
    "\n",
    "optimizer = SparseAdam(model.parameters(), lr=LR)\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, EPOCHS + 1):\n",
    "    for batch, _ in train_dl_merlin:\n",
    "        model.train()\n",
    "        losses = AverageMeter(\"Loss\", \":.4e\")\n",
    "\n",
    "        aid1, aid2 = batch[\"aid\"], batch[\"aid_next\"]\n",
    "        aid1 = aid1.to(\"cuda\")\n",
    "        aid2 = aid2.to(\"cuda\")\n",
    "        output_pos = model(aid1, aid2)\n",
    "        output_neg = model(aid1, aid2[torch.randperm(aid2.shape[0])])\n",
    "\n",
    "        output = torch.cat([output_pos, output_neg])\n",
    "        targets = torch.cat([torch.ones_like(output_pos), torch.zeros_like(output_pos)])\n",
    "        loss = criterion(output, targets)\n",
    "        losses.update(loss.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        accuracy = AverageMeter(\"accuracy\")\n",
    "        for batch, _ in valid_dl_merlin:\n",
    "            aid1, aid2 = batch[\"aid\"], batch[\"aid_next\"]\n",
    "            output_pos = model(aid1, aid2)\n",
    "            output_neg = model(aid1, aid2[torch.randperm(aid2.shape[0])])\n",
    "            accuracy_batch = (\n",
    "                torch.cat([output_pos.sigmoid() > 0.5, output_neg.sigmoid() < 0.5])\n",
    "                .float()\n",
    "                .mean()\n",
    "            )\n",
    "            accuracy.update(accuracy_batch, aid1.shape[0])\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch:02d}/{EPOCHS} \\t loss={losses.avg:.3f} \\t val_acc={accuracy.avg:.3f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model.aid_factors.weight.detach().cpu().numpy().astype(\"float32\")\n",
    "\n",
    "name = f\"embed_{SHIFT}_{DIM}{'_cartbuy' if NO_CLICKS else ''}_{MODE}.npy\"\n",
    "np.save(f\"../output/matrix_factorization/{name}\", embeddings)\n",
    "\n",
    "print(\n",
    "    f\"Saved matrix of shape {embeddings.shape} to\",\n",
    "    f\"../output/matrix_factorization/{name}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done !"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "f7241b2af102f7e024509099765066b36197b195077f7bfac6e5bc041ba17c8c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
