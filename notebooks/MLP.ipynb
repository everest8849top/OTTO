{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About :** Trains XGBoost models.\n",
    "\n",
    "**TODO**:\n",
    "- Tweak pos prop, lr, bs, model size\n",
    "- change arch\n",
    "- retrain fullfit for test ? or other folds ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/kaggle_otto_rs/src\n"
     ]
    }
   ],
   "source": [
    "cd ../src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 32 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import cudf\n",
    "import json\n",
    "import glob\n",
    "import numba\n",
    "import xgboost\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pandarallel import pandarallel\n",
    "from numerize.numerize import numerize\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "pd.options.display.max_columns = 500\n",
    "pd.options.display.max_rows = 500\n",
    "pandarallel.initialize(nb_workers=32, progress_bar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from params import *\n",
    "\n",
    "from data.dataset import FeaturesDataset\n",
    "from model_zoo.mlp import define_model\n",
    "from training.mlp import train\n",
    "\n",
    "from utils.load import *\n",
    "from utils.metrics import get_coverage\n",
    "from utils.logger import save_config, prepare_log_folder, create_logger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = \"c-orders-v4.7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = \"gt_*\"   # \"gt_clicks\", \"gt_carts\", \"gt_orders\", \"gt_*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "POS_RATIO = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = [  # REMOVE CORRELATED\n",
    "    'clicks_popularity_w_pos-log', 'clicks_popularity_w_type-163', 'clicks_popularity_w_lastday', 'clicks_popularity_w_recsys', \n",
    "    'carts_popularity_w_pos-log', 'carts_popularity_w_type-163', 'carts_popularity_w_lastday', 'carts_popularity_w_recsys', \n",
    "    'orders_popularity_w_pos-log', 'orders_popularity_w_type-163', 'orders_popularity_w_lastday', 'orders_popularity_w_recsys', \n",
    "    'clicks_popularity_w_pos-log_w', 'clicks_popularity_w_type-163_w', 'clicks_popularity_w_recsys_w', \n",
    "    'carts_popularity_w_pos-log_w', 'carts_popularity_w_type-163_w', 'carts_popularity_w_recsys_w', \n",
    "    'orders_popularity_w_pos-log_w', 'orders_popularity_w_type-163_w', 'orders_popularity_w_recsys_w',\n",
    "    'w_pos-log', 'w_type-163', 'w_lastday', 'w_time', 'w_recsys',\n",
    "    'matrix_123_temporal_20_mean', 'matrix_123_temporal_20_sum', 'matrix_123_temporal_20_max', 'matrix_123_temporal_20_pos-log_mean', 'matrix_123_temporal_20_pos-log_sum', 'matrix_123_temporal_20_pos-log_max', 'matrix_123_temporal_20_type-163_mean', 'matrix_123_temporal_20_type-163_sum', 'matrix_123_temporal_20_type-163_max', 'matrix_123_temporal_20_lastday_mean', 'matrix_123_temporal_20_lastday_sum', 'matrix_123_temporal_20_lastday_max', 'matrix_123_temporal_20_time_mean', 'matrix_123_temporal_20_time_sum', 'matrix_123_temporal_20_time_max', 'matrix_123_temporal_20_recsys_mean', 'matrix_123_temporal_20_recsys_sum', 'matrix_123_temporal_20_recsys_max',\n",
    "    'matrix_123_type136_20_mean', 'matrix_123_type136_20_sum', 'matrix_123_type136_20_max', 'matrix_123_type136_20_pos-log_mean', 'matrix_123_type136_20_pos-log_sum', 'matrix_123_type136_20_pos-log_max', 'matrix_123_type136_20_type-163_mean', 'matrix_123_type136_20_type-163_sum', 'matrix_123_type136_20_type-163_max', 'matrix_123_type136_20_lastday_mean', 'matrix_123_type136_20_lastday_sum', 'matrix_123_type136_20_lastday_max', 'matrix_123_type136_20_time_mean', 'matrix_123_type136_20_time_sum', 'matrix_123_type136_20_time_max', 'matrix_123_type136_20_recsys_mean', 'matrix_123_type136_20_recsys_sum', 'matrix_123_type136_20_recsys_max',\n",
    "    'matrix_12__20_mean', 'matrix_12__20_sum', 'matrix_12__20_max', 'matrix_12__20_pos-log_mean', 'matrix_12__20_pos-log_sum', 'matrix_12__20_pos-log_max', 'matrix_12__20_type-163_mean', 'matrix_12__20_type-163_sum', 'matrix_12__20_type-163_max', 'matrix_12__20_lastday_mean', 'matrix_12__20_lastday_sum', 'matrix_12__20_lastday_max', 'matrix_12__20_time_mean', 'matrix_12__20_time_sum', 'matrix_12__20_time_max', 'matrix_12__20_recsys_mean', 'matrix_12__20_recsys_sum', 'matrix_12__20_recsys_max',\n",
    "    'matrix_123_type0.590.5_20_mean', 'matrix_123_type0.590.5_20_sum', 'matrix_123_type0.590.5_20_max', 'matrix_123_type0.590.5_20_pos-log_mean', 'matrix_123_type0.590.5_20_pos-log_sum', 'matrix_123_type0.590.5_20_pos-log_max', 'matrix_123_type0.590.5_20_type-163_mean', 'matrix_123_type0.590.5_20_type-163_sum', 'matrix_123_type0.590.5_20_type-163_max', 'matrix_123_type0.590.5_20_lastday_mean', 'matrix_123_type0.590.5_20_lastday_sum', 'matrix_123_type0.590.5_20_lastday_max', 'matrix_123_type0.590.5_20_time_mean', 'matrix_123_type0.590.5_20_time_sum', 'matrix_123_type0.590.5_20_time_max', 'matrix_123_type0.590.5_20_recsys_mean', 'matrix_123_type0.590.5_20_recsys_sum', 'matrix_123_type0.590.5_20_recsys_max',\n",
    "    'matrix_cpu-90_mean', 'matrix_cpu-90_sum', 'matrix_cpu-90_max', 'matrix_cpu-90_pos-log_mean', 'matrix_cpu-90_pos-log_sum', 'matrix_cpu-90_pos-log_max', 'matrix_cpu-90_type-163_mean', 'matrix_cpu-90_type-163_sum', 'matrix_cpu-90_type-163_max', 'matrix_cpu-90_lastday_mean', 'matrix_cpu-90_lastday_sum', 'matrix_cpu-90_lastday_max', 'matrix_cpu-90_time_mean', 'matrix_cpu-90_time_sum', 'matrix_cpu-90_time_max', 'matrix_cpu-90_recsys_mean', 'matrix_cpu-90_recsys_sum', 'matrix_cpu-90_recsys_max',\n",
    "    'matrix_cpu-95_mean', 'matrix_cpu-95_sum', 'matrix_cpu-95_max', 'matrix_cpu-95_pos-log_mean', 'matrix_cpu-95_pos-log_sum', 'matrix_cpu-95_pos-log_max', 'matrix_cpu-95_type-163_mean', 'matrix_cpu-95_type-163_sum', 'matrix_cpu-95_type-163_max', 'matrix_cpu-95_lastday_mean', 'matrix_cpu-95_lastday_sum', 'matrix_cpu-95_lastday_max', 'matrix_cpu-95_time_mean', 'matrix_cpu-95_time_sum', 'matrix_cpu-95_time_max', 'matrix_cpu-95_recsys_mean', 'matrix_cpu-95_recsys_sum', 'matrix_cpu-95_recsys_max',\n",
    "    'matrix_cpu-99_mean', 'matrix_cpu-99_sum', 'matrix_cpu-99_max', 'matrix_cpu-99_pos-log_mean', 'matrix_cpu-99_pos-log_sum', 'matrix_cpu-99_pos-log_max', 'matrix_cpu-99_type-163_mean', 'matrix_cpu-99_type-163_sum', 'matrix_cpu-99_type-163_max', 'matrix_cpu-99_lastday_mean', 'matrix_cpu-99_lastday_sum', 'matrix_cpu-99_lastday_max', 'matrix_cpu-99_time_mean', 'matrix_cpu-99_time_sum', 'matrix_cpu-99_time_max', 'matrix_cpu-99_recsys_mean', 'matrix_cpu-99_recsys_sum', 'matrix_cpu-99_recsys_max',\n",
    "    'matrix_gpu-116_mean', 'matrix_gpu-116_sum', 'matrix_gpu-116_max', 'matrix_gpu-116_pos-log_mean', 'matrix_gpu-116_pos-log_sum', 'matrix_gpu-116_pos-log_max', 'matrix_gpu-116_type-163_mean', 'matrix_gpu-116_type-163_sum', 'matrix_gpu-116_type-163_max', 'matrix_gpu-116_lastday_mean', 'matrix_gpu-116_lastday_sum', 'matrix_gpu-116_lastday_max', 'matrix_gpu-116_time_mean', 'matrix_gpu-116_time_sum', 'matrix_gpu-116_time_max', 'matrix_gpu-116_recsys_mean', 'matrix_gpu-116_recsys_sum', 'matrix_gpu-116_recsys_max',\n",
    "    'matrix_gpu-115_mean', 'matrix_gpu-115_sum', 'matrix_gpu-115_max', 'matrix_gpu-115_pos-log_mean', 'matrix_gpu-115_pos-log_sum', 'matrix_gpu-115_pos-log_max', 'matrix_gpu-115_type-163_mean', 'matrix_gpu-115_type-163_sum', 'matrix_gpu-115_type-163_max', 'matrix_gpu-115_lastday_mean', 'matrix_gpu-115_lastday_sum', 'matrix_gpu-115_lastday_max', 'matrix_gpu-115_time_mean', 'matrix_gpu-115_time_sum', 'matrix_gpu-115_time_max', 'matrix_gpu-115_recsys_mean', 'matrix_gpu-115_recsys_sum', 'matrix_gpu-115_recsys_max',\n",
    "    'matrix_gpu-93_mean', 'matrix_gpu-93_sum', 'matrix_gpu-93_max', 'matrix_gpu-93_pos-log_mean', 'matrix_gpu-93_pos-log_sum', 'matrix_gpu-93_pos-log_max', 'matrix_gpu-93_type-163_mean', 'matrix_gpu-93_type-163_sum', 'matrix_gpu-93_type-163_max', 'matrix_gpu-93_lastday_mean', 'matrix_gpu-93_lastday_sum', 'matrix_gpu-93_lastday_max', 'matrix_gpu-93_time_mean', 'matrix_gpu-93_time_sum', 'matrix_gpu-93_time_max', 'matrix_gpu-93_recsys_mean', 'matrix_gpu-93_recsys_sum', 'matrix_gpu-93_recsys_max',\n",
    "    'matrix_gpu-217_mean', 'matrix_gpu-217_sum', 'matrix_gpu-217_max', 'matrix_gpu-217_pos-log_mean', 'matrix_gpu-217_pos-log_sum', 'matrix_gpu-217_pos-log_max', 'matrix_gpu-217_type-163_mean', 'matrix_gpu-217_type-163_sum', 'matrix_gpu-217_type-163_max', 'matrix_gpu-217_lastday_mean', 'matrix_gpu-217_lastday_sum', 'matrix_gpu-217_lastday_max', 'matrix_gpu-217_time_mean', 'matrix_gpu-217_time_sum', 'matrix_gpu-217_time_max', 'matrix_gpu-217_recsys_mean', 'matrix_gpu-217_recsys_sum', 'matrix_gpu-217_recsys_max',\n",
    "    'matrix_gpu-226_mean','matrix_gpu-226_sum','matrix_gpu-226_max','matrix_gpu-226_pos-log_mean','matrix_gpu-226_pos-log_sum','matrix_gpu-226_pos-log_max','matrix_gpu-226_type-163_mean','matrix_gpu-226_type-163_sum','matrix_gpu-226_type-163_max','matrix_gpu-226_lastday_mean','matrix_gpu-226_lastday_sum','matrix_gpu-226_lastday_max','matrix_gpu-226_time_mean','matrix_gpu-226_time_sum','matrix_gpu-226_time_max','matrix_gpu-226_recsys_mean','matrix_gpu-226_recsys_sum','matrix_gpu-226_recsys_max',\n",
    "    'matrix_gpu-232_mean', 'matrix_gpu-232_sum', 'matrix_gpu-232_max', 'matrix_gpu-232_pos-log_mean', 'matrix_gpu-232_pos-log_sum', 'matrix_gpu-232_pos-log_max', 'matrix_gpu-232_type-163_mean', 'matrix_gpu-232_type-163_sum', 'matrix_gpu-232_type-163_max', 'matrix_gpu-232_lastday_mean', 'matrix_gpu-232_lastday_sum', 'matrix_gpu-232_lastday_max', 'matrix_gpu-232_time_mean', 'matrix_gpu-232_time_sum', 'matrix_gpu-232_time_max', 'matrix_gpu-232_recsys_mean', 'matrix_gpu-232_recsys_sum', 'matrix_gpu-232_recsys_max',\n",
    "    'matrix_gpu-239_mean', 'matrix_gpu-239_sum', 'matrix_gpu-239_max', 'matrix_gpu-239_pos-log_mean', 'matrix_gpu-239_pos-log_sum', 'matrix_gpu-239_pos-log_max', 'matrix_gpu-239_type-163_mean', 'matrix_gpu-239_type-163_sum', 'matrix_gpu-239_type-163_max', 'matrix_gpu-239_lastday_mean', 'matrix_gpu-239_lastday_sum', 'matrix_gpu-239_lastday_max', 'matrix_gpu-239_time_mean', 'matrix_gpu-239_time_sum', 'matrix_gpu-239_time_max', 'matrix_gpu-239_recsys_mean', 'matrix_gpu-239_recsys_sum', 'matrix_gpu-239_recsys_max',\n",
    "    'matrix_gpu-700_mean', 'matrix_gpu-700_sum', 'matrix_gpu-700_max', 'matrix_gpu-700_pos-log_mean', 'matrix_gpu-700_pos-log_sum', 'matrix_gpu-700_pos-log_max', 'matrix_gpu-700_type-163_mean', 'matrix_gpu-700_type-163_sum', 'matrix_gpu-700_type-163_max', 'matrix_gpu-700_lastday_mean', 'matrix_gpu-700_lastday_sum', 'matrix_gpu-700_lastday_max', 'matrix_gpu-700_time_mean', 'matrix_gpu-700_time_sum', 'matrix_gpu-700_time_max', 'matrix_gpu-700_recsys_mean', 'matrix_gpu-700_recsys_sum', 'matrix_gpu-700_recsys_max',\n",
    "    'matrix_gpu-701_mean', 'matrix_gpu-701_sum', 'matrix_gpu-701_max', 'matrix_gpu-701_pos-log_mean', 'matrix_gpu-701_pos-log_sum', 'matrix_gpu-701_pos-log_max', 'matrix_gpu-701_type-163_mean', 'matrix_gpu-701_type-163_sum', 'matrix_gpu-701_type-163_max', 'matrix_gpu-701_lastday_mean', 'matrix_gpu-701_lastday_sum', 'matrix_gpu-701_lastday_max', 'matrix_gpu-701_time_mean', 'matrix_gpu-701_time_sum', 'matrix_gpu-701_time_max', 'matrix_gpu-701_recsys_mean', 'matrix_gpu-701_recsys_sum', 'matrix_gpu-701_recsys_max',\n",
    "    'candidate_clicks_before', 'candidate_carts_before', 'candidate_orders_before', 'candidate_*_before', 'n_views', 'n_clicks', 'n_carts', 'n_orders',\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "TO_REMOVE = []\n",
    "TO_REMOVE = [f for f in FEATURES if \"type-191\" in f]\n",
    "TO_REMOVE += [f for f in FEATURES if \"matrix_gpu-220\" in f]\n",
    "TO_REMOVE += [f for f in FEATURES if \"matrix_gpu-235\" in f]\n",
    "TO_REMOVE += [f for f in FEATURES if \"lasthour\" in f]\n",
    "TO_REMOVE += [f for f in FEATURES if \"lastmin\" in f]\n",
    "TO_REMOVE += [f for f in FEATURES if f.startswith(\"popularity\")]\n",
    "TO_REMOVE += [f for f in FEATURES if \"_old\" in f]\n",
    "TO_REMOVE += [f for f in FEATURES if \"popularity_w_time\" in f]\n",
    "TO_REMOVE += [f for f in FEATURES if \"popularity_w_lastday_w\" in f]\n",
    "\n",
    "FEATURES = [f for f in FEATURES if f not in TO_REMOVE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_train_val_data(regex, folds_file, pos_ratio=0, target=\"\", train_only=False, use_gt=False, columns=None, save_folder=\"\"):\n",
    "    files = sorted(glob.glob(regex))    \n",
    "    folds = cudf.read_csv(folds_file)\n",
    "    n_folds = int(folds['fold'].max()) + 1\n",
    "\n",
    "    for idx, file in enumerate(tqdm(files)):\n",
    "        df = cudf.read_parquet(file, columns=columns)\n",
    "        df = df.merge(folds, on=\"session\", how=\"left\")\n",
    "        \n",
    "        for fold in range(n_folds):\n",
    "            os.makedirs(save_folder + f\"{fold}\", exist_ok=True)\n",
    "            os.makedirs(save_folder + f\"{fold}/train/\", exist_ok=True)\n",
    "            os.makedirs(save_folder + f\"{fold}/val/\", exist_ok=True)\n",
    "\n",
    "            if not train_only:\n",
    "                df_val = df[df['fold'] == fold].reset_index(drop=True)\n",
    "\n",
    "            df_train = df[df['fold'] != fold].reset_index(drop=True)\n",
    "\n",
    "            if target:  # Subsample\n",
    "                df_train['gt_*'] = df_train[['gt_carts', \"gt_clicks\", \"gt_orders\"]].max(axis=1)\n",
    "\n",
    "                if use_gt:\n",
    "                    gt = cudf.read_parquet(\"../output/val_labels.parquet\")\n",
    "                    kept_sessions = gt[gt['type'] == target[3:]].drop('ground_truth', axis=1)\n",
    "                    df_train = df_train.merge(kept_sessions, on=\"session\", how=\"left\").dropna(0).drop('type', axis=1).reset_index(drop=True)\n",
    "\n",
    "                pos = df_train.index[df_train[target] == 1]\n",
    "\n",
    "                if pos_ratio > 0:\n",
    "                    try:\n",
    "                        n_neg = int(df_train[target].sum() / pos_ratio)\n",
    "                        neg = df_train[[target]][df_train[target] == 0].sample(n_neg).index\n",
    "                        df_train = df_train.iloc[cudf.concat([pos, neg])]\n",
    "                    except:\n",
    "                        pass\n",
    "                elif pos_ratio == -1:  # only positives\n",
    "                    df_train = df_train.iloc[pos]\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "                df_train.drop('gt_*', axis=1, inplace=True)\n",
    "                \n",
    "            if not train_only:\n",
    "                df_val.to_parquet(save_folder + f\"{fold}/val/\" + file.split('/')[-1])\n",
    "                del df_val\n",
    "\n",
    "            df_train.to_parquet(save_folder + f\"{fold}/train/\" + file.split('/')[-1])\n",
    "            \n",
    "            del df_train\n",
    "            numba.cuda.current_context().deallocations.clear()\n",
    "            gc.collect()\n",
    "            \n",
    "            break\n",
    "            \n",
    "        del df\n",
    "        numba.cuda.current_context().deallocations.clear()\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare_train_val_data(\n",
    "#     f\"../output/features/fts_val_{VERSION}/*\",\n",
    "#     \"../input/folds_4.csv\",\n",
    "#     pos_ratio=-1,\n",
    "#     target=TARGET,\n",
    "#     use_gt=False,\n",
    "#     train_only=True,\n",
    "#     columns=['session','candidates','gt_clicks','gt_carts','gt_orders'] + FEATURES,\n",
    "#     save_folder= f\"../output/features/fts_val_{VERSION}_split/\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLD = 0  # \"*\"\n",
    "\n",
    "val_regex = f\"../output/features/fts_val_{VERSION}_split/{FOLD}/val/*\"\n",
    "val_files = glob.glob(val_regex)\n",
    "\n",
    "train_regex = f\"../output/features/fts_val_{VERSION}_split/{FOLD}/train/*\"\n",
    "train_files = glob.glob(train_regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_regex = f\"../output/features/fts_test_{VERSION}/*\"\n",
    "test_files = glob.glob(test_regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1062858 3981185\n"
     ]
    }
   ],
   "source": [
    "n_val = sum([len(cudf.read_parquet(f, columns=['gt_orders'])) for f in val_files[:10]])\n",
    "n_train  = sum([len(cudf.read_parquet(f, columns=['gt_orders'])) for f in train_files])\n",
    "\n",
    "print(n_train, n_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Val data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from merlin.io import Dataset\n",
    "# from merlin.loader.torch import Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = Dataset(train_files, engine=\"parquet\")\n",
    "# loader = Loader(\n",
    "#     dataset,\n",
    "#     batch_size=2**16,\n",
    "#     shuffle=False,\n",
    "# #     pin_memory=True,\n",
    "# #     worker_init_fn=worker_init_fn,\n",
    "# #     persistent_workers=True,\n",
    "# #     num_workers=NUM_WORKERS,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# batch = next(iter(loader))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = cudf.read_parquet(path, columns=['session', \"candidates\"] + [TARGET])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# x = torch.cat([batch[k] for k in batch.keys()], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = FeaturesDataset(df_train, [\"gt_carts\"], df_train.columns[5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# df_val = pd.read_csv(f'../output/fts_train_{VERSION}.csv', nrows=10_000_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = define_model(\"res\")\n",
    "# x = torch.rand(5, 50)\n",
    "# model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    seed = 100\n",
    "    version = VERSION\n",
    "    pos_ratio = POS_RATIO\n",
    "\n",
    "    features = FEATURES\n",
    "\n",
    "    target = [TARGET] if TARGET != \"gt_*\" else [\"gt_clicks\", \"gt_carts\", \"gt_orders\"]\n",
    "    pos_ratio = POS_RATIO\n",
    "    \n",
    "    # Model\n",
    "    model = \"mlp\"\n",
    "    nb_ft = len(features)\n",
    "    d = 768\n",
    "    p = 0.1\n",
    "    num_layers = 3\n",
    "    num_classes = len(target)\n",
    "\n",
    "    # Training    \n",
    "    loss_config = {\n",
    "        \"name\": \"bce\",\n",
    "        \"smoothing\": 0.,\n",
    "        \"activation\": \"sigmoid\",\n",
    "    }\n",
    "\n",
    "    data_config = {\n",
    "        \"target\": target,\n",
    "        \"features\": features,\n",
    "        \"batch_size\": 2 ** 17,\n",
    "        \"val_bs\": 2 ** 16,\n",
    "    }\n",
    "\n",
    "    optimizer_config = {\n",
    "        \"name\": \"Adam\",\n",
    "        \"lr\": 1e-3,\n",
    "        \"warmup_prop\": 0.,\n",
    "        \"betas\": (0.9, 0.999),\n",
    "    }\n",
    "\n",
    "    epochs = 50  # 70\n",
    "\n",
    "    use_fp16 = True\n",
    "\n",
    "    verbose = 1\n",
    "    verbose_eval = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "DEBUG_MORE = False\n",
    "df_val = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging results to ../logs/2023-01-16/4/\n",
      "\n",
      "-------------   Training MLP Model   -------------\n",
      "\n",
      "    -> 1.06M training candidates\n",
      "    -> 3.98M validation candidates subset\n",
      "    -> 639.62K trainable parameters\n",
      "\n",
      "Epoch 50/50 (step 0451)\tlr=0.0e+00\t t=2166s \t loss=0.351\t val_loss=0.351\t auc=0.8108  (0.599, 0.679, 0.912)\n",
      "\n",
      "    -> Inferring 31.77M val candidates\n",
      "\n",
      "100%|##########| 485/485 [04:13<00:00,  1.91it/s]\n",
      "\n",
      "-> gt_clicks - AUC : 0.5975\n",
      "-> gt_carts - AUC : 0.6821\n",
      "-> gt_orders - AUC : 0.9128\n",
      "\n",
      "- clicks \t-  Found 134.8K GTs\t-  Recall : 0.3072\n",
      "- carts \t-  Found 34.3K GTs\t-  Recall : 0.2386\n",
      "- orders \t-  Found 44.95K GTs\t-  Recall : 0.5763\n",
      "\n",
      "-> CV : 0.4481\n",
      "\n",
      "    -> Inferring 119.78M test candidates per chunk\n",
      "\n",
      "100%|##########| 193/193 [00:43<00:00,  4.40it/s]\n",
      "100%|##########| 213/213 [00:50<00:00,  4.26it/s]\n",
      "100%|##########| 228/228 [00:55<00:00,  4.12it/s]\n",
      "100%|##########| 141/141 [00:31<00:00,  4.43it/s]\n",
      "100%|##########| 219/219 [00:51<00:00,  4.24it/s]\n",
      "100%|##########| 188/188 [00:45<00:00,  4.10it/s]\n",
      "100%|##########| 219/219 [00:46<00:00,  4.67it/s]\n",
      "100%|##########| 199/199 [00:42<00:00,  4.63it/s]\n",
      "100%|##########| 133/133 [00:27<00:00,  4.88it/s]\n",
      "100%|##########| 99/99 [00:18<00:00,  5.48it/s]\n"
     ]
    }
   ],
   "source": [
    "log_folder = None\n",
    "if not DEBUG:\n",
    "    log_folder = prepare_log_folder(LOG_PATH)\n",
    "    print(f'Logging results to {log_folder}')\n",
    "    save_config(Config, log_folder + 'config')\n",
    "    create_logger(directory=log_folder, name=\"logs.txt\")\n",
    "\n",
    "df_val = train(train_files, val_files, test_files, Config, log_folder=log_folder, debug=DEBUG_MORE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- clicks \t-  Found 239.1K GTs\t-  Recall : 0.5450\n",
    "- carts \t-  Found 62.01K GTs\t-  Recall : 0.4313\n",
    "- orders \t-  Found 51.63K GTs\t-  Recall : 0.6620\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGB : 0.554 / 0.439 / 0.666"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXP_FOLDERS = [\n",
    "#     \"../logs/2023-01-08/13/\",\n",
    "#     \"../logs/2023-01-08/16/\",\n",
    "#     \"../logs/2023-01-08/17/\",\n",
    "# ]\n",
    "\n",
    "# if df_val is None:\n",
    "#     for exp_folder in tqdm(EXP_FOLDERS):\n",
    "#         df_val_ = cudf.read_parquet(exp_folder + \"results.parquet\")\n",
    "#         df_val_ = df_val_.sort_values(['session', 'candidates'])\n",
    "#         if df_val is None:\n",
    "#             df_val = df_val_.copy()\n",
    "#         else:\n",
    "#     #         assert df_val\n",
    "#             for c in df_val.columns[2:]:\n",
    "#                 df_val[c] += df_val_[c]\n",
    "\n",
    "#     for c in df_val.columns[2:]:\n",
    "#         df_val[c] /= len(EXP_FOLDERS)\n",
    "\n",
    "#     df_val[['session', 'candidates']] = df_val[['session', 'candidates']].astype(\"int32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
