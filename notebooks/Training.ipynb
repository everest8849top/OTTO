{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/kaggle/kaggle_otto_rs/src\n"
     ]
    }
   ],
   "source": [
    "cd ../src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import json\n",
    "import glob\n",
    "import torch\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import nvtabular as nvt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils.tokenizers import update_tokenizers\n",
    "# package_path = \"/opt/conda/lib/python3.8/site-packages/transformers\"\n",
    "# input_dir = \"../input/deberta_fast_tokenizer\"\n",
    "\n",
    "# update_tokenizers(package_path, input_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.dataset import OttoDataset\n",
    "from data.preparation import prepare_data\n",
    "# from training.main import k_fold\n",
    "from models import OttoTransformer\n",
    "\n",
    "from utils.metrics import *\n",
    "from utils.logger import prepare_log_folder, save_config, create_logger\n",
    "\n",
    "from params import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nvtabular.ops import *\n",
    "from merlin.schema.tags import Tags\n",
    "from merlin_standard_lib import Schema\n",
    "from transformers4rec import torch as tr\n",
    "from transformers4rec.torch.ranking_metric import RecallAt\n",
    "from nvtabular.loader.torch import TorchAsyncItr, DLDataLoader\n",
    "\n",
    "from trainer import Trainer\n",
    "from transformers4rec.config.trainer import T4RecTrainingArguments\n",
    "from transformers4rec.torch.utils.data_utils import NVTabularDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"../input/parquets/train_0.parquet\")\n",
    "df_ref = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def convert_size(size_bytes):\n",
    "    if size_bytes == 0:\n",
    "        return \"0B\"\n",
    "    size_name = (\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\", \"EB\", \"ZB\", \"YB\")\n",
    "    i = int(math.floor(math.log(size_bytes, 1024)))\n",
    "    p = math.pow(1024, i)\n",
    "    s = round(size_bytes / p, 2)\n",
    "    return \"%s %s\" % (s, size_name[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ref = \"../input/parquets/train_0.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from merlin.loader.torch import Loader \n",
    "from merlin.io import Dataset\n",
    "\n",
    "train_ds = Dataset(df_ref)\n",
    "\n",
    "train_dl_merlin = Loader(\n",
    "    train_ds,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 45.7 s, sys: 2.65 s, total: 48.4 s\n",
      "Wall time: 49.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "batch = next(iter(train_dl_merlin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch(batch):\n",
    "    processed_batch = {}\n",
    "    lens = []\n",
    "    \n",
    "    for k in batch.keys():\n",
    "        try:\n",
    "            x, s = batch[k]\n",
    "        except:\n",
    "            processed_batch[k] = batch[k]\n",
    "            continue\n",
    "\n",
    "        x_ = list(x.tensor_split(s[1:].cpu().long().squeeze()))\n",
    "        processed_batch[k] = x_\n",
    "\n",
    "        if \"len\" not in processed_batch.keys():\n",
    "            processed_batch['len'] = [x.size(0) for x in x_]\n",
    "\n",
    "#         max_size = np.max([x.size(0) for x in x_])\n",
    "#         ph = torch.zeros((len(x_), max_size), dtype=x.dtype)\n",
    "#         for i, x in enumerate(x_):\n",
    "#             ph[i, : x.size(0)] = x\n",
    "#         processed_batch[k] = ph[:max_size]\n",
    "\n",
    "    return processed_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.78 ms, sys: 353 µs, total: 7.13 ms\n",
      "Wall time: 6.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "processed_batch = process_batch(batch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8125/8125 [02:25<00:00, 55.80it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 12s, sys: 13 s, total: 2min 25s\n",
      "Wall time: 2min 25s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "processed_batches = {}\n",
    "\n",
    "for batch in tqdm(train_dl_merlin):\n",
    "    processed_batch = process_batch(batch[0])\n",
    "\n",
    "    for k in processed_batch:\n",
    "        try:\n",
    "            processed_batches[k] += processed_batch[k]\n",
    "        except KeyError:\n",
    "            processed_batches[k] = processed_batch[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = np.arange(1, 500)\n",
    "# plt.plot(x, 5 * np.log(x))\n",
    "# plt.grid(True)\n",
    "# plt.plot(x, x / 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def len_sampler(lens, batch_size=32, drop_last=False):\n",
    "    batches = []\n",
    "    buckets = [[]] * 1000\n",
    "    yielded = 0\n",
    "\n",
    "    for idx, len_ in enumerate(lens):\n",
    "        count_zeros = int(5 * np.log(len_))\n",
    "        if len(buckets[count_zeros]) == 0:\n",
    "            buckets[count_zeros] = []\n",
    "\n",
    "        buckets[count_zeros].append(idx)\n",
    "\n",
    "        if len(buckets[count_zeros]) == batch_size:\n",
    "            batch = list(buckets[count_zeros])\n",
    "#             yield batch\n",
    "            batches.append(batch)\n",
    "            yielded += 1\n",
    "            buckets[count_zeros] = []\n",
    "\n",
    "    batch = []\n",
    "    leftover = [idx for bucket in buckets for idx in bucket]\n",
    "\n",
    "    for idx in leftover:\n",
    "        batch.append(idx)\n",
    "        if len(batch) == batch_size:\n",
    "            yielded += 1\n",
    "            batches.append(batch)\n",
    "#             yield batch\n",
    "            batch = []\n",
    "\n",
    "    if len(batch) > 0 and not drop_last:\n",
    "        yielded += 1\n",
    "        batches.append(batch)\n",
    "#         yield batch\n",
    "\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = len_sampler(processed_batches['len'], 32, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['aid', 'len', 'ts', 'type', 'labels_clicks', 'session', 'labels_carts_0', 'labels_orders_0', 'labels_carts_1', 'labels_orders_1', 'labels_carts_2', 'labels_orders_2', 'labels_carts_3', 'labels_orders_3', 'labels_carts_4', 'labels_orders_4', 'labels_carts_5', 'labels_orders_5', 'labels_carts_6', 'labels_orders_6', 'labels_carts_7', 'labels_orders_7', 'labels_carts_8', 'labels_orders_8', 'labels_carts_9', 'labels_orders_9', 'labels_carts_10', 'labels_orders_10', 'labels_carts_11', 'labels_orders_11', 'labels_carts_12', 'labels_orders_12', 'labels_carts_13', 'labels_orders_13', 'labels_carts_14', 'labels_orders_14', 'labels_carts_15', 'labels_orders_15', 'labels_carts_16', 'labels_orders_16', 'labels_carts_17', 'labels_orders_17', 'labels_carts_18', 'labels_orders_18', 'labels_carts_19', 'labels_orders_19'])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_batches.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8125 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "min_lens = []\n",
    "for batch in tqdm(batches):\n",
    "    lens = [processed_batches['len'][idx] for idx in batch]\n",
    "\n",
    "    min_len = np.min(lens)\n",
    "    min_lens.append(min_len)\n",
    "\n",
    "#     for k in processed_batches:\n",
    "#         print(k)\n",
    "#         x = torch.stack([processed_batches[k][idx][:min_len] for idx in batch])\n",
    "\n",
    "    x = {k: torch.stack([processed_batches[k][idx][:min_len] for idx in batch]) for k in ['aid', 'ts', 'type']}\n",
    "    y = {k: torch.stack([processed_batches[k][idx][min_len - 1] for idx in batch]) for k in processed_batches if k not in ['session', 'aid', 'len', 'ts', 'type']}\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 818697, 1296642, 1407078,  ...,  776384, 1415436,  806996],\n",
       "        [ 329936, 1506982,  671392,  ...,  624925,  204728,  324620],\n",
       "        [ 927101, 1727393,  282587,  ...,  101986,  176666,  176666],\n",
       "        ...,\n",
       "        [1517226,  200827,  200827,  ..., 1403545,  697270,  489181],\n",
       "        [ 266237,  266237, 1390154,  ...,  323049, 1278224,  220468],\n",
       "        [1072406,  372017,  372017,  ..., 1708940, 1070747,  568214]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x['aid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels_clicks': tensor([      0, 1099388,  176666,  156247,   31508,  631899, 1363224, 1272510,\n",
       "         1046491, 1111934, 1478294, 1553122, 1273977, 1460858,  804700,  858693,\n",
       "         1572293, 1576766, 1447712,  796748,  463079, 1308580, 1787512,  385078,\n",
       "         1257092,  225619,  226254,    5769, 1364448,  697270,  172465, 1847053],\n",
       "        device='cuda:0'),\n",
       " 'labels_carts_0': tensor([1699802., 1357411., 1329897.,       0.,       0.,       0.,       0.,\n",
       "         1272510.,  835497.,       0.,  231386.,       0.,       0.,       0.,\n",
       "               0.,       0.,       0.,       0.,       0.,       0.,       0.,\n",
       "               0.,       0.,       0.,       0.,       0.,       0.,       0.,\n",
       "               0.,       0.,       0., 1708940.], device='cuda:0',\n",
       "        dtype=torch.float64),\n",
       " 'labels_orders_0': tensor([ 806996.,       0.,       0.,       0.,       0.,       0.,       0.,\n",
       "               0.,  835497.,       0.,       0.,       0.,       0., 1810824.,\n",
       "               0.,       0., 1572293.,       0.,       0.,       0.,       0.,\n",
       "               0.,       0.,       0.,       0.,       0.,       0.,       0.,\n",
       "               0.,       0.,       0.,       0.], device='cuda:0',\n",
       "        dtype=torch.float64),\n",
       " 'labels_carts_1': tensor([1062579.,       0.,       0.,       0.,       0.,       0.,       0.,\n",
       "               0.,  172949.,       0., 1478294.,       0.,       0.,       0.,\n",
       "               0.,       0.,       0.,       0.,       0.,       0.,       0.,\n",
       "               0.,       0.,       0.,       0.,       0.,       0.,       0.,\n",
       "               0.,       0.,       0.,       0.], device='cuda:0',\n",
       "        dtype=torch.float64),\n",
       " 'labels_orders_1': tensor([1415436.,       0.,       0.,       0.,       0.,       0.,       0.,\n",
       "               0.,  172949.,       0.,       0.,       0.,       0., 1460858.,\n",
       "               0.,       0.,       0.,       0.,       0.,       0.,       0.,\n",
       "               0.,       0.,       0.,       0.,       0.,       0.,       0.,\n",
       "               0.,       0.,       0.,       0.], device='cuda:0',\n",
       "        dtype=torch.float64),\n",
       " 'labels_carts_2': tensor([1534972.,       0.,       0.,       0.,       0.,       0.,       0.,\n",
       "               0.,       0.,       0.,       0.,       0.,       0.,       0.,\n",
       "               0.,       0.,       0.,       0.,       0.,       0.,       0.,\n",
       "               0.,       0.,       0.,       0.,       0.,       0.,       0.,\n",
       "               0.,       0.,       0.,       0.], device='cuda:0',\n",
       "        dtype=torch.float64),\n",
       " 'labels_orders_2': tensor([1534972.,       0.,       0.,       0.,       0.,       0.,       0.,\n",
       "               0.,       0.,       0.,       0.,       0.,       0.,  520421.,\n",
       "               0.,       0.,       0.,       0.,       0.,       0.,       0.,\n",
       "               0.,       0.,       0.,       0.,       0.,       0.,       0.,\n",
       "               0.,       0.,       0.,       0.], device='cuda:0',\n",
       "        dtype=torch.float64),\n",
       " 'labels_carts_3': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', dtype=torch.float64),\n",
       " 'labels_orders_3': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', dtype=torch.float64),\n",
       " 'labels_carts_4': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', dtype=torch.float64),\n",
       " 'labels_orders_4': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', dtype=torch.float64),\n",
       " 'labels_carts_5': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', dtype=torch.float64),\n",
       " 'labels_orders_5': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', dtype=torch.float64),\n",
       " 'labels_carts_6': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', dtype=torch.float64),\n",
       " 'labels_orders_6': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', dtype=torch.float64),\n",
       " 'labels_carts_7': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', dtype=torch.float64),\n",
       " 'labels_orders_7': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', dtype=torch.float64),\n",
       " 'labels_carts_8': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', dtype=torch.float64),\n",
       " 'labels_orders_8': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', dtype=torch.float64),\n",
       " 'labels_carts_9': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', dtype=torch.float64),\n",
       " 'labels_orders_9': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', dtype=torch.float64),\n",
       " 'labels_carts_10': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', dtype=torch.float64),\n",
       " 'labels_orders_10': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', dtype=torch.float64),\n",
       " 'labels_carts_11': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', dtype=torch.float64),\n",
       " 'labels_orders_11': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', dtype=torch.float64),\n",
       " 'labels_carts_12': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', dtype=torch.float64),\n",
       " 'labels_orders_12': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', dtype=torch.float64),\n",
       " 'labels_carts_13': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', dtype=torch.float64),\n",
       " 'labels_orders_13': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', dtype=torch.float64),\n",
       " 'labels_carts_14': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', dtype=torch.float64),\n",
       " 'labels_orders_14': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', dtype=torch.float64),\n",
       " 'labels_carts_15': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', dtype=torch.float64),\n",
       " 'labels_orders_15': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', dtype=torch.float64),\n",
       " 'labels_carts_16': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', dtype=torch.float64),\n",
       " 'labels_orders_16': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', dtype=torch.float64),\n",
       " 'labels_carts_17': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', dtype=torch.float64),\n",
       " 'labels_orders_17': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', dtype=torch.float64),\n",
       " 'labels_carts_18': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', dtype=torch.float64),\n",
       " 'labels_orders_18': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', dtype=torch.float64),\n",
       " 'labels_carts_19': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', dtype=torch.float64),\n",
       " 'labels_orders_19': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', dtype=torch.float64)}"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# for k in processed_batches.keys():\n",
    "#     sz = convert_size(sys.getsizeof(processed_batches[k]))\n",
    "#     print(k, sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 3311/8125 [03:41<05:21, 14.98it/s] \n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for batch in tqdm(train_dl_merlin):\n",
    "    processed_batch = process_batch(batch[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, df_test = prepare_data(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = df[df['fold'] == 0].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = OttoDataset(df_test.head(10000), max_len=410, max_trunc=100, train=False, test=True, pad=False)\n",
    "dataset = OttoDataset(df_val.head(10000), max_len=410, max_trunc=100, train=False, test=False, pad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens = []\n",
    "for idx in tqdm(range(10000)):\n",
    "    data = dataset[idx]\n",
    "    lens.append(data['ids'].size(0))\n",
    "#     break\n",
    "\n",
    "if len(lens) > 100:\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    sns.countplot(x=np.clip(lens, 0, 70))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = OttoTrainDataset(df_test, max_len=410, train=False)\n",
    "# lens = []\n",
    "\n",
    "# for idx in tqdm(range(10000)):\n",
    "#     data = dataset[idx]\n",
    "#     lens.append(data.shape[0])\n",
    "    \n",
    "# plt.figure(figsize=(15, 5))\n",
    "# sns.countplot(x=np.clip(lens, 0, 70))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [dataset.targets[k] for k in sorted(dataset.targets.keys())]\n",
    "recall(copy.deepcopy(y[:100]), copy.deepcopy(y[:100]), k=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = NERTransformer(\"microsoft/deberta-v3-base\", num_classes=3)\n",
    "model = OttoTransformer(\"roberta-base\", num_classes=3, n_ids=N_IDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data['ids'].unsqueeze(0)\n",
    "types = data['token_type_ids'].unsqueeze(0).cuda()\n",
    "\n",
    "x = torch.cat([x] * 16, 0)\n",
    "types = torch.cat([types] * 16, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()\n",
    "x = x.cuda()\n",
    "types = types.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(x, types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZES = {\n",
    "    \"microsoft/deberta-v3-base\": 32,\n",
    "    \"microsoft/deberta-v3-large\": 32,\n",
    "}\n",
    "\n",
    "LRS = {\n",
    "    \"microsoft/deberta-v3-base\": 3e-5,\n",
    "    \"microsoft/deberta-v3-large\": 3e-5,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    # General\n",
    "    seed = 2222\n",
    "    device = \"cuda\"\n",
    "    \n",
    "    # Splits\n",
    "    k = 4\n",
    "    random_state = 2222\n",
    "    selected_folds = [0, 1, 2, 3]\n",
    "    folds_file = \"/workspace/folds_kgd_4.csv\"\n",
    "\n",
    "    # Architecture\n",
    "    name = \"microsoft/deberta-v3-base\"\n",
    "\n",
    "    pretrained_weights = None \n",
    "\n",
    "    no_dropout = False\n",
    "    use_conv = False\n",
    "    use_lstm = False\n",
    "    nb_layers = 1\n",
    "    nb_ft = 128\n",
    "    conv_kernel = 5\n",
    "    drop_p = 0 if no_dropout else 0.1\n",
    "    multi_sample_dropout = False\n",
    "\n",
    "    num_classes = 3\n",
    "    n_ids = N_IDS\n",
    "\n",
    "    # Texts\n",
    "    max_len_train = 410\n",
    "    max_len = 410\n",
    "\n",
    "#     extra_data_path = OUT_PATH + \"pl_case5/\"\n",
    "    extra_data_path = None  # OUT_PATH + \"pl_6/df_pl.csv\"\n",
    "\n",
    "    # Training    \n",
    "    loss_config = {\n",
    "        \"name\": \"bce\",  # ce, bce\n",
    "        \"smoothing\": 0,  # 0.01\n",
    "        \"activation\": \"sigmoid\",  # \"sigmoid\", \"softmax\"\n",
    "    }\n",
    "\n",
    "    data_config = {\n",
    "        \"batch_size\": BATCH_SIZES[name],\n",
    "        \"val_bs\": BATCH_SIZES[name] * 2,\n",
    "        \"use_len_sampler\": True,\n",
    "        \"pad_token\": 1 if \"roberta\" in name else 0,\n",
    "    }\n",
    "\n",
    "    optimizer_config = {\n",
    "        \"name\": \"AdamW\",\n",
    "        \"lr\": 5e-5,\n",
    "        \"lr_transfo\": LRS[name],\n",
    "        \"lr_decay\": 0.99,\n",
    "        \"warmup_prop\": 0.1,\n",
    "        \"weight_decay\": 1,\n",
    "        \"betas\": (0.5, 0.99),\n",
    "        \"max_grad_norm\": 1.,\n",
    "        # AWP\n",
    "        \"use_awp\": False,\n",
    "        \"awp_start_step\": 1000,\n",
    "        \"awp_lr\": 1,\n",
    "        \"awp_eps\": 5e-5 if \"xlarge\" in name else 1e-3,\n",
    "        \"awp_period\": 3,\n",
    "        # SWA\n",
    "        \"use_swa\": False,\n",
    "        \"swa_start\": 9400,\n",
    "        \"swa_freq\": 500,\n",
    "    }\n",
    "\n",
    "    gradient_checkpointing = False\n",
    "    acc_steps = 1\n",
    "    epochs = 1\n",
    "\n",
    "    use_fp16 = True\n",
    "\n",
    "    verbose = 1\n",
    "    verbose_eval = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = True\n",
    "log_folder = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not DEBUG:\n",
    "    log_folder = prepare_log_folder(LOG_PATH)\n",
    "    print(f\"Logging results to {log_folder}\")\n",
    "    save_config(Config, log_folder + \"config.json\")\n",
    "    create_logger(directory=log_folder, name=\"logs.txt\")\n",
    "\n",
    "pred_val, pred_test = k_fold(\n",
    "    Config,\n",
    "    df,\n",
    "    df_test=df_test,\n",
    "    log_folder=log_folder\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
