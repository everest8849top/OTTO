{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import json\n",
    "import glob\n",
    "import torch\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils.tokenizers import update_tokenizers\n",
    "# package_path = \"/opt/conda/lib/python3.8/site-packages/transformers\"\n",
    "# input_dir = \"../input/deberta_fast_tokenizer\"\n",
    "\n",
    "# update_tokenizers(package_path, input_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.dataset import OttoDataset\n",
    "from data.preparation import prepare_data\n",
    "# from training.main import k_fold\n",
    "from models import OttoTransformer\n",
    "\n",
    "from utils.metrics import *\n",
    "from utils.logger import prepare_log_folder, save_config, create_logger\n",
    "\n",
    "from params import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, df_test = prepare_data(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = df[df['fold'] == 0].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = OttoDataset(df_test.head(10000), max_len=410, max_trunc=100, train=False, test=True, pad=False)\n",
    "dataset = OttoDataset(df_val.head(10000), max_len=410, max_trunc=100, train=False, test=False, pad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens = []\n",
    "for idx in tqdm(range(10000)):\n",
    "    data = dataset[idx]\n",
    "    lens.append(data['ids'].size(0))\n",
    "#     break\n",
    "\n",
    "if len(lens) > 100:\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    sns.countplot(x=np.clip(lens, 0, 70))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = OttoTrainDataset(df_test, max_len=410, train=False)\n",
    "# lens = []\n",
    "\n",
    "# for idx in tqdm(range(10000)):\n",
    "#     data = dataset[idx]\n",
    "#     lens.append(data.shape[0])\n",
    "    \n",
    "# plt.figure(figsize=(15, 5))\n",
    "# sns.countplot(x=np.clip(lens, 0, 70))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [dataset.targets[k] for k in sorted(dataset.targets.keys())]\n",
    "recall(copy.deepcopy(y[:100]), copy.deepcopy(y[:100]), k=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = NERTransformer(\"microsoft/deberta-v3-base\", num_classes=3)\n",
    "model = OttoTransformer(\"roberta-base\", num_classes=3, n_ids=N_IDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data['ids'].unsqueeze(0)\n",
    "types = data['token_type_ids'].unsqueeze(0).cuda()\n",
    "\n",
    "x = torch.cat([x] * 16, 0)\n",
    "types = torch.cat([types] * 16, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()\n",
    "x = x.cuda()\n",
    "types = types.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(x, types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZES = {\n",
    "    \"microsoft/deberta-v3-base\": 32,\n",
    "    \"microsoft/deberta-v3-large\": 32,\n",
    "}\n",
    "\n",
    "LRS = {\n",
    "    \"microsoft/deberta-v3-base\": 3e-5,\n",
    "    \"microsoft/deberta-v3-large\": 3e-5,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    # General\n",
    "    seed = 2222\n",
    "    device = \"cuda\"\n",
    "    \n",
    "    # Splits\n",
    "    k = 4\n",
    "    random_state = 2222\n",
    "    selected_folds = [0, 1, 2, 3]\n",
    "    folds_file = \"/workspace/folds_kgd_4.csv\"\n",
    "\n",
    "    # Architecture\n",
    "    name = \"microsoft/deberta-v3-base\"\n",
    "\n",
    "    pretrained_weights = None \n",
    "\n",
    "    no_dropout = False\n",
    "    use_conv = False\n",
    "    use_lstm = False\n",
    "    nb_layers = 1\n",
    "    nb_ft = 128\n",
    "    conv_kernel = 5\n",
    "    drop_p = 0 if no_dropout else 0.1\n",
    "    multi_sample_dropout = False\n",
    "\n",
    "    num_classes = 3\n",
    "    n_ids = N_IDS\n",
    "\n",
    "    # Texts\n",
    "    max_len_train = 410\n",
    "    max_len = 410\n",
    "\n",
    "#     extra_data_path = OUT_PATH + \"pl_case5/\"\n",
    "    extra_data_path = None  # OUT_PATH + \"pl_6/df_pl.csv\"\n",
    "\n",
    "    # Training    \n",
    "    loss_config = {\n",
    "        \"name\": \"bce\",  # ce, bce\n",
    "        \"smoothing\": 0,  # 0.01\n",
    "        \"activation\": \"sigmoid\",  # \"sigmoid\", \"softmax\"\n",
    "    }\n",
    "\n",
    "    data_config = {\n",
    "        \"batch_size\": BATCH_SIZES[name],\n",
    "        \"val_bs\": BATCH_SIZES[name] * 2,\n",
    "        \"use_len_sampler\": True,\n",
    "        \"pad_token\": 1 if \"roberta\" in name else 0,\n",
    "    }\n",
    "\n",
    "    optimizer_config = {\n",
    "        \"name\": \"AdamW\",\n",
    "        \"lr\": 5e-5,\n",
    "        \"lr_transfo\": LRS[name],\n",
    "        \"lr_decay\": 0.99,\n",
    "        \"warmup_prop\": 0.1,\n",
    "        \"weight_decay\": 1,\n",
    "        \"betas\": (0.5, 0.99),\n",
    "        \"max_grad_norm\": 1.,\n",
    "        # AWP\n",
    "        \"use_awp\": False,\n",
    "        \"awp_start_step\": 1000,\n",
    "        \"awp_lr\": 1,\n",
    "        \"awp_eps\": 5e-5 if \"xlarge\" in name else 1e-3,\n",
    "        \"awp_period\": 3,\n",
    "        # SWA\n",
    "        \"use_swa\": False,\n",
    "        \"swa_start\": 9400,\n",
    "        \"swa_freq\": 500,\n",
    "    }\n",
    "\n",
    "    gradient_checkpointing = False\n",
    "    acc_steps = 1\n",
    "    epochs = 1\n",
    "\n",
    "    use_fp16 = True\n",
    "\n",
    "    verbose = 1\n",
    "    verbose_eval = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = True\n",
    "log_folder = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not DEBUG:\n",
    "    log_folder = prepare_log_folder(LOG_PATH)\n",
    "    print(f\"Logging results to {log_folder}\")\n",
    "    save_config(Config, log_folder + \"config.json\")\n",
    "    create_logger(directory=log_folder, name=\"logs.txt\")\n",
    "\n",
    "pred_val, pred_test = k_fold(\n",
    "    Config,\n",
    "    df,\n",
    "    df_test=df_test,\n",
    "    log_folder=log_folder\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
