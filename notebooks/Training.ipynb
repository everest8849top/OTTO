{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/kaggle/kgd_barcelona/src\n"
     ]
    }
   ],
   "source": [
    "cd ../src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import json\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils.tokenizers import update_tokenizers\n",
    "# package_path = \"/opt/conda/lib/python3.8/site-packages/transformers\"\n",
    "# input_dir = \"../input/deberta_fast_tokenizer\"\n",
    "\n",
    "# update_tokenizers(package_path, input_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from data.dataset import *\n",
    "from data.processing import *\n",
    "from data.preparation import *\n",
    "from data.tokenization import *\n",
    "\n",
    "from training.main import k_fold\n",
    "from models import NERTransformer\n",
    "\n",
    "# from utils.plot import *\n",
    "from utils.logger import prepare_log_folder, save_config, create_logger\n",
    "\n",
    "from params import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import KFold\n",
    "# K = 4\n",
    "\n",
    "# df = pd.read_csv(DATA_PATH + \"info_train.csv\")\n",
    "\n",
    "# skf = KFold(n_splits=K, shuffle=True, random_state=42)\n",
    "# splits = skf.split(df)\n",
    "\n",
    "# df['fold'] = -1\n",
    "# for i, (_, val_idx) in enumerate(splits):\n",
    "#     df.loc[val_idx, \"fold\"] = i\n",
    "    \n",
    "# df_folds = df[[\"notebook_id\", \"fold\"]]\n",
    "# df_folds.to_csv(f\"/worskpace/folds_kgd_{K}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_and_prepare(DATA_PATH)\n",
    "\n",
    "df_test = load_and_prepare_test(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85249\n",
      "6623\n",
      "2260\n",
      "670\n",
      "163\n"
     ]
    }
   ],
   "source": [
    "print((df['target'] > 0).sum())\n",
    "print((df['target'] > 10).sum())\n",
    "print((df['target'] > 100).sum())\n",
    "print((df['target'] > 1000).sum())\n",
    "print((df['target'] > 10000).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_metric = -1\n",
      "\n",
      "best_metric_epoch = -1\n",
      "\n",
      "epoch_loss_values = list()\n",
      "\n",
      "auc_metric = ROCAUCMetric()\n",
      "\n",
      "metric_values = list()\n",
      "\n",
      "\n",
      "\n",
      "for epoch in range(epoch_num):\n",
      "\n",
      "    print('-' * 10)\n",
      "\n",
      "    print(f\"epoch {epoch + 1}/{epoch_num}\")\n",
      "\n",
      "    model.train()\n",
      "\n",
      "    epoch_loss = 0\n",
      "\n",
      "    step = 0\n",
      "\n",
      "\n",
      "\n",
      "    for batch_data in train_loader:\n",
      "\n",
      "        step += 1\n",
      "\n",
      "        inputs, labels = batch_data[0].to(device), batch_data[1].to(device)\n",
      "\n",
      "        optimizer.zero_grad()\n",
      "\n",
      "        outputs = model(inputs.float())     ##### \n",
      "\n",
      "        loss = loss_function(outputs, labels)\n",
      "\n",
      "        loss.backward()\n",
      "\n",
      "        optimizer.step()\n",
      "\n",
      "        epoch_loss += loss.item()\n",
      "\n",
      "        print(f\"{step}/{len(train_ds) // train_loader.batch_size}, train_loss: {loss.item():.4f}\")\n",
      "\n",
      "        epoch_len = len(train_ds) // train_loader.batch_size\n",
      "\n",
      "\n",
      "\n",
      "    epoch_loss /= step\n",
      "\n",
      "    epoch_loss_values.append(epoch_loss)\n",
      "\n",
      "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
      "\n",
      "\n",
      "\n",
      "    if (epoch + 1) % val_interval == 0:\n",
      "\n",
      "        model.eval()\n",
      "\n",
      "        with torch.no_grad():\n",
      "\n",
      "            y_pred = torch.tensor([], dtype=torch.float32, device=device)\n",
      "\n",
      "            y = torch.tensor([], dtype=torch.long, device=device)\n",
      "\n",
      "            for val_data in val_loader:\n",
      "\n",
      "                val_images, val_labels = val_data[0].to(device), val_data[1].to(device)\n",
      "\n",
      "                y_pred = torch.cat([y_pred, model(val_images.float())], dim=0)\n",
      "\n",
      "                y = torch.cat([y, val_labels], dim=0)\n",
      "\n",
      "                \n",
      "\n",
      "            y_onehot = [to_onehot(i) for i in y]\n",
      "\n",
      "            y_pred_act = [act(i) for i in y_pred]\n",
      "\n",
      "            auc_metric(y_pred_act, y_onehot)\n",
      "\n",
      "            auc_result = auc_metric.aggregate()\n",
      "\n",
      "            auc_metric.reset()\n",
      "\n",
      "            del y_pred_act, y_onehot\n",
      "\n",
      "            metric_values.append(auc_result)\n",
      "\n",
      "            acc_value = torch.eq(y_pred.argmax(dim=1), y)\n",
      "\n",
      "            acc_metric = acc_value.sum().item() / len(acc_value)\n",
      "\n",
      "            \n",
      "\n",
      "            if acc_metric > best_metric:\n",
      "\n",
      "                best_metric = acc_metric\n",
      "\n",
      "                best_metric_epoch = epoch + 1\n",
      "\n",
      "                torch.save(model.state_dict(), 'best_metric_model.pth')\n",
      "\n",
      "                print('saved new best metric model')\n",
      "\n",
      "                \n",
      "\n",
      "            print(f\"current epoch: {epoch + 1} current AUC: {auc_result:.4f}\"\n",
      "\n",
      "                  f\" current accuracy: {acc_metric:.4f} best AUC: {best_metric:.4f}\"\n",
      "\n",
      "                  f\" at epoch: {best_metric_epoch}\")\n",
      "\n",
      "            \n",
      "\n",
      "print(f\"train completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")\n",
      "\n",
      "\n",
      "#################################################\n",
      "\n",
      "best_metric = -1\n",
      "\n",
      "best_metric_epoch = -1\n",
      "\n",
      "epoch_loss_values = list()\n",
      "\n",
      "auc_metric = ROCAUCMetric()\n",
      "\n",
      "metric_values = list()\n",
      "\n",
      "\n",
      "\n",
      "for epoch in range(epoch_num):\n",
      "\n",
      "    print('-' * 10)\n",
      "\n",
      "    print(f\"epoch {epoch + 1}/{epoch_num}\")\n",
      "\n",
      "    model.train()\n",
      "\n",
      "    epoch_loss = 0\n",
      "\n",
      "    step = 0\n",
      "\n",
      "\n",
      "\n",
      "    for batch_data in train_loader:\n",
      "\n",
      "        step += 1\n",
      "\n",
      "        inputs, labels = batch_data[0].to(device), batch_data[1].to(device)\n",
      "\n",
      "        optimizer.zero_grad()\n",
      "\n",
      "        outputs = model(inputs.float())     ##### .float()\n",
      "\n",
      "        loss = loss_function(outputs, labels)\n",
      "\n",
      "        loss.backward()\n",
      "\n",
      "        optimizer.step()\n",
      "\n",
      "        epoch_loss += loss.item()\n",
      "\n",
      "        print(f\"{step}/{len(train_ds) // train_loader.batch_size}, train_loss: {loss.item():.4f}\")\n",
      "\n",
      "        epoch_len = len(train_ds) // train_loader.batch_size\n",
      "\n",
      "\n",
      "\n",
      "    epoch_loss /= step\n",
      "\n",
      "    epoch_loss_values.append(epoch_loss)\n",
      "\n",
      "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
      "\n",
      "\n",
      "\n",
      "    if (epoch + 1) % val_interval == 0:\n",
      "\n",
      "        model.eval()\n",
      "\n",
      "        with torch.no_grad():\n",
      "\n",
      "            y_pred = torch.tensor([], dtype=torch.float32, device=device)\n",
      "\n",
      "            y = torch.tensor([], dtype=torch.long, device=device)\n",
      "\n",
      "            for val_data in val_loader:\n",
      "\n",
      "                val_images, val_labels = val_data[0].to(device), val_data[1].to(device)\n",
      "\n",
      "                y_pred = torch.cat([y_pred, model(val_images)], dim=0)\n",
      "\n",
      "                y = torch.cat([y, val_labels], dim=0)\n",
      "\n",
      "                \n",
      "\n",
      "            y_onehot = [to_onehot(i) for i in y]\n",
      "\n",
      "            y_pred_act = [act(i) for i in y_pred]\n",
      "\n",
      "            auc_metric(y_pred_act, y_onehot)\n",
      "\n",
      "            auc_result = auc_metric.aggregate()\n",
      "\n",
      "            auc_metric.reset()\n",
      "\n",
      "            del y_pred_act, y_onehot\n",
      "\n",
      "            metric_values.append(auc_result)\n",
      "\n",
      "            acc_value = torch.eq(y_pred.argmax(dim=1), y)\n",
      "\n",
      "            acc_metric = acc_value.sum().item() / len(acc_value)\n",
      "\n",
      "            \n",
      "\n",
      "            if acc_metric > best_metric:\n",
      "\n",
      "                best_metric = acc_metric\n",
      "\n",
      "                best_metric_epoch = epoch + 1\n",
      "\n",
      "                torch.save(model.state_dict(), 'best_metric_model.pth')\n",
      "\n",
      "                print('saved new best metric model')\n",
      "\n",
      "                \n",
      "\n",
      "            print(f\"current epoch: {epoch + 1} current AUC: {auc_result:.4f}\"\n",
      "\n",
      "                  f\" current accuracy: {acc_metric:.4f} best AUC: {best_metric:.4f}\"\n",
      "\n",
      "                  f\" at epoch: {best_metric_epoch}\")\n",
      "\n",
      "            \n",
      "\n",
      "print(f\"train completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")\n",
      "\n",
      "\n",
      "#################################################\n",
      "\n",
      "if __name__ == '__main__':\n",
      "\n",
      "    \n",
      "\n",
      "    def get_result(oof_df):\n",
      "\n",
      "        labels = oof_df['discourse_effectiveness'].values\n",
      "\n",
      "        preds = oof_df[['pred_0','pred_1','pred_2']].values\n",
      "\n",
      "        score = get_score(labels, preds)\n",
      "\n",
      "        LOGGER.info(f'Score: {score:<.4f}')\n",
      "\n",
      "    \n",
      "\n",
      "    oof_df = pd.DataFrame()\n",
      "\n",
      "    for fold in range(CFG.n_fold):\n",
      "\n",
      "        if fold in CFG.trn_fold:\n",
      "\n",
      "            _oof_df = train_loop(train, fold)\n",
      "\n",
      "            oof_df = pd.concat([oof_df, _oof_df])\n",
      "\n",
      "            LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
      "\n",
      "            get_result(_oof_df)\n",
      "\n",
      "    oof_df = oof_df.reset_index(drop=True)\n",
      "\n",
      "    LOGGER.info(f\"========== CV ==========\")\n",
      "\n",
      "    get_result(oof_df)\n",
      "\n",
      "    oof_df.to_pickle(OUTPUT_DIR+'oof_df.pkl')\n",
      "\n",
      "        \n",
      "\n",
      "    if CFG.wandb:\n",
      "\n",
      "        wandb.finish()\n",
      "\n",
      "#################################################\n",
      "\n",
      "%%time \n",
      "\n",
      "oof_pred = automl.fit_predict(train_data, roles = roles, verbose = 3)\n",
      "\n",
      "#################################################\n",
      "\n",
      "for fold in range(params['num_fold']):\n",
      "\n",
      "    print(''.join(['#']*51))\n",
      "\n",
      "    print(f\"{''.join(['=']*15)} TRAINING FOLD: {fold+1}/{train_df['kfold'].nunique()} {''.join(['=']*15)}\")\n",
      "\n",
      "    # Data Split to train and Validation\n",
      "\n",
      "    train = train_df[train_df['kfold'] != fold]\n",
      "\n",
      "    valid = train_df[train_df['kfold'] == fold]\n",
      "\n",
      "    \n",
      "\n",
      "    X_train = train['image_path']\n",
      "\n",
      "    y_train = train['label_enc']\n",
      "\n",
      "    X_valid = valid['image_path']\n",
      "\n",
      "    y_valid = valid['label_enc']\n",
      "\n",
      "    \n",
      "\n",
      "    # Pytorch Dataset Creation\n",
      "\n",
      "    train_dataset = PaddyDataset(\n",
      "\n",
      "        images_filepaths=X_train.values,\n",
      "\n",
      "        targets=y_train.values,\n",
      "\n",
      "        transform=get_train_transforms()\n",
      "\n",
      "    )\n",
      "\n",
      "\n",
      "\n",
      "    valid_dataset = PaddyDataset(\n",
      "\n",
      "        images_filepaths=X_valid.values,\n",
      "\n",
      "        targets=y_valid.values,\n",
      "\n",
      "        transform=get_valid_transforms()\n",
      "\n",
      "    )\n",
      "\n",
      "    \n",
      "\n",
      "    # Pytorch Dataloader creation\n",
      "\n",
      "    train_loader = DataLoader(\n",
      "\n",
      "        train_dataset, batch_size=params['batch_size'], shuffle=True,\n",
      "\n",
      "        num_workers=params['num_workers'], pin_memory=True\n",
      "\n",
      "        )\n",
      "\n",
      "\n",
      "\n",
      "    val_loader = DataLoader(\n",
      "\n",
      "        valid_dataset, batch_size=params['batch_size'], shuffle=False,\n",
      "\n",
      "        num_workers=params['num_workers'], pin_memory=True\n",
      "\n",
      "        )\n",
      "\n",
      "    \n",
      "\n",
      "    # Model, cost function and optimizer instancing\n",
      "\n",
      "    model = PaddyNet()\n",
      "\n",
      "    model = model.to(params['device'])\n",
      "\n",
      "    criterion = nn.CrossEntropyLoss()\n",
      "\n",
      "    optimizer = torch.optim.AdamW(model.parameters(), lr=params['lr'],\n",
      "\n",
      "                                  weight_decay=params['weight_decay'],\n",
      "\n",
      "                                  amsgrad=False)\n",
      "\n",
      "    scheduler = get_scheduler(optimizer)\n",
      "\n",
      "\n",
      "\n",
      "    if params['fp16']:\n",
      "\n",
      "        scaler = torch.cuda.amp.GradScaler()\n",
      "\n",
      "    else:\n",
      "\n",
      "        scaler = None\n",
      "\n",
      "    \n",
      "\n",
      "    # Training and Validation Loop\n",
      "\n",
      "    best_accracy = -np.inf\n",
      "\n",
      "    best_epoch = np.inf\n",
      "\n",
      "    best_model_name = None\n",
      "\n",
      "    for epoch in range(1, params['epochs'] + 1):\n",
      "\n",
      "        train_fn(train_loader, model, criterion, optimizer, epoch, params, scheduler, scaler)\n",
      "\n",
      "        predictions, valid_targets = validate_fn(val_loader, model, criterion, epoch, params)\n",
      "\n",
      "        accuracy = round(accuracy_score(valid_targets, predictions), 3)\n",
      "\n",
      "        if accuracy > best_accracy:\n",
      "\n",
      "            best_accracy = accuracy\n",
      "\n",
      "            best_epoch = epoch\n",
      "\n",
      "            if best_model_name is not None:\n",
      "\n",
      "                os.remove(best_model_name)\n",
      "\n",
      "            torch.save(model.state_dict(), f\"{params['model']}_{epoch}_epoch_f{fold+1}_{accuracy}_accuracy.pth\")\n",
      "\n",
      "            best_model_name = f\"{params['model']}_{epoch}_epoch_f{fold+1}_{accuracy}_accuracy.pth\"\n",
      "\n",
      "\n",
      "\n",
      "    # Print summary of this fold\n",
      "\n",
      "    print('')\n",
      "\n",
      "    print(f'The best Accuracy: {best_accracy} for fold {fold+1} was achieved on epoch: {best_epoch}.')\n",
      "\n",
      "    print(f'The Best saved model is: {best_model_name}')\n",
      "\n",
      "    best_models_of_each_fold.append(best_model_name)\n",
      "\n",
      "    accuracy_tracker.append(best_accracy)\n",
      "\n",
      "    print(''.join(['#']*50))\n",
      "\n",
      "    del model\n",
      "\n",
      "    gc.collect()\n",
      "\n",
      "    torch.cuda.empty_cache()\n",
      "\n",
      "\n",
      "\n",
      "print('')\n",
      "\n",
      "print(f'Average Accuracy of all folds: {round(np.mean(accuracy_tracker), 4)}')\n",
      "\n",
      "#################################################\n",
      "\n",
      "if __name__ == '__main__':\n",
      "\n",
      "    \n",
      "\n",
      "    def get_result(oof_df):\n",
      "\n",
      "        #print(oof_df)\n",
      "\n",
      "        labels = oof_df['score'].values\n",
      "\n",
      "        preds = oof_df['pred'].values\n",
      "\n",
      "        score = get_score(labels, preds)\n",
      "\n",
      "        LOGGER.info(f'Score: {score:<.4f}')\n",
      "\n",
      "    \n",
      "\n",
      "    if CFG.train:\n",
      "\n",
      "        oof_df = pd.DataFrame()\n",
      "\n",
      "        for fold in range(CFG.n_fold):\n",
      "\n",
      "            if fold in CFG.trn_fold:\n",
      "\n",
      "                _oof_df = train_loop(train, fold)\n",
      "\n",
      "                oof_df = pd.concat([oof_df, _oof_df])\n",
      "\n",
      "                LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
      "\n",
      "                get_result(_oof_df)\n",
      "\n",
      "        oof_df = oof_df.reset_index(drop=True)\n",
      "\n",
      "        LOGGER.info(f\"========== CV ==========\")\n",
      "\n",
      "        get_result(oof_df)\n",
      "\n",
      "        oof_df.to_pickle(OUTPUT_DIR+'oof_df.pkl')\n",
      "\n",
      "        \n",
      "\n",
      "    if CFG.wandb:\n",
      "\n",
      "        wandb.finish()\n",
      "\n",
      "#################################################\n",
      "\n",
      "for e in range(epoch):\n",
      "\n",
      "    vit_model.train()\n",
      "\n",
      "    print(f\"====================== EPOCH {e+1} ======================\")\n",
      "\n",
      "    print(\"Training.....\")\n",
      "\n",
      "    for i, (data, target) in enumerate(train_dataloader):\n",
      "\n",
      "        optimizer.zero_grad()\n",
      "\n",
      "        output = vit_model(data)\n",
      "\n",
      "        loss = criterion(output, target.view(-1,))\n",
      "\n",
      "        loss.backward()\n",
      "\n",
      "        \n",
      "\n",
      "        nn.utils.clip_grad_norm_(vit_model.parameters(), 3)\n",
      "\n",
      "        accuracy = (output.argmax(dim=1) == target).float().mean()\n",
      "\n",
      "        \n",
      "\n",
      "        loss_history[0].append(loss.item())\n",
      "\n",
      "        accuracy_history[0].append(accuracy)\n",
      "\n",
      "        \n",
      "\n",
      "        optimizer.step()\n",
      "\n",
      "        \n",
      "\n",
      "        print(f\"MINIBATCH {i+1}/{train_dataloader.__len__()} TRAIN ACC : {accuracy_history[0][-1]}  TRAIN LOSS : {loss_history[0][-1]}\")\n",
      "\n",
      "            \n",
      "\n",
      "    \n",
      "\n",
      "    print(\"Validation.....\")\n",
      "\n",
      "    vit_model.eval()\n",
      "\n",
      "    \n",
      "\n",
      "    with torch.no_grad():\n",
      "\n",
      "        for i, (data, target) in enumerate(validation_dataloader):\n",
      "\n",
      "            output = vit_model(data)\n",
      "\n",
      "            loss = criterion(output, target.view(-1,))\n",
      "\n",
      "            accuracy = (output.argmax(dim=1) == target).float().mean()\n",
      "\n",
      "            loss_history[1].append(loss.item())\n",
      "\n",
      "            accuracy_history[1].append(accuracy)\n",
      "\n",
      "        \n",
      "\n",
      "    acc_epoch_history[0].append(sum(accuracy_history[0][-1:-train_dataloader.__len__():-1])/train_dataloader.__len__())\n",
      "\n",
      "    acc_epoch_history[1].append(sum(accuracy_history[1][-1:-validation_dataloader.__len__():-1])/validation_dataloader.__len__())\n",
      "\n",
      "    \n",
      "\n",
      "    loss_epoch_history[0].append(sum(loss_history[0][-1:-train_dataloader.__len__():-1])/train_dataloader.__len__())\n",
      "\n",
      "    loss_epoch_history[1].append(sum(loss_history[1][-1:-validation_dataloader.__len__():-1])/validation_dataloader.__len__())\n",
      "\n",
      "    \n",
      "\n",
      "    print(\"====================================================\")\n",
      "\n",
      "    print(f\"TRAIN ACC : {acc_epoch_history[0][-1]}  TRAIN LOSS : {loss_epoch_history[0][-1]}\")\n",
      "\n",
      "    print(f\"VALL ACC : {acc_epoch_history[1][-1]}  VAL LOSS : {loss_epoch_history[1][-1]}\")\n",
      "\n",
      "    print(\"====================================================\")\n",
      "\n",
      "    \n",
      "\n",
      "    torch.save({\n",
      "\n",
      "            'epoch': e,\n",
      "\n",
      "            'model_state_dict': vit_model.state_dict(),\n",
      "\n",
      "            'optimizer_state_dict': optimizer.state_dict(),\n",
      "\n",
      "            'loss': loss_epoch_history[0][-1],\n",
      "\n",
      "            'acc' : acc_epoch_history[0][-1]\n",
      "\n",
      "            }, './model_checkpoint.pt')\n",
      "\n",
      "#################################################\n",
      "\n",
      "# Reduce trial number of optuna for operation test.\n",
      "\n",
      "N_TRIALS=20\n",
      "\n",
      "N_RANDOM_STATE_VARIATION=2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "result=[]\n",
      "\n",
      "estimators={}\n",
      "\n",
      "for pipe_dataset_dict in pipe_dataset_dict_list:\n",
      "\n",
      "    pipe_name    = pipe_dataset_dict[\"pipe_name\"]\n",
      "\n",
      "    pipe         = pipe_dataset_dict[\"pipe\"]\n",
      "\n",
      "    dataset_name =  pipe_dataset_dict[\"dataset_name\"]\n",
      "\n",
      "    dataset      = pipe_dataset_dict[\"dataset\"]\n",
      "\n",
      "    tmp_train_X,tmp_train_y = dataset\n",
      "\n",
      "    print(f\"### {pipe_name}_{dataset_name} \" + (\"#\"*100))\n",
      "\n",
      "    \n",
      "\n",
      "    # # -----------------------------------------------------------\n",
      "\n",
      "    # # RandomForest + cross_val_score\n",
      "\n",
      "    # model_name = \"randomforest\"\n",
      "\n",
      "    # estimator_name,estimator,score = build_estimator(pipe_name,pipe, model_name, \n",
      "\n",
      "    #                                                  RandomForestRegressor(n_estimators=1000,max_depth=10,random_state=1),\n",
      "\n",
      "    #                                                  dataset_name,tmp_train_X,tmp_train_y,test_X,cv_fit)\n",
      "\n",
      "    # result.append({\"pipe_name\":pipe_name,\"dataset_name\":dataset_name,\"model_name\":model_name,\"estimator_name\":estimator_name,\"score\":score})\n",
      "\n",
      "    # estimators[estimator_name]={\"pipe\":pipe,\"dataset\":dataset,\"estimator\":estimator}\n",
      "\n",
      "    # print()\n",
      "\n",
      "    \n",
      "\n",
      "    # # -----------------------------------------------------------\n",
      "\n",
      "    # # GradientBoosting + cross_val_score\n",
      "\n",
      "    # model_name = \"gradientboosting\"\n",
      "\n",
      "    # estimator_name,estimator,score= build_estimator(pipe_name,pipe, model_name,\n",
      "\n",
      "    #                                                 GradientBoostingRegressor(n_estimators=1000,max_depth=10,random_state=1),\n",
      "\n",
      "    #                                                 dataset_name,tmp_train_X,tmp_train_y,test_X,cv_fit)\n",
      "\n",
      "    # result.append({\"pipe_name\":pipe_name,\"dataset_name\":dataset_name,\"model_name\":model_name,\"estimator_name\":estimator_name,\"score\":score})\n",
      "\n",
      "    # estimators[estimator_name]={\"pipe\":pipe,\"dataset\":dataset,\"estimator\":estimator}\n",
      "\n",
      "    # print()\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    # -----------------------------------------------------------\n",
      "\n",
      "    # XGBoost + OptunaSearchCV, multipled by different random_state\n",
      "\n",
      "    for random_state in range(N_RANDOM_STATE_VARIATION):\n",
      "\n",
      "        model_name = f\"xgb-optuna-{random_state}\"\n",
      "\n",
      "        params_distributions={\n",
      "\n",
      "            'model__n_estimators'     : optuna.distributions.IntUniformDistribution(1000,2000),\n",
      "\n",
      "            # \"model__learning_rate\"    : optuna.distributions.CategoricalDistribution([0.001,0.005,0.01,0.05,0.1]),\n",
      "\n",
      "            # \"model__max_depth\"        : optuna.distributions.IntUniformDistribution(5,10),\n",
      "\n",
      "            # \"model__min_child_weight\" : optuna.distributions.IntUniformDistribution(1,5),\n",
      "\n",
      "            \"model__gamma\"            : optuna.distributions.UniformDistribution(0.,0.5),\n",
      "\n",
      "            \"model__subsample\"        : optuna.distributions.UniformDistribution(0.6,1),\n",
      "\n",
      "            \"model__colsample_bytree\" : optuna.distributions.UniformDistribution(0.6,1),\n",
      "\n",
      "            \"model__reg_alpha\"        : optuna.distributions.UniformDistribution(1e-5,100),\n",
      "\n",
      "            \"model__reg_lambda\"       : optuna.distributions.UniformDistribution(1e-5,1),\n",
      "\n",
      "        }\n",
      "\n",
      "        params={\"n_trials\":N_TRIALS,\"random_state\":random_state, \"params_distributions\":params_distributions}\n",
      "\n",
      "        estimator_name,estimator,score = build_estimator(pipe_name,pipe, model_name,\n",
      "\n",
      "                                                         XGBRegressor(random_state=random_state,learning_rate=0.01,max_depth=6,min_child_weight=1),\n",
      "\n",
      "                                                         dataset_name,tmp_train_X,tmp_train_y,test_X,optuna_cv_fit,**params)\n",
      "\n",
      "        result.append({\"pipe_name\":pipe_name,\"dataset_name\":dataset_name,\"model_name\":model_name,\"estimator_name\":estimator_name,\"score\":score})\n",
      "\n",
      "        estimators[estimator_name]={\"pipe\":pipe,\"dataset\":dataset,\"estimator\":estimator}\n",
      "\n",
      "        print()\n",
      "\n",
      "\n",
      "\n",
      "df_result = pd.DataFrame(result)\n",
      "\n",
      "df_result.index.name=\"exec_order\"\n",
      "\n",
      "#################################################\n",
      "\n",
      "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
      "\n",
      "epoch_number = 0\n",
      "\n",
      "\n",
      "\n",
      "EPOCHS = 12\n",
      "\n",
      "\n",
      "\n",
      "best_vloss = 1_000_000.\n",
      "\n",
      "\n",
      "\n",
      "model.to(device)\n",
      "\n",
      "\n",
      "\n",
      "for epoch in range(EPOCHS):\n",
      "\n",
      "    print('EPOCH {}:'.format(epoch_number + 1))\n",
      "\n",
      "\n",
      "\n",
      "    avg_loss = train(epoch_number)\n",
      "\n",
      "\n",
      "\n",
      "    avg_vloss = test()\n",
      "\n",
      "    print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
      "\n",
      "\n",
      "\n",
      "    if avg_vloss < best_vloss:\n",
      "\n",
      "        best_vloss = avg_vloss\n",
      "\n",
      "        model_path = 'model_{}_{}'.format(timestamp, epoch_number)\n",
      "\n",
      "        torch.save(model.state_dict(), model_path)\n",
      "\n",
      "\n",
      "\n",
      "    epoch_number += 1\n",
      "\n",
      "#################################################\n",
      "\n",
      "best_metric = -1\n",
      "\n",
      "best_metric_epoch = -1\n",
      "\n",
      "epoch_loss_values = list()\n",
      "\n",
      "auc_metric = ROCAUCMetric()\n",
      "\n",
      "metric_values = list()\n",
      "\n",
      "\n",
      "\n",
      "for epoch in range(epoch_num):\n",
      "\n",
      "    print('-' * 10)\n",
      "\n",
      "    print(f\"epoch {epoch + 1}/{epoch_num}\")\n",
      "\n",
      "    model.train()\n",
      "\n",
      "    epoch_loss = 0\n",
      "\n",
      "    step = 0\n",
      "\n",
      "\n",
      "\n",
      "    for batch_data in train_loader:\n",
      "\n",
      "        step += 1\n",
      "\n",
      "        inputs, labels = batch_data[0].to(device), batch_data[1].to(device)\n",
      "\n",
      "        optimizer.zero_grad()\n",
      "\n",
      "        outputs = model(inputs.float())     ##### \n",
      "\n",
      "        loss = loss_function(outputs, labels)\n",
      "\n",
      "        loss.backward()\n",
      "\n",
      "        optimizer.step()\n",
      "\n",
      "        epoch_loss += loss.item()\n",
      "\n",
      "        print(f\"{step}/{len(train_ds) // train_loader.batch_size}, train_loss: {loss.item():.4f}\")\n",
      "\n",
      "        epoch_len = len(train_ds) // train_loader.batch_size\n",
      "\n",
      "\n",
      "\n",
      "    epoch_loss /= step\n",
      "\n",
      "    epoch_loss_values.append(epoch_loss)\n",
      "\n",
      "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
      "\n",
      "\n",
      "\n",
      "    if (epoch + 1) % val_interval == 0:\n",
      "\n",
      "        model.eval()\n",
      "\n",
      "        with torch.no_grad():\n",
      "\n",
      "            y_pred = torch.tensor([], dtype=torch.float32, device=device)\n",
      "\n",
      "            y = torch.tensor([], dtype=torch.long, device=device)\n",
      "\n",
      "            for val_data in val_loader:\n",
      "\n",
      "                val_images, val_labels = val_data[0].to(device), val_data[1].to(device)\n",
      "\n",
      "                y_pred = torch.cat([y_pred, model(val_images.float())], dim=0)\n",
      "\n",
      "                y = torch.cat([y, val_labels], dim=0)\n",
      "\n",
      "                \n",
      "\n",
      "            y_onehot = [to_onehot(i) for i in y]\n",
      "\n",
      "            y_pred_act = [act(i) for i in y_pred]\n",
      "\n",
      "            auc_metric(y_pred_act, y_onehot)\n",
      "\n",
      "            auc_result = auc_metric.aggregate()\n",
      "\n",
      "            auc_metric.reset()\n",
      "\n",
      "            del y_pred_act, y_onehot\n",
      "\n",
      "            metric_values.append(auc_result)\n",
      "\n",
      "            acc_value = torch.eq(y_pred.argmax(dim=1), y)\n",
      "\n",
      "            acc_metric = acc_value.sum().item() / len(acc_value)\n",
      "\n",
      "            \n",
      "\n",
      "            if acc_metric > best_metric:\n",
      "\n",
      "                best_metric = acc_metric\n",
      "\n",
      "                best_metric_epoch = epoch + 1\n",
      "\n",
      "                torch.save(model.state_dict(), 'best_metric_model.pth')\n",
      "\n",
      "                print('saved new best metric model')\n",
      "\n",
      "                \n",
      "\n",
      "            print(f\"current epoch: {epoch + 1} current AUC: {auc_result:.4f}\"\n",
      "\n",
      "                  f\" current accuracy: {acc_metric:.4f} best AUC: {best_metric:.4f}\"\n",
      "\n",
      "                  f\" at epoch: {best_metric_epoch}\")\n",
      "\n",
      "            \n",
      "\n",
      "print(f\"train completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")\n",
      "\n",
      "\n",
      "#################################################\n",
      "\n",
      "for fold in range(1):\n",
      "\n",
      "    print(f'#'*15)\n",
      "\n",
      "    print(f'### Fold: {fold}')\n",
      "\n",
      "    print(f'#'*15)\n",
      "\n",
      "\n",
      "\n",
      "    train_loader, valid_loader = prepare_loaders(fold=fold, debug=CFG.debug)\n",
      "\n",
      "    model     = build_model()\n",
      "\n",
      "    optimizer = optim.Adam(model.parameters(), lr=CFG.lr, weight_decay=CFG.wd)\n",
      "\n",
      "    scheduler = fetch_scheduler(optimizer)\n",
      "\n",
      "    model, history = run_training(model, optimizer, scheduler,\n",
      "\n",
      "                                  device=CFG.device,\n",
      "\n",
      "                                  num_epochs=CFG.epochs)\n",
      "\n",
      "#################################################\n",
      "\n",
      "# make output dir, created default trainer and go ahead)\n",
      "\n",
      "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
      "\n",
      "trainer = DefaultTrainer(cfg) \n",
      "\n",
      "trainer.resume_or_load(resume=False)\n",
      "\n",
      "trainer.train()\n",
      "\n",
      "#################################################\n",
      "\n",
      "# train\n",
      "\n",
      "\n",
      "\n",
      "!echo start training\n",
      "\n",
      "\n",
      "\n",
      "!fairseq-train \\\n",
      "\n",
      "../input/wicopacodatafull/gtc-bt \\\n",
      "\n",
      "--save-dir \"$model_new\" \\\n",
      "\n",
      "--tensorboard-logdir \"$tensorgraph_new\" \\\n",
      "\n",
      "--restore-file \"$model_previous\"/checkpoint_last.pt \\\n",
      "\n",
      "--fp16 \\\n",
      "\n",
      "--arch transformer \\\n",
      "\n",
      "--encoder-layers 6 --decoder-layers 6 \\\n",
      "\n",
      "--encoder-embed-dim 1024 --decoder-embed-dim 1024 \\\n",
      "\n",
      "--encoder-ffn-embed-dim 4096 --decoder-ffn-embed-dim 4096 \\\n",
      "\n",
      "--encoder-attention-heads 16 --decoder-attention-heads 16 \\\n",
      "\n",
      "--share-decoder-input-output-embed \\\n",
      "\n",
      "--optimizer adam --adam-betas '(0.9, 0.997)' --adam-eps 1e-09 --clip-norm 25.0 \\\n",
      "\n",
      "--lr 1e-4 --lr-scheduler inverse_sqrt --warmup-updates 16000 \\\n",
      "\n",
      "--dropout 0.1 --attention-dropout 0.1 --activation-dropout 0.1 \\\n",
      "\n",
      "--weight-decay 0.00025 \\\n",
      "\n",
      "--criterion label_smoothed_cross_entropy --label-smoothing 0.2 \\\n",
      "\n",
      "--max-tokens 4096 \\\n",
      "\n",
      "--no-epoch-checkpoints \\\n",
      "\n",
      "--max-epoch \"$epoch_new\"\n",
      "\n",
      "\n",
      "\n",
      "# ../input/wicopacodatafull/gtc-bt \\\n",
      "\n",
      "# --tpu \\\n",
      "\n",
      "\n",
      "\n",
      "# --max-tokens 4096 \\\n",
      "\n",
      "# --fp16 \\\n",
      "\n",
      "# --bf16 \\\n",
      "\n",
      "# --patience 5 \\\n",
      "\n",
      "# --restore-file modelsbt/checkpoint_last.pt \\\n",
      "\n",
      "# --log-format=json --log-file log.json \\\n",
      "\n",
      "# --restore-file checkpoint_last.pt \\\n",
      "\n",
      "# --tensorboard-logdir ./tensor_graph \\\n",
      "\n",
      "# --no-last-checkpoints \\\n",
      "\n",
      "#################################################\n",
      "\n",
      "import gc\n",
      "\n",
      "# LEARNING_RATE_SUGGESTED = [5.477225568029098e-05, 2.9154431103961542e-05, 0.00024877983378246427, 0.00010290031059412286, 0.00021930268849246204]\n",
      "\n",
      "\n",
      "\n",
      "def fastai_swin_kfolds():\n",
      "\n",
      "    all_preds = []\n",
      "\n",
      "    global TRAINED_MODEL_PATH, TRAINED_MODEL_PATH2\n",
      "\n",
      "    for i in range(N_FOLDS):\n",
      "\n",
      "        if i in [3, 4] and 'beit' in TRAINED_MODEL_PATH:\n",
      "\n",
      "            TRAINED_MODEL_PATH = TRAINED_MODEL_PATH2\n",
      "\n",
      "        print(f'Fold {i} results')\n",
      "\n",
      "        learn = get_learner(fold_num=i)\n",
      "\n",
      "        if KFOLD_TRAIN:\n",
      "\n",
      "            original_model_dir = learn.model_dir\n",
      "\n",
      "            learn.model_dir = PRETRAINED_MODEL_PATH\n",
      "\n",
      "            learn.load(PRETRAINED_MODEL_NAME)\n",
      "\n",
      "            learn.model_dir = original_model_dir\n",
      "\n",
      "            learn.fit_one_cycle(EPOCHS, LEARNING_RATE, cbs=[SaveModelCallback(), EarlyStoppingCallback(monitor='petfinder_rmse', comp=np.less, patience=2)]) \n",
      "\n",
      "\n",
      "\n",
      "            learn.recorder.plot_loss()\n",
      "\n",
      "\n",
      "\n",
      "            learn = learn.to_fp32()\n",
      "\n",
      "            learn.export(f'model_fold_{i}.pkl')\n",
      "\n",
      "            learn.save(f'model_fold_{i}.pkl')\n",
      "\n",
      "\n",
      "\n",
      "        else:\n",
      "\n",
      "            learn.model_dir = TRAINED_MODEL_PATH\n",
      "\n",
      "            learn.load(f'model_fold_{i}.pkl')\n",
      "\n",
      "\n",
      "\n",
      "        dls = ImageDataLoaders.from_df(train_df, #pass in train DataFrame\n",
      "\n",
      "                                       valid_pct=0.2, #80-20 train-validation random split\n",
      "\n",
      "                                       seed=SEED, #seed\n",
      "\n",
      "                                       fn_col='path', #filename/path is in the second column of the DataFrame\n",
      "\n",
      "                                       label_col='norm_score', #label is in the first column of the DataFrame\n",
      "\n",
      "                                       y_block=RegressionBlock, #The type of target\n",
      "\n",
      "                                       bs=BATCH_SIZE, #pass in batch size\n",
      "\n",
      "                                       num_workers=WORKERS,\n",
      "\n",
      "                                       item_tfms=Resize(IMAGE_SIZE), #pass in item_tfms\n",
      "\n",
      "                                       batch_tfms=setup_aug_tfms([Brightness(), Contrast(), Hue(), Saturation()])) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "        test_dl = dls.test_dl(test_df)\n",
      "\n",
      "\n",
      "\n",
      "        preds, _ = learn.tta(dl=test_dl, n=5, beta=0)\n",
      "\n",
      "\n",
      "\n",
      "        all_preds.append(preds)\n",
      "\n",
      "\n",
      "\n",
      "        del learn\n",
      "\n",
      "\n",
      "\n",
      "        torch.cuda.empty_cache()\n",
      "\n",
      "\n",
      "\n",
      "        gc.collect()\n",
      "\n",
      "\n",
      "\n",
      "    preds = np.mean(np.stack(all_preds), axis=0)\n",
      "\n",
      "    # preds = preds*100\n",
      "\n",
      "    return preds\n",
      "\n",
      "\n",
      "\n",
      "if USE_FASTAI_SWIN:\n",
      "\n",
      "    KFOLD_TRAIN = True\n",
      "\n",
      "    BATCH_SIZE = 8 # when inference. train 시는 batch size 8로 해야\n",
      "\n",
      "    MODEL_NAME = 'swin_large_patch4_window12_384'\n",
      "\n",
      "    IMAGE_SIZE = 384 \n",
      "\n",
      "    TRAINED_MODEL_PATH = \"../input/petfinder-trained-model-16p52-384-v2\"\n",
      "\n",
      "    preds2 = fastai_swin_kfolds()\n",
      "\n",
      "    \n",
      "\n",
      "#     MODEL_NAME = 'swin_large_patch4_window7_224'\n",
      "\n",
      "#     IMAGE_SIZE = 224 \n",
      "\n",
      "#     TRAINED_MODEL_PATH = \"../input/petfinder-trained-model-16p67-224-v2\"\n",
      "\n",
      "#     preds3 = fastai_swin_kfolds()\n",
      "\n",
      "    \n",
      "\n",
      "#     MODEL_NAME = 'beit_large_patch16_224'\n",
      "\n",
      "#     IMAGE_SIZE = 224 \n",
      "\n",
      "#     TRAINED_MODEL_PATH = \"../input/petfinder-trained-model-beit-224-rmse16p83-v1\"\n",
      "\n",
      "#     TRAINED_MODEL_PATH2 = \"../input/petfinder-trained-model-beit-224-rmse16p85-v1-2\"\n",
      "\n",
      "#     preds4 = fastai_swin_kfolds()\n",
      "\n",
      "#################################################\n",
      "\n",
      "class args:\n",
      "\n",
      "    epochs = 10\n",
      "\n",
      "    lr = 1e-3\n",
      "\n",
      "    batch_size = 32\n",
      "\n",
      "    num_workers = 2\n",
      "\n",
      "    embed_size = 2048\n",
      "\n",
      "    val_samples = 1\n",
      "\n",
      "    backbone_name=\"densenet161\"\n",
      "\n",
      "    n_classes = data_df[\"hotel_id_code\"].nunique()\n",
      "\n",
      "    device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
      "\n",
      "    continue_from_checkpoint = False\n",
      "\n",
      "\n",
      "\n",
      "train_and_validate(args, data_df)\n",
      "\n",
      "#################################################\n",
      "\n",
      "if __name__ == '__main__':\n",
      "\n",
      "    \n",
      "\n",
      "    def get_result(oof_df):\n",
      "\n",
      "        labels = oof_df['discourse_effectiveness'].values\n",
      "\n",
      "        preds = oof_df[['pred_0','pred_1','pred_2']].values\n",
      "\n",
      "        score = get_score(labels, preds)\n",
      "\n",
      "        LOGGER.info(f'Score: {score:<.4f}')\n",
      "\n",
      "    \n",
      "\n",
      "    oof_df = pd.DataFrame()\n",
      "\n",
      "    for fold in range(CFG.n_fold):\n",
      "\n",
      "        if fold in CFG.trn_fold:\n",
      "\n",
      "            _oof_df = train_loop(train, fold)\n",
      "\n",
      "            oof_df = pd.concat([oof_df, _oof_df])\n",
      "\n",
      "            LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
      "\n",
      "            get_result(_oof_df)\n",
      "\n",
      "    oof_df = oof_df.reset_index(drop=True)\n",
      "\n",
      "    LOGGER.info(f\"========== CV ==========\")\n",
      "\n",
      "    get_result(oof_df)\n",
      "\n",
      "    oof_df.to_pickle(OUTPUT_DIR+'oof_df.pkl')\n",
      "\n",
      "        \n",
      "\n",
      "    if CFG.wandb:\n",
      "\n",
      "        wandb.finish()\n",
      "\n",
      "#################################################\n",
      "\n",
      "if __name__ == '__main__':\n",
      "\n",
      "    kf = StratifiedKFold(n_splits=Config['N_SPLITS'])\n",
      "\n",
      "    train_file = pd.read_csv(Config['CSV_PATH'])\n",
      "\n",
      "    train_file['discourse_effectiveness'] = train_file['discourse_effectiveness'].map(\n",
      "\n",
      "        {'Ineffective': 0, 'Adequate': 1, 'Effective': 2}\n",
      "\n",
      "    )\n",
      "\n",
      "    train_file['essay'] = train_file['essay_id'].apply(fetchEssay)\n",
      "\n",
      "    train_file['text'] = train_file['discourse_text'] + ' [SEP] ' + train_file['essay']\n",
      "\n",
      "    train_file = train_file.drop(['discourse_text', 'essay'], axis=1)\n",
      "\n",
      "    \n",
      "\n",
      "    for fold_, (train_idx, valid_idx) in enumerate(kf.split(X=train_file, y=train_file['essay_id'])):\n",
      "\n",
      "        print(f\"{'='*40} Fold: {fold_+1} / {Config['N_SPLITS']} {'='*40}\")\n",
      "\n",
      "        \n",
      "\n",
      "        train_ = train_file.loc[train_idx]\n",
      "\n",
      "        valid_ = train_file.loc[valid_idx]\n",
      "\n",
      "        \n",
      "\n",
      "        train_set = BERTDataset(\n",
      "\n",
      "            data = train_,\n",
      "\n",
      "            config = Config,\n",
      "\n",
      "        )\n",
      "\n",
      "        valid_set = BERTDataset(\n",
      "\n",
      "            data = valid_,\n",
      "\n",
      "            config = Config,\n",
      "\n",
      "        )\n",
      "\n",
      "        \n",
      "\n",
      "        train_loader = DataLoader(\n",
      "\n",
      "            train_set,\n",
      "\n",
      "            batch_size = Config['TRAIN_BS'],\n",
      "\n",
      "            shuffle = True,\n",
      "\n",
      "            num_workers = Config['NUM_WORKERS'],\n",
      "\n",
      "            pin_memory = True\n",
      "\n",
      "        )\n",
      "\n",
      "        \n",
      "\n",
      "        valid_loader = DataLoader(\n",
      "\n",
      "            valid_set,\n",
      "\n",
      "            batch_size = Config['VALID_BS'],\n",
      "\n",
      "            shuffle = False,\n",
      "\n",
      "            num_workers = Config['NUM_WORKERS'],\n",
      "\n",
      "        )\n",
      "\n",
      "        \n",
      "\n",
      "        model = BERTModel(backbone_arch=Config['MODEL_NAME'])\n",
      "\n",
      "        model = model.to(torch.device(Config['DEVICE']))\n",
      "\n",
      "        \n",
      "\n",
      "        # Log model to WandB\n",
      "\n",
      "        wandb.watch(model)\n",
      "\n",
      "            \n",
      "\n",
      "        optimizer = torch.optim.AdamW(model.parameters(), lr=Config['LR'])\n",
      "\n",
      "        scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
      "\n",
      "            optimizer, \n",
      "\n",
      "            T_0=Config['T_0'], \n",
      "\n",
      "            eta_min=Config['η_min']\n",
      "\n",
      "        )\n",
      "\n",
      "        train_lfn, valid_lfn = nn.CrossEntropyLoss(), nn.CrossEntropyLoss()\n",
      "\n",
      "        \n",
      "\n",
      "        trainer = Trainer(\n",
      "\n",
      "            config = Config,\n",
      "\n",
      "            dataloaders=(train_loader, valid_loader),\n",
      "\n",
      "            loss_fns=(train_lfn, valid_lfn),\n",
      "\n",
      "            optimizer=optimizer,\n",
      "\n",
      "            model = model,\n",
      "\n",
      "            scheduler=scheduler,\n",
      "\n",
      "            apex=True\n",
      "\n",
      "        )\n",
      "\n",
      "        \n",
      "\n",
      "        trainer.fit(\n",
      "\n",
      "            fold = fold_,\n",
      "\n",
      "            epochs = Config['NB_EPOCHS'],\n",
      "\n",
      "            custom_name = f\"{Config['MODEL_NAME']}_fold_{fold_}.bin\"\n",
      "\n",
      "        )\n",
      "\n",
      "#################################################\n",
      "\n",
      "X_train, X_test, y_train, y_test = train_test_split(character_images, df.character, test_size=0.2, random_state=42, shuffle=True)\n",
      "\n",
      "Xr_train, Xr_test, yr_train, yr_test = train_test_split(pca_reduced_images, df.character, test_size=0.2, random_state=42, shuffle=True)\n",
      "\n",
      "\n",
      "\n",
      "f_global = True\n",
      "\n",
      "r_global = True\n",
      "\n",
      "plot_cm_global = False\n",
      "\n",
      "print_report_global = False\n",
      "\n",
      "plot_samples_global = True\n",
      "\n",
      "\n",
      "\n",
      "def run_and_gather(estimator, X_train, y_train, X_test, y_test, plot_cm=False, print_report=False, plot_samples=False):\n",
      "\n",
      "    start = time()\n",
      "\n",
      "    estimator.fit(X_train, y_train)\n",
      "\n",
      "    mid = time()\n",
      "\n",
      "    predicted = estimator.predict(X_test)\n",
      "\n",
      "    end = time()\n",
      "\n",
      "    \n",
      "\n",
      "    if plot_samples:\n",
      "\n",
      "        images_and_predictions = list(zip(images[y_test.index], predicted))\n",
      "\n",
      "        fig, ax = plt.subplots(1, 10, figsize=(16, 16))\n",
      "\n",
      "        for axis, (image, prediction) in zip(ax[:], images_and_predictions[13000:13010]):\n",
      "\n",
      "            axis.set_axis_off()\n",
      "\n",
      "            axis.imshow(image)\n",
      "\n",
      "            axis.set_title('Pred: %s' % prediction.split(\"_\")[-1])\n",
      "\n",
      "\n",
      "\n",
      "        plt.subplots_adjust(wspace=0.5)\n",
      "\n",
      "        \n",
      "\n",
      "        plt.show()\n",
      "\n",
      "\n",
      "\n",
      "    if print_report:\n",
      "\n",
      "        print(\"Classification report for classifier %s:\\n%s\\n\"\n",
      "\n",
      "          % (estimator, metrics.classification_report(y_test, predicted)))\n",
      "\n",
      "\n",
      "\n",
      "    if plot_cm:\n",
      "\n",
      "        disp = metrics.plot_confusion_matrix(estimator, X_test, y_test)\n",
      "\n",
      "#        print(\"Confusion matrix:\\n%s\" % disp.confusion_matrix)\n",
      "\n",
      "        disp.figure_.set_size_inches(16, 16)\n",
      "\n",
      "        plt.xticks(rotation=75)\n",
      "\n",
      "        plt.subplots_adjust(left=-2)\n",
      "\n",
      "\n",
      "\n",
      "        plt.show()\n",
      "\n",
      "\n",
      "\n",
      "    return accuracy_score(y_test, predicted), mid - start, end - mid\n",
      "\n",
      "\n",
      "\n",
      "def orchestrate(classifiers):\n",
      "\n",
      "    for name, f_feas, r_feas, clf, plot_cm, print_report, plot_samples in classifiers:\n",
      "\n",
      "        lst = [name]\n",
      "\n",
      "        print(name)\n",
      "\n",
      "        clf_f = clf\n",
      "\n",
      "        clf_r = clf\n",
      "\n",
      "    \n",
      "\n",
      "        retval_f = []\n",
      "\n",
      "        retval_r = []\n",
      "\n",
      "\n",
      "\n",
      "        if plot_cm_global == False:\n",
      "\n",
      "            plot_cm = False\n",
      "\n",
      "        \n",
      "\n",
      "        if print_report_global == False:\n",
      "\n",
      "            print_report = False\n",
      "\n",
      "        \n",
      "\n",
      "        if plot_samples_global == False:\n",
      "\n",
      "            plot_samples = False\n",
      "\n",
      "\n",
      "\n",
      "        if (f_global & f_feas):\n",
      "\n",
      "            print(\"Calling %s on full dimension data set\" % (name))\n",
      "\n",
      "            retval_f = run_and_gather(clf_f, X_train, y_train, X_test, y_test, plot_cm, print_report, plot_samples)\n",
      "\n",
      "        else:\n",
      "\n",
      "            print(\"Skipping %s on full dimension data set\" % (name))\n",
      "\n",
      "            retval_f = [0.0, 0.0, 0.0]\n",
      "\n",
      "        lst.extend(retval_f)\n",
      "\n",
      "\n",
      "\n",
      "        if (r_global & r_feas):\n",
      "\n",
      "            print(\"Calling %s on reduced dimension data set\" % (name))\n",
      "\n",
      "            retval_r = run_and_gather(clf_r, Xr_train, yr_train, Xr_test, yr_test, plot_cm, print_report, plot_samples)\n",
      "\n",
      "        else:\n",
      "\n",
      "            print(\"Skipping %s on reduced dimension data set\" % (name))\n",
      "\n",
      "            retval_r = [0.0, 0.0, 0.0]\n",
      "\n",
      "        lst.extend(retval_r)\n",
      "\n",
      "        results.append(lst)\n",
      "\n",
      "    #    print(lst)\n",
      "\n",
      "        print()\n",
      "\n",
      "\n",
      "\n",
      "orchestrate(classifiers)\n",
      "\n",
      "#print(results)\n",
      "\n",
      "#################################################\n",
      "\n",
      "Xs = {}\n",
      "\n",
      "ys = {}\n",
      "\n",
      "models = {}\n",
      "\n",
      "\n",
      "\n",
      "for asset_id, asset_name in zip(df_asset_details['Asset_ID'], df_asset_details['Asset_Name']):\n",
      "\n",
      "    print(f\"Training model for {asset_name:<16} (ID={asset_id:<2})\")\n",
      "\n",
      "    X, y, model = get_Xy_and_model_for_asset(df_train, asset_id)    \n",
      "\n",
      "    Xs[asset_id], ys[asset_id], models[asset_id] = X, y, model\n",
      "\n",
      "#################################################\n",
      "\n",
      "# list with predicted InChI's\n",
      "\n",
      "predictions_inchi = []\n",
      "\n",
      "# List with image id's\n",
      "\n",
      "predictions_img_ids = []\n",
      "\n",
      "# Distributed test set, needed for TPU\n",
      "\n",
      "test_dist_dataset = strategy.experimental_distribute_dataset(test_dataset)\n",
      "\n",
      "\n",
      "\n",
      "# Prediction Loop\n",
      "\n",
      "for step, (per_replica_imgs, per_repliac_img_ids) in tqdm(enumerate(test_dist_dataset), total=N_TEST_STEPS):\n",
      "\n",
      "    # special step for last batch which has a different size\n",
      "\n",
      "    # this step will take about half a minute because the function needs to be compiled\n",
      "\n",
      "    if TPU and step == N_TEST_STEPS - 1:\n",
      "\n",
      "        imgs_single_device = strategy.gather(per_replica_imgs, axis=0)\n",
      "\n",
      "        preds = test_step_last_batch(imgs_single_device)\n",
      "\n",
      "    else:\n",
      "\n",
      "        # make test step and get predictions\n",
      "\n",
      "        preds = distributed_test_step(per_replica_imgs)\n",
      "\n",
      "    \n",
      "\n",
      "    # get image ids\n",
      "\n",
      "    img_ids = strategy.gather(per_repliac_img_ids, axis=0)\n",
      "\n",
      "    \n",
      "\n",
      "    # decode integer encoded predictions to characters and add to InChI's prediction list\n",
      "\n",
      "    predictions_inchi += [int2char(p) for p in preds.numpy()]\n",
      "\n",
      "    # add image id's to list\n",
      "\n",
      "    predictions_img_ids += [e.decode() for e in img_ids.numpy()]\n",
      "\n",
      "#################################################\n",
      "\n",
      "def read_data(data):\n",
      "\n",
      "    return tuple(d.cuda() for d in data[:-1]), data[-1].cuda()\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "def validate(model, val_loader):\n",
      "\n",
      "    model.eval()\n",
      "\n",
      "    \n",
      "\n",
      "    tbar = tqdm(val_loader, file=sys.stdout)\n",
      "\n",
      "    \n",
      "\n",
      "    preds = []\n",
      "\n",
      "    labels = []\n",
      "\n",
      "\n",
      "\n",
      "    with torch.no_grad():\n",
      "\n",
      "        for idx, data in enumerate(tbar):\n",
      "\n",
      "            inputs, target = read_data(data)\n",
      "\n",
      "\n",
      "\n",
      "            pred = model(inputs[0], inputs[1])\n",
      "\n",
      "\n",
      "\n",
      "            preds.append(pred.detach().cpu().numpy().ravel())\n",
      "\n",
      "            labels.append(target.detach().cpu().numpy().ravel())\n",
      "\n",
      "    return np.concatenate(labels), np.concatenate(preds)\n",
      "\n",
      "\n",
      "\n",
      "def train(model, train_loader, val_loader, epochs):\n",
      "\n",
      "    np.random.seed(0)\n",
      "\n",
      "    \n",
      "\n",
      "    optimizer = get_optimizer(model)\n",
      "\n",
      "\n",
      "\n",
      "    criterion = torch.nn.L1Loss()\n",
      "\n",
      "    \n",
      "\n",
      "    for e in range(epochs):   \n",
      "\n",
      "        model.train()\n",
      "\n",
      "        tbar = tqdm(train_loader, file=sys.stdout)\n",
      "\n",
      "        \n",
      "\n",
      "        lr = adjust_lr(optimizer, e)\n",
      "\n",
      "        \n",
      "\n",
      "        loss_list = []\n",
      "\n",
      "        preds = []\n",
      "\n",
      "        labels = []\n",
      "\n",
      "\n",
      "\n",
      "        for idx, data in enumerate(tbar):\n",
      "\n",
      "            inputs, target = read_data(data)\n",
      "\n",
      "\n",
      "\n",
      "            optimizer.zero_grad()\n",
      "\n",
      "            pred = model(inputs[0], inputs[1])\n",
      "\n",
      "\n",
      "\n",
      "            loss = criterion(pred, target)\n",
      "\n",
      "            loss.backward()\n",
      "\n",
      "            optimizer.step()\n",
      "\n",
      "            \n",
      "\n",
      "            loss_list.append(loss.detach().cpu().item())\n",
      "\n",
      "            preds.append(pred.detach().cpu().numpy().ravel())\n",
      "\n",
      "            labels.append(target.detach().cpu().numpy().ravel())\n",
      "\n",
      "            \n",
      "\n",
      "            avg_loss = np.round(np.mean(loss_list), 4)\n",
      "\n",
      "\n",
      "\n",
      "            tbar.set_description(f\"Epoch {e+1} Loss: {avg_loss} lr: {lr}\")\n",
      "\n",
      "            \n",
      "\n",
      "        y_val, y_pred = validate(model, val_loader)\n",
      "\n",
      "            \n",
      "\n",
      "        val_df[\"pred\"] = val_df.groupby([\"id\", \"cell_type\"])[\"rank\"].rank(pct=True)\n",
      "\n",
      "        val_df.loc[val_df[\"cell_type\"] == \"markdown\", \"pred\"] = y_pred\n",
      "\n",
      "\n",
      "\n",
      "        y_dummy = val_df.sort_values(\"pred\").groupby('id')['cell_id'].apply(list)\n",
      "\n",
      "        score = kendall_tau(df_orders.loc[y_dummy.index], y_dummy)\n",
      "\n",
      "\n",
      "\n",
      "        print('score : ', score)\n",
      "\n",
      "\n",
      "\n",
      "        output_model_file = f\"./my_own_model_file_{e}_{np.round(score, 5)}.bin\"\n",
      "\n",
      "        model_to_save = model.module if hasattr(model, 'module') else model\n",
      "\n",
      "        torch.save(model_to_save.state_dict(), output_model_file)\n",
      "\n",
      "                        \n",
      "\n",
      "        print(\"Validation MSE:\", np.round(mean_squared_error(y_val, y_pred), 4))\n",
      "\n",
      "        print()\n",
      "\n",
      "    return model, y_pred\n",
      "\n",
      "\n",
      "\n",
      "model = MarkdownModel()\n",
      "\n",
      "model = model.cuda()\n",
      "\n",
      "# model.load_state_dict(torch.load('../input/model-markdown-3/model.bin'))\n",
      "\n",
      "model, y_pred = train(model, train_loader, val_loader, epochs=1)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "torch.save(model.state_dict(), './model.bin')\n",
      "\n",
      "#################################################\n",
      "\n",
      "best_metric = -1\n",
      "\n",
      "best_metric_epoch = -1\n",
      "\n",
      "epoch_loss_values = list()\n",
      "\n",
      "auc_metric = ROCAUCMetric()\n",
      "\n",
      "metric_values = list()\n",
      "\n",
      "\n",
      "\n",
      "for epoch in range(epoch_num):\n",
      "\n",
      "    print('-' * 10)\n",
      "\n",
      "    print(f\"epoch {epoch + 1}/{epoch_num}\")\n",
      "\n",
      "    model.train()\n",
      "\n",
      "    epoch_loss = 0\n",
      "\n",
      "    step = 0\n",
      "\n",
      "\n",
      "\n",
      "    for batch_data in train_loader:\n",
      "\n",
      "        step += 1\n",
      "\n",
      "        inputs, labels = batch_data[0].to(device), batch_data[1].to(device)\n",
      "\n",
      "        optimizer.zero_grad()\n",
      "\n",
      "        outputs = model(inputs.float())     ##### \n",
      "\n",
      "        loss = loss_function(outputs, labels)\n",
      "\n",
      "        loss.backward()\n",
      "\n",
      "        optimizer.step()\n",
      "\n",
      "        epoch_loss += loss.item()\n",
      "\n",
      "        print(f\"{step}/{len(train_ds) // train_loader.batch_size}, train_loss: {loss.item():.4f}\")\n",
      "\n",
      "        epoch_len = len(train_ds) // train_loader.batch_size\n",
      "\n",
      "\n",
      "\n",
      "    epoch_loss /= step\n",
      "\n",
      "    epoch_loss_values.append(epoch_loss)\n",
      "\n",
      "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
      "\n",
      "\n",
      "\n",
      "    if (epoch + 1) % val_interval == 0:\n",
      "\n",
      "        model.eval()\n",
      "\n",
      "        with torch.no_grad():\n",
      "\n",
      "            y_pred = torch.tensor([], dtype=torch.float32, device=device)\n",
      "\n",
      "            y = torch.tensor([], dtype=torch.long, device=device)\n",
      "\n",
      "            for val_data in val_loader:\n",
      "\n",
      "                val_images, val_labels = val_data[0].to(device), val_data[1].to(device)\n",
      "\n",
      "                y_pred = torch.cat([y_pred, model(val_images.float())], dim=0)\n",
      "\n",
      "                y = torch.cat([y, val_labels], dim=0)\n",
      "\n",
      "                \n",
      "\n",
      "            y_onehot = [to_onehot(i) for i in y]\n",
      "\n",
      "            y_pred_act = [act(i) for i in y_pred]\n",
      "\n",
      "            auc_metric(y_pred_act, y_onehot)\n",
      "\n",
      "            auc_result = auc_metric.aggregate()\n",
      "\n",
      "            auc_metric.reset()\n",
      "\n",
      "            del y_pred_act, y_onehot\n",
      "\n",
      "            metric_values.append(auc_result)\n",
      "\n",
      "            acc_value = torch.eq(y_pred.argmax(dim=1), y)\n",
      "\n",
      "            acc_metric = acc_value.sum().item() / len(acc_value)\n",
      "\n",
      "            \n",
      "\n",
      "            if acc_metric > best_metric:\n",
      "\n",
      "                best_metric = acc_metric\n",
      "\n",
      "                best_metric_epoch = epoch + 1\n",
      "\n",
      "                torch.save(model.state_dict(), 'best_metric_model.pth')\n",
      "\n",
      "                print('saved new best metric model')\n",
      "\n",
      "                \n",
      "\n",
      "            print(f\"current epoch: {epoch + 1} current AUC: {auc_result:.4f}\"\n",
      "\n",
      "                  f\" current accuracy: {acc_metric:.4f} best AUC: {best_metric:.4f}\"\n",
      "\n",
      "                  f\" at epoch: {best_metric_epoch}\")\n",
      "\n",
      "            \n",
      "\n",
      "print(f\"train completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")\n",
      "\n",
      "\n",
      "#################################################\n",
      "\n",
      "for i, (train_index, val_index) in enumerate(KFold(n_splits=N_SPLITS).split(range(N_SPLITS))):\n",
      "\n",
      "    if TPU is not None:\n",
      "\n",
      "        tf.tpu.experimental.initialize_tpu_system(TPU)\n",
      "\n",
      "\n",
      "\n",
      "    train_filenames = np.ravel(\n",
      "\n",
      "        [\n",
      "\n",
      "            tf.io.gfile.glob(os.path.join(GCS_PATH, \"tfrec\", str(x), \"*.tfrec\"))\n",
      "\n",
      "            for x in train_index\n",
      "\n",
      "        ]\n",
      "\n",
      "    )\n",
      "\n",
      "    steps_per_epoch = count_samples(train_filenames) // BATCH_SIZE\n",
      "\n",
      "    train_dataset = get_dataset(train_filenames)\n",
      "\n",
      "\n",
      "\n",
      "    val_filenames = np.ravel(\n",
      "\n",
      "        [\n",
      "\n",
      "            tf.io.gfile.glob(os.path.join(GCS_PATH, \"tfrec\", str(x), \"*.tfrec\"))\n",
      "\n",
      "            for x in val_index\n",
      "\n",
      "        ]\n",
      "\n",
      "    )\n",
      "\n",
      "    validation_steps = count_samples(val_filenames) // BATCH_SIZE\n",
      "\n",
      "    val_dataset = get_dataset(val_filenames, ordered=True, repeated=False, cached=True)\n",
      "\n",
      "\n",
      "\n",
      "    with STRATEGY.scope():\n",
      "\n",
      "        model = get_model()\n",
      "\n",
      "\n",
      "\n",
      "        total_steps = steps_per_epoch * EPOCHS\n",
      "\n",
      "        warmup_steps = int(WARMUP_RATE * total_steps)\n",
      "\n",
      "\n",
      "\n",
      "        optimizer = transformers.AdamWeightDecay(\n",
      "\n",
      "            learning_rate=WarmupLinearDecay(\n",
      "\n",
      "                base_learning_rate=LR,\n",
      "\n",
      "                warmup_steps=warmup_steps,\n",
      "\n",
      "                total_steps=total_steps,\n",
      "\n",
      "            ),\n",
      "\n",
      "            weight_decay_rate=0.01,\n",
      "\n",
      "            exclude_from_weight_decay=[\n",
      "\n",
      "                \"bias\",\n",
      "\n",
      "                \"LayerNorm.bias\",\n",
      "\n",
      "                \"LayerNorm.weight\",\n",
      "\n",
      "            ],\n",
      "\n",
      "        )\n",
      "\n",
      "        model.compile(loss=\"mae\", optimizer=optimizer)\n",
      "\n",
      "\n",
      "\n",
      "    metrics = model.fit(\n",
      "\n",
      "        train_dataset,\n",
      "\n",
      "        steps_per_epoch=steps_per_epoch,\n",
      "\n",
      "        validation_data=val_dataset,\n",
      "\n",
      "        validation_steps=validation_steps,\n",
      "\n",
      "        epochs=EPOCHS,\n",
      "\n",
      "        verbose=VERBOSE,\n",
      "\n",
      "    ).history\n",
      "\n",
      "\n",
      "\n",
      "    model.save_weights(f\"model_{i}.h5\")\n",
      "\n",
      "    break\n",
      "\n",
      "#################################################\n",
      "\n",
      "#learn.fit_one_cycle(10,1e-2, 1e-1)\n",
      "\n",
      "learn.fine_tune(10,base_lr= 1e-7)\n",
      "\n",
      "interp = ClassificationInterpretation.from_learner(learn)\n",
      "\n",
      "interp.plot_confusion_matrix()\n",
      "\n",
      "#################################################\n",
      "\n",
      "best_metric = -1\n",
      "\n",
      "best_metric_epoch = -1\n",
      "\n",
      "epoch_loss_values = list()\n",
      "\n",
      "auc_metric = ROCAUCMetric()\n",
      "\n",
      "metric_values = list()\n",
      "\n",
      "\n",
      "\n",
      "for epoch in range(epoch_num):\n",
      "\n",
      "    print('-' * 10)\n",
      "\n",
      "    print(f\"epoch {epoch + 1}/{epoch_num}\")\n",
      "\n",
      "    model.train()\n",
      "\n",
      "    epoch_loss = 0\n",
      "\n",
      "    step = 0\n",
      "\n",
      "\n",
      "\n",
      "    for batch_data in train_loader:\n",
      "\n",
      "        step += 1\n",
      "\n",
      "        inputs, labels = batch_data[0].to(device), batch_data[1].to(device)\n",
      "\n",
      "        optimizer.zero_grad()\n",
      "\n",
      "        outputs = model(inputs.float())     ##### .float()\n",
      "\n",
      "        loss = loss_function(outputs, labels)\n",
      "\n",
      "        loss.backward()\n",
      "\n",
      "        optimizer.step()\n",
      "\n",
      "        epoch_loss += loss.item()\n",
      "\n",
      "        print(f\"{step}/{len(train_ds) // train_loader.batch_size}, train_loss: {loss.item():.4f}\")\n",
      "\n",
      "        epoch_len = len(train_ds) // train_loader.batch_size\n",
      "\n",
      "\n",
      "\n",
      "    epoch_loss /= step\n",
      "\n",
      "    epoch_loss_values.append(epoch_loss)\n",
      "\n",
      "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
      "\n",
      "\n",
      "\n",
      "    if (epoch + 1) % val_interval == 0:\n",
      "\n",
      "        model.eval()\n",
      "\n",
      "        with torch.no_grad():\n",
      "\n",
      "            y_pred = torch.tensor([], dtype=torch.float32, device=device)\n",
      "\n",
      "            y = torch.tensor([], dtype=torch.long, device=device)\n",
      "\n",
      "            for val_data in val_loader:\n",
      "\n",
      "                val_images, val_labels = val_data[0].to(device), val_data[1].to(device)\n",
      "\n",
      "                y_pred = torch.cat([y_pred, model(val_images)], dim=0)\n",
      "\n",
      "                y = torch.cat([y, val_labels], dim=0)\n",
      "\n",
      "                \n",
      "\n",
      "            y_onehot = [to_onehot(i) for i in y]\n",
      "\n",
      "            y_pred_act = [act(i) for i in y_pred]\n",
      "\n",
      "            auc_metric(y_pred_act, y_onehot)\n",
      "\n",
      "            auc_result = auc_metric.aggregate()\n",
      "\n",
      "            auc_metric.reset()\n",
      "\n",
      "            del y_pred_act, y_onehot\n",
      "\n",
      "            metric_values.append(auc_result)\n",
      "\n",
      "            acc_value = torch.eq(y_pred.argmax(dim=1), y)\n",
      "\n",
      "            acc_metric = acc_value.sum().item() / len(acc_value)\n",
      "\n",
      "            \n",
      "\n",
      "            if acc_metric > best_metric:\n",
      "\n",
      "                best_metric = acc_metric\n",
      "\n",
      "                best_metric_epoch = epoch + 1\n",
      "\n",
      "                torch.save(model.state_dict(), 'best_metric_model.pth')\n",
      "\n",
      "                print('saved new best metric model')\n",
      "\n",
      "                \n",
      "\n",
      "            print(f\"current epoch: {epoch + 1} current AUC: {auc_result:.4f}\"\n",
      "\n",
      "                  f\" current accuracy: {acc_metric:.4f} best AUC: {best_metric:.4f}\"\n",
      "\n",
      "                  f\" at epoch: {best_metric_epoch}\")\n",
      "\n",
      "            \n",
      "\n",
      "print(f\"train completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")\n",
      "\n",
      "\n",
      "#################################################\n",
      "\n",
      "for fold in CFG.folds:\n",
      "\n",
      "    print(f'#'*15)\n",
      "\n",
      "    print(f'### Fold: {fold}')\n",
      "\n",
      "    print(f'#'*15)\n",
      "\n",
      "    run = wandb.init(project='uwmadison_challenge', entity=\"patronuseeker\",\n",
      "\n",
      "                     config={k:v for k, v in dict(vars(CFG)).items() if '__' not in k},\n",
      "\n",
      "                     anonymous=anonymous,\n",
      "\n",
      "                     name=f\"fold-{fold}|dim-{CFG.img_size[0]}x{CFG.img_size[1]}|model-{CFG.model_name}\",\n",
      "\n",
      "                     group=CFG.comment,\n",
      "\n",
      "                    )\n",
      "\n",
      "    train_loader, valid_loader = prepare_loaders(fold=fold, debug=CFG.debug)\n",
      "\n",
      "    model     = build_model()\n",
      "\n",
      "    \n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "    # Optional\n",
      "\n",
      "    optimizer = optim.Adam(model.parameters(), lr=CFG.lr, weight_decay=CFG.wd)\n",
      "\n",
      "    scheduler = fetch_scheduler(optimizer)\n",
      "\n",
      "    model, history = run_training(model, optimizer, scheduler,\n",
      "\n",
      "                                  device=CFG.device,\n",
      "\n",
      "                                  num_epochs=CFG.epochs)\n",
      "\n",
      "    run.finish()\n",
      "\n",
      "    display(ipd.IFrame(run.url, width=1000, height=720))\n",
      "\n",
      "#################################################\n",
      "\n",
      "oof, test_predictions, fold_errors = run_training(model, train, test,submission, 'fold', FT_COLS,\n",
      "\n",
      "                                              mixture_value_cols, mixture_title_cols, TARGET, cv_bm,\n",
      "\n",
      "                                            outlier_col='outlier_filter', \n",
      "\n",
      "                                            epochs=30,\n",
      "\n",
      "                                            batch_size=256, #lower batch sizes looked steadier \n",
      "\n",
      "                                            #but i did not get much better end result from limited testing\n",
      "\n",
      "                                            \n",
      "\n",
      "                                            verbose=False,\n",
      "\n",
      "                                            dense=70, \n",
      "\n",
      "                                            dout=0.15, \n",
      "\n",
      "                                            dense_reg = 0.000001,\n",
      "\n",
      "                                            act='elu',)\n",
      "\n",
      "#################################################\n",
      "\n",
      "gc.collect()\n",
      "\n",
      "for fold in range(params['num_folds']):\n",
      "\n",
      "    print(f'******************** Training Fold: {fold+1} ********************')\n",
      "\n",
      "    current_fold = fold\n",
      "\n",
      "    df_train = train_df[train_df['kfold'] != current_fold].copy()\n",
      "\n",
      "    df_valid = train_df[train_df['kfold'] == current_fold].copy()\n",
      "\n",
      "\n",
      "\n",
      "    train_dataset = BERTDataset(\n",
      "\n",
      "        df_train.more_toxic.values,\n",
      "\n",
      "        df_train.less_toxic.values\n",
      "\n",
      "    )\n",
      "\n",
      "    valid_dataset = BERTDataset(\n",
      "\n",
      "        df_valid.more_toxic.values,\n",
      "\n",
      "        df_valid.less_toxic.values\n",
      "\n",
      "    )\n",
      "\n",
      "\n",
      "\n",
      "    train_dataloader = DataLoader(\n",
      "\n",
      "        train_dataset, batch_size=params['batch_size'], shuffle=True,\n",
      "\n",
      "        num_workers=params['num_workers'], pin_memory=True\n",
      "\n",
      "    )\n",
      "\n",
      "    valid_dataloader = DataLoader(\n",
      "\n",
      "        valid_dataset, batch_size=params['batch_size']*2, shuffle=False,\n",
      "\n",
      "        num_workers=params['num_workers'], pin_memory=True\n",
      "\n",
      "    )\n",
      "\n",
      "    \n",
      "\n",
      "    model = ToxicityModel()\n",
      "\n",
      "    model = model.to(params['device'])\n",
      "\n",
      "    criterion = nn.MarginRankingLoss(margin=params['margin'])\n",
      "\n",
      "    if params['no_decay']:\n",
      "\n",
      "        param_optimizer = list(model.named_parameters())\n",
      "\n",
      "        no_decay = ['bias', 'LayerNorm.weight', 'LayerNorm.bias']\n",
      "\n",
      "        optimizer_grouped_parameters = [\n",
      "\n",
      "            {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
      "\n",
      "            {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
      "\n",
      "        ]\n",
      "\n",
      "        optimizer = optim.AdamW(optimizer_grouped_parameters, lr=params['lr'])\n",
      "\n",
      "    else:\n",
      "\n",
      "        optimizer = optim.AdamW(model.parameters(), lr=params['lr'])\n",
      "\n",
      "    scheduler = get_scheduler(optimizer)\n",
      "\n",
      "\n",
      "\n",
      "    # Training and Validation Loop\n",
      "\n",
      "    best_loss = np.inf\n",
      "\n",
      "    best_epoch = 0\n",
      "\n",
      "    best_model_name = None\n",
      "\n",
      "    for epoch in range(1, params['epochs'] + 1):\n",
      "\n",
      "        train_fn(train_dataloader, model, criterion, optimizer, epoch, params, scheduler)\n",
      "\n",
      "        valid_loss = validate_fn(valid_dataloader, model, criterion, epoch, params)\n",
      "\n",
      "        if valid_loss <= best_loss:\n",
      "\n",
      "            best_loss = valid_loss\n",
      "\n",
      "            best_epoch = epoch\n",
      "\n",
      "            if best_model_name is not None:\n",
      "\n",
      "                os.remove(best_model_name)\n",
      "\n",
      "            torch.save(model.state_dict(), f\"{params['checkpoint']}_{epoch}_epoch_f{fold+1}.pth\")\n",
      "\n",
      "            best_model_name = f\"{params['checkpoint']}_{epoch}_epoch_f{fold+1}.pth\"\n",
      "\n",
      "\n",
      "\n",
      "    # Print summary of this fold\n",
      "\n",
      "    print('')\n",
      "\n",
      "    print(f'The best LOSS: {best_loss} for fold {fold+1} was achieved on epoch: {best_epoch}.')\n",
      "\n",
      "    print(f'The Best saved model is: {best_model_name}')\n",
      "\n",
      "    best_models_of_each_fold.append(best_model_name)\n",
      "\n",
      "    del df_train, df_valid, train_dataset, valid_dataset, train_dataloader, valid_dataloader, model\n",
      "\n",
      "    _ = gc.collect()\n",
      "\n",
      "    torch.cuda.empty_cache()\n",
      "\n",
      "#################################################\n",
      "\n",
      "for e in range(epoch):\n",
      "\n",
      "    xcit_model.train()\n",
      "\n",
      "    print(f\"====================== EPOCH {e+1} ======================\")\n",
      "\n",
      "    print(\"Training.....\")\n",
      "\n",
      "    for i, (data, target) in enumerate(train_dataloader):\n",
      "\n",
      "        optimizer.zero_grad()\n",
      "\n",
      "        output = xcit_model(data)\n",
      "\n",
      "        loss = criterion(output, target.view(-1,))\n",
      "\n",
      "        loss.backward()\n",
      "\n",
      "        \n",
      "\n",
      "        nn.utils.clip_grad_norm_(xcit_model.parameters(), 3)\n",
      "\n",
      "        accuracy = (output.argmax(dim=1) == target).float().mean()\n",
      "\n",
      "        \n",
      "\n",
      "        loss_history[0].append(loss.item())\n",
      "\n",
      "        accuracy_history[0].append(accuracy)\n",
      "\n",
      "        \n",
      "\n",
      "        optimizer.step()\n",
      "\n",
      "        \n",
      "\n",
      "        print(f\"MINIBATCH {i+1}/{train_dataloader.__len__()} TRAIN ACC : {accuracy_history[0][-1]}  TRAIN LOSS : {loss_history[0][-1]}\")\n",
      "\n",
      "            \n",
      "\n",
      "    \n",
      "\n",
      "    print(\"Validation.....\")\n",
      "\n",
      "    xcit_model.eval()\n",
      "\n",
      "    \n",
      "\n",
      "    with torch.no_grad():\n",
      "\n",
      "        for i, (data, target) in enumerate(validation_dataloader):\n",
      "\n",
      "            output = xcit_model(data)\n",
      "\n",
      "            loss = criterion(output, target.view(-1,))\n",
      "\n",
      "            accuracy = (output.argmax(dim=1) == target).float().mean()\n",
      "\n",
      "            loss_history[1].append(loss.item())\n",
      "\n",
      "            accuracy_history[1].append(accuracy)\n",
      "\n",
      "        \n",
      "\n",
      "    acc_epoch_history[0].append(sum(accuracy_history[0][-1:-train_dataloader.__len__():-1])/train_dataloader.__len__())\n",
      "\n",
      "    acc_epoch_history[1].append(sum(accuracy_history[1][-1:-validation_dataloader.__len__():-1])/validation_dataloader.__len__())\n",
      "\n",
      "    \n",
      "\n",
      "    loss_epoch_history[0].append(sum(loss_history[0][-1:-train_dataloader.__len__():-1])/train_dataloader.__len__())\n",
      "\n",
      "    loss_epoch_history[1].append(sum(loss_history[1][-1:-validation_dataloader.__len__():-1])/validation_dataloader.__len__())\n",
      "\n",
      "    \n",
      "\n",
      "    print(\"====================================================\")\n",
      "\n",
      "    print(f\"TRAIN ACC : {acc_epoch_history[0][-1]}  TRAIN LOSS : {loss_epoch_history[0][-1]}\")\n",
      "\n",
      "    print(f\"VALL ACC : {acc_epoch_history[1][-1]}  VAL LOSS : {loss_epoch_history[1][-1]}\")\n",
      "\n",
      "    print(\"====================================================\")\n",
      "\n",
      "    \n",
      "\n",
      "    torch.save({\n",
      "\n",
      "            'epoch': e,\n",
      "\n",
      "            'model_state_dict': xcit_model.state_dict(),\n",
      "\n",
      "            'optimizer_state_dict': optimizer.state_dict(),\n",
      "\n",
      "            'loss': loss_epoch_history[0][-1],\n",
      "\n",
      "            'acc' : acc_epoch_history[0][-1]\n",
      "\n",
      "            }, './model_checkpoint.pt')\n",
      "\n",
      "#################################################\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "\n",
      "    main()\n",
      "\n",
      "#################################################\n",
      "\n",
      "study.optimize(nn, n_trials=30, gc_after_trial=True, show_progress_bar=True)\n",
      "\n",
      "\n",
      "\n",
      "print('Number of finished trials: {}'.format(len(study.trials)))\n",
      "\n",
      "\n",
      "\n",
      "print('Best trial:')\n",
      "\n",
      "trial = study.best_trial\n",
      "\n",
      "\n",
      "\n",
      "print('  Value: {}'.format(trial.value))\n",
      "\n",
      "\n",
      "\n",
      "print('  Params: ')\n",
      "\n",
      "for key, value in trial.params.items():\n",
      "\n",
      "    print('    {}: {}'.format(key, value))\n",
      "\n",
      "#################################################\n",
      "\n",
      "for fold in range(1, config.n_folds):\n",
      "\n",
      "    val_data = do_fold(fold)\n",
      "\n",
      "    val_preds_df = pd.concat([val_preds_df, val_data])\n",
      "\n",
      "#################################################\n",
      "\n",
      "# Train\n",
      "\n",
      "EPOCHS = 5\n",
      "\n",
      "\n",
      "\n",
      "scaler = GradScaler()\n",
      "\n",
      "model.zero_grad()\n",
      "\n",
      "\n",
      "\n",
      "for epoch in range(EPOCHS):\n",
      "\n",
      "    print(f'Epoch: {epoch+1}/{EPOCHS}')\n",
      "\n",
      "    train_loss = train_epoch(model, scaler, train_loader, device, optimizer)\n",
      "\n",
      "    print(f'Train Loss: {train_loss}')\n",
      "\n",
      "#################################################\n",
      "\n",
      "params = {\n",
      "\n",
      "    'n_estimators'  : [100, 500] ,\n",
      "\n",
      "    'learning_rate' : [ 0.05, 0.1]\n",
      "\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "grid_cv = GridSearchCV(gb_clf, param_grid = params, cv=2, verbose= 1)\n",
      "\n",
      "grid_cv.fit(X_train, y_train)\n",
      "\n",
      "\n",
      "\n",
      "print('Best params : \\n',grid_cv.best_estimator_)\n",
      "\n",
      "print('Best accuracy : {0:.4f}'.format(grid_cv.best_score_))\n",
      "\n",
      "#################################################\n",
      "\n",
      "for fold in CFG.folds:\n",
      "\n",
      "    print(f'#'*15)\n",
      "\n",
      "    print(f'### Fold: {fold}')\n",
      "\n",
      "    print(f'#'*15)\n",
      "\n",
      "    run = wandb.init(project='uw-maddison-gi-tract', \n",
      "\n",
      "                     config={k:v for k, v in dict(vars(CFG)).items() if '__' not in k},\n",
      "\n",
      "                     anonymous=anonymous,\n",
      "\n",
      "                     name=f\"fold-{fold}|dim-{CFG.img_size[0]}x{CFG.img_size[1]}|model-{CFG.model_name}\",\n",
      "\n",
      "                     group=CFG.comment,\n",
      "\n",
      "                    )\n",
      "\n",
      "    train_loader, valid_loader = prepare_loaders(fold=fold, debug=CFG.debug)\n",
      "\n",
      "    model     = build_model()\n",
      "\n",
      "    optimizer = optim.Adam(model.parameters(), lr=CFG.lr, weight_decay=CFG.wd)\n",
      "\n",
      "    scheduler = fetch_scheduler(optimizer)\n",
      "\n",
      "    model, history = run_training(model, optimizer, scheduler,\n",
      "\n",
      "                                  device=CFG.device,\n",
      "\n",
      "                                  num_epochs=CFG.epochs)\n",
      "\n",
      "    run.finish()\n",
      "\n",
      "    display(ipd.IFrame(run.url, width=1000, height=720))\n",
      "\n",
      "#################################################\n",
      "\n",
      "for fold in CFG.folds:\n",
      "\n",
      "    print(f'#'*15)\n",
      "\n",
      "    print(f'### Fold: {fold}')\n",
      "\n",
      "    print(f'#'*15)\n",
      "\n",
      "    run = wandb.init(project='uw-maddison-gi-tract', \n",
      "\n",
      "                     config={k:v for k, v in dict(vars(CFG)).items() if '__' not in k},\n",
      "\n",
      "                     anonymous=anonymous,\n",
      "\n",
      "                     name=f\"fold-{fold}|dim-{CFG.img_size[0]}x{CFG.img_size[1]}|model-{CFG.model_name}\",\n",
      "\n",
      "                     group=CFG.comment,\n",
      "\n",
      "                    )\n",
      "\n",
      "    train_loader, valid_loader = prepare_loaders(fold=fold, debug=CFG.debug)\n",
      "\n",
      "    model     = build_model()\n",
      "\n",
      "    optimizer = optim.Adam(model.parameters(), lr=CFG.lr, weight_decay=CFG.wd)\n",
      "\n",
      "    scheduler = fetch_scheduler(optimizer)\n",
      "\n",
      "    model, history = run_training(model, optimizer, scheduler,\n",
      "\n",
      "                                  device=CFG.device,\n",
      "\n",
      "                                  num_epochs=CFG.epochs)\n",
      "\n",
      "    run.finish()\n",
      "\n",
      "    display(ipd.IFrame(run.url, width=1000, height=720))\n",
      "\n",
      "#################################################\n",
      "\n",
      "step_total = 0\n",
      "\n",
      "#previous trained 16 epochs\n",
      "\n",
      "#train another 12 epochs\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "for epoch in range(EPOCHS):\n",
      "\n",
      "    print(f'***** EPOCH {epoch + 1} *****')\n",
      "\n",
      "    \n",
      "\n",
      "    t_start = time.time()\n",
      "\n",
      "    t_start_batch = time.time()\n",
      "\n",
      "    total_loss = 0\n",
      "\n",
      "    \n",
      "\n",
      "    # create distributed versions of dataset\n",
      "\n",
      "    train_dist_dataset = iter(strategy.experimental_distribute_dataset(train_dataset))\n",
      "\n",
      "    val_dist_dataset = iter(strategy.experimental_distribute_dataset(val_dataset))\n",
      "\n",
      "\n",
      "\n",
      "    for step in range(1, STEPS_PER_EPOCH + 1):\n",
      "\n",
      "        # train step\n",
      "\n",
      "        distributed_train_step(train_dist_dataset)\n",
      "\n",
      "        STATS.update_stats()\n",
      "\n",
      "        # save epoch weights\n",
      "\n",
      "        encoder.save_weights(f'./encoder_epoch_{epoch+1}.h5')\n",
      "\n",
      "        decoder.save_weights(f'./decoder_epoch_{epoch+1}.h5')\n",
      "\n",
      "            \n",
      "\n",
      "        # end of epoch validation\n",
      "\n",
      "        if step == STEPS_PER_EPOCH:\n",
      "\n",
      "            val_ls_distance = get_val_metrics(val_dist_dataset)\n",
      "\n",
      "            # log with validation\n",
      "\n",
      "            log(step, t_start_batch, val_ls_distance)\n",
      "\n",
      "        else:\n",
      "\n",
      "            # normal log\n",
      "\n",
      "            log(step, t_start_batch)\n",
      "\n",
      "            # reset start time batch\n",
      "\n",
      "            t_start_batch = time.time()\n",
      "\n",
      "            \n",
      "\n",
      "        total_loss += train_loss.result()\n",
      "\n",
      "        \n",
      "\n",
      "        # learning rate step\n",
      "\n",
      "        LRREDUCE.step(epoch * TRAIN_STEPS + step * VERBOSE_FREQ - 1)\n",
      "\n",
      "        \n",
      "\n",
      "        # stop training when NaN loss is detected, this can be caused by exploding gradients\n",
      "\n",
      "        if np.isnan(total_loss):\n",
      "\n",
      "            break\n",
      "\n",
      "            \n",
      "\n",
      "    # stop training when NaN loss is detected\n",
      "\n",
      "    if np.isnan(total_loss):\n",
      "\n",
      "        break\n",
      "\n",
      "\n",
      "\n",
      "    print(f'Epoch {epoch} Loss {round(total_loss.numpy() / TRAIN_STEPS, 3)}, time: {int(time.time() - t_start)} sec\\n')\n",
      "\n",
      "#################################################\n",
      "\n",
      "import gc\n",
      "\n",
      "import pyvips\n",
      "\n",
      "from tqdm.auto import tqdm\n",
      "\n",
      "\n",
      "\n",
      "for tif_path in tqdm(ls_imgs):\n",
      "\n",
      "    # img = Image.open(tif_path)\n",
      "\n",
      "    name, _ = os.path.splitext(os.path.basename(tif_path))\n",
      "\n",
      "    png_path = os.path.join(\"./train_images\", f\"{name}.png\")\n",
      "\n",
      "    pyvips.Image.thumbnail(tif_path, 2000).write_to_file(png_path)\n",
      "\n",
      "    gc.collect()\n",
      "\n",
      "#################################################\n",
      "\n",
      "from detectron2.config.config import CfgNode as CN\n",
      "\n",
      "\n",
      "\n",
      "cfg = get_cfg()\n",
      "\n",
      "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\"))\n",
      "\n",
      "cfg.DATASETS.TRAIN = (\"train_data\",)\n",
      "\n",
      "cfg.DATASETS.TEST = (\"val_data\",)\n",
      "\n",
      "cfg.DATALOADER.NUM_WORKERS = 4\n",
      "\n",
      "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
      "\n",
      "cfg.SOLVER.IMS_PER_BATCH = 4\n",
      "\n",
      "cfg.SOLVER.BASE_LR = 0.001\n",
      "\n",
      "cfg.SOLVER.WARMUP_ITERS = 1000\n",
      "\n",
      "cfg.SOLVER.MAX_ITER = 30000 #adjust up if val mAP is still rising, adjust down if overfit\n",
      "\n",
      "# cfg.SOLVER.STEPS = [0,20000,40000]\n",
      "\n",
      "cfg.SOLVER.GAMMA = 0.05\n",
      "\n",
      "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 64\n",
      "\n",
      "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 5\n",
      "\n",
      "# cfg.TEST.EVAL_PERIOD = 1000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
      "\n",
      "trainer = CocoTrainer(cfg) \n",
      "\n",
      "# trainer.resume_or_load(resume=False)\n",
      "\n",
      "trainer.resume_or_load(resume=False)\n",
      "\n",
      "\n",
      "\n",
      "trainer.train()\n",
      "\n",
      "#################################################\n",
      "\n",
      "best_metric = -1\n",
      "\n",
      "best_metric_epoch = -1\n",
      "\n",
      "epoch_loss_values = list()\n",
      "\n",
      "auc_metric = ROCAUCMetric()\n",
      "\n",
      "metric_values = list()\n",
      "\n",
      "\n",
      "\n",
      "for epoch in range(epoch_num):\n",
      "\n",
      "    print('-' * 10)\n",
      "\n",
      "    print(f\"epoch {epoch + 1}/{epoch_num}\")\n",
      "\n",
      "    model.train()\n",
      "\n",
      "    epoch_loss = 0\n",
      "\n",
      "    step = 0\n",
      "\n",
      "\n",
      "\n",
      "    for batch_data in train_loader:\n",
      "\n",
      "        step += 1\n",
      "\n",
      "        inputs, labels = batch_data[0].to(device), batch_data[1].to(device)\n",
      "\n",
      "        optimizer.zero_grad()\n",
      "\n",
      "        outputs = model(inputs.float())     ##### .float()\n",
      "\n",
      "        loss = loss_function(outputs, labels)\n",
      "\n",
      "        loss.backward()\n",
      "\n",
      "        optimizer.step()\n",
      "\n",
      "        epoch_loss += loss.item()\n",
      "\n",
      "        print(f\"{step}/{len(train_ds) // train_loader.batch_size}, train_loss: {loss.item():.4f}\")\n",
      "\n",
      "        epoch_len = len(train_ds) // train_loader.batch_size\n",
      "\n",
      "\n",
      "\n",
      "    epoch_loss /= step\n",
      "\n",
      "    epoch_loss_values.append(epoch_loss)\n",
      "\n",
      "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
      "\n",
      "\n",
      "\n",
      "    if (epoch + 1) % val_interval == 0:\n",
      "\n",
      "        model.eval()\n",
      "\n",
      "        with torch.no_grad():\n",
      "\n",
      "            y_pred = torch.tensor([], dtype=torch.float32, device=device)\n",
      "\n",
      "            y = torch.tensor([], dtype=torch.long, device=device)\n",
      "\n",
      "            for val_data in val_loader:\n",
      "\n",
      "                val_images, val_labels = val_data[0].to(device), val_data[1].to(device)\n",
      "\n",
      "                y_pred = torch.cat([y_pred, model(val_images)], dim=0)\n",
      "\n",
      "                y = torch.cat([y, val_labels], dim=0)\n",
      "\n",
      "                \n",
      "\n",
      "            y_onehot = [to_onehot(i) for i in y]\n",
      "\n",
      "            y_pred_act = [act(i) for i in y_pred]\n",
      "\n",
      "            auc_metric(y_pred_act, y_onehot)\n",
      "\n",
      "            auc_result = auc_metric.aggregate()\n",
      "\n",
      "            auc_metric.reset()\n",
      "\n",
      "            del y_pred_act, y_onehot\n",
      "\n",
      "            metric_values.append(auc_result)\n",
      "\n",
      "            acc_value = torch.eq(y_pred.argmax(dim=1), y)\n",
      "\n",
      "            acc_metric = acc_value.sum().item() / len(acc_value)\n",
      "\n",
      "            \n",
      "\n",
      "            if acc_metric > best_metric:\n",
      "\n",
      "                best_metric = acc_metric\n",
      "\n",
      "                best_metric_epoch = epoch + 1\n",
      "\n",
      "                torch.save(model.state_dict(), 'best_metric_model.pth')\n",
      "\n",
      "                print('saved new best metric model')\n",
      "\n",
      "                \n",
      "\n",
      "            print(f\"current epoch: {epoch + 1} current AUC: {auc_result:.4f}\"\n",
      "\n",
      "                  f\" current accuracy: {acc_metric:.4f} best AUC: {best_metric:.4f}\"\n",
      "\n",
      "                  f\" at epoch: {best_metric_epoch}\")\n",
      "\n",
      "            \n",
      "\n",
      "print(f\"train completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")\n",
      "\n",
      "\n",
      "#################################################\n",
      "\n",
      "enable_display_notebook = False  # If True, you can see mp4 in notebook but slow. If False, you can't see mp4 in notebook(so you should download and see locally) but fast.\n",
      "\n",
      "\n",
      "\n",
      "i = 0\n",
      "\n",
      "for _, w_df in tqdm.tqdm(df_rets.groupby(\"start_time\")):\n",
      "\n",
      "    i += 1\n",
      "\n",
      "    if i % 50 == 0:\n",
      "\n",
      "        make_movie(w_df, enable_display_notebook)\n",
      "\n",
      "    # if i > 3: # For debug. If you output all movie, disable this!\n",
      "\n",
      "    #     break\n",
      "\n",
      "#################################################\n",
      "\n",
      "for fold in CFG.folds:\n",
      "\n",
      "    print(f'#'*15)\n",
      "\n",
      "    print(f'### Fold: {fold}')\n",
      "\n",
      "    print(f'#'*15)\n",
      "\n",
      "    run = wandb.init(project='uw-maddison-gi-tract', \n",
      "\n",
      "                     config={k:v for k, v in dict(vars(CFG)).items() if '__' not in k},\n",
      "\n",
      "                     anonymous=anonymous,\n",
      "\n",
      "                     name=f\"fold-{fold}|dim-{CFG.img_size[0]}x{CFG.img_size[1]}|model-{CFG.model_name}\",\n",
      "\n",
      "                     group=CFG.comment,\n",
      "\n",
      "                    )\n",
      "\n",
      "    train_loader, valid_loader = prepare_loaders(fold=fold, debug=CFG.debug)\n",
      "\n",
      "    model     = build_model()\n",
      "\n",
      "    optimizer = optim.Adam(model.parameters(), lr=CFG.lr, weight_decay=CFG.wd)\n",
      "\n",
      "    scheduler = fetch_scheduler(optimizer)\n",
      "\n",
      "    model, history = run_training(model, optimizer, scheduler,\n",
      "\n",
      "                                  device=CFG.device,\n",
      "\n",
      "                                  num_epochs=CFG.epochs)\n",
      "\n",
      "    run.finish()\n",
      "\n",
      "    display(ipd.IFrame(run.url, width=1000, height=720))\n",
      "\n",
      "#################################################\n",
      "\n",
      "%%time \n",
      "\n",
      "\n",
      "\n",
      "class args:\n",
      "\n",
      "    epochs = 5\n",
      "\n",
      "    lr = 1e-3\n",
      "\n",
      "    batch_size = 16\n",
      "\n",
      "    num_workers = 2\n",
      "\n",
      "    val_samples = 1\n",
      "\n",
      "    embedding_size = 128\n",
      "\n",
      "    backbone_name = \"tf_efficientnetv2_b3\"\n",
      "\n",
      "    n_classes = data_df[\"hotel_id_code\"].nunique()\n",
      "\n",
      "    device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
      "\n",
      "\n",
      "\n",
      "train_and_validate(args, data_df)\n",
      "\n",
      "#################################################\n",
      "\n",
      "train_size = int(len(X) * 0.8)\n",
      "\n",
      "mse_loss = tf.keras.losses.MeanSquaredError()\n",
      "\n",
      "\n",
      "\n",
      "skf = StratifiedKFold(n_splits=5)\n",
      "\n",
      "oof_preds = np.zeros((5, len(test)))\n",
      "\n",
      "\n",
      "\n",
      "for i,(train_index, test_index) in enumerate(skf.split(X, y)):\n",
      "\n",
      "    X_train, X_test = X[train_index], X[test_index]\n",
      "\n",
      "    y_train, y_test = y[train_index], y[test_index]\n",
      "\n",
      "    \n",
      "\n",
      "    batch_size = 32\n",
      "\n",
      "    model = create_bnn_model(train_size)\n",
      "\n",
      "    model.compile(\n",
      "\n",
      "        optimizer=tf.keras.optimizers.RMSprop(learning_rate=learning_rate),\n",
      "\n",
      "        loss=mse_loss,\n",
      "\n",
      "        metrics=[tf.keras.metrics.RootMeanSquaredError()],\n",
      "\n",
      "    )\n",
      "\n",
      "        \n",
      "\n",
      "    print('Training fold:%2d' % (i+1))\n",
      "\n",
      "    \n",
      "\n",
      "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)\n",
      "\n",
      "    model.fit(X_train, y_train, validation_data=(X_test, y_test), \n",
      "\n",
      "              callbacks=[callback],\n",
      "\n",
      "              batch_size=batch_size, epochs=300, verbose=True)\n",
      "\n",
      "    clear_output(wait=True)\n",
      "\n",
      "    \n",
      "\n",
      "    oof_preds[i] = model.predict(test).reshape(-1)\n",
      "\n",
      "#################################################\n",
      "\n",
      "if __name__ == '__main__':\n",
      "\n",
      "    \n",
      "\n",
      "    def get_result(oof_df):\n",
      "\n",
      "        labels = create_labels_for_scoring(oof_df)\n",
      "\n",
      "        predictions = oof_df[[i for i in range(CFG.max_len)]].values\n",
      "\n",
      "        char_probs = get_char_probs(oof_df['pn_history'].values, predictions, CFG.tokenizer)\n",
      "\n",
      "        results = get_results(char_probs, th=0.5)\n",
      "\n",
      "        preds = get_predictions(results)\n",
      "\n",
      "        score = get_score(labels, preds)\n",
      "\n",
      "        LOGGER.info(f'Score: {score:<.4f}')\n",
      "\n",
      "    \n",
      "\n",
      "    if CFG.train:\n",
      "\n",
      "        oof_df = pd.DataFrame()\n",
      "\n",
      "        #    n_fold=5\n",
      "\n",
      "        #    trn_fold=[0, 1, 2, 3, 4]\n",
      "\n",
      "        for fold in range(CFG.n_fold):\n",
      "\n",
      "            if fold in CFG.trn_fold:\n",
      "\n",
      "#train.head() is like:                 \n",
      "\n",
      "#id\tcase_num\tpn_num\tfeature_num\tannotation\tlocation\tfeature_text\tpn_history-> fold\n",
      "\n",
      "# 0\t00016_000\t0\t16\t0\t[dad with recent heart attcak]\t[696 724]\tFamily-history-of-MI-OR-Family-history-of-myoc...\tHPI: 17yo M presents with palpitations. Patien...\n",
      "\n",
      "# 1\t00016_001\t0\t16\t1\t[mom with \"thyroid disease]\t[668 693]\tFamily-history-of-thyroid-disorder\tHPI: 17yo M presents with palpitations. Patien...\n",
      "\n",
      "# 2\t00016_002\t0\t16\t2\t[chest pressure]\t[203 217]\tChest-pressure\tHPI: 17yo M presents with palpitations. Patien...\n",
      "\n",
      "# 3\t00016_003\t0\t16\t3\t[intermittent episodes, episode]\t[70 91, 176 183]\tIntermittent-symptoms\tHPI: 17yo M presents with palpitations. Patien...\n",
      "\n",
      "# 4\t00016_004\t0\t16\t4\t[felt as if he were going to pass out]\t[222 258]\tLightheaded\tHPI: 17yo M presents with palpitations. Patien...\n",
      "\n",
      "                _oof_df = train_loop(train, fold)\n",
      "\n",
      "                oof_df = pd.concat([oof_df, _oof_df])\n",
      "\n",
      "                LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
      "\n",
      "                get_result(_oof_df)\n",
      "\n",
      "        oof_df = oof_df.reset_index(drop=True)\n",
      "\n",
      "#         print(\"oof_df shape=\"+oof_df.shape)\n",
      "\n",
      "        LOGGER.info(f\"========== CV ==========\")\n",
      "\n",
      "        get_result(oof_df)\n",
      "\n",
      "        oof_df.to_pickle(OUTPUT_DIR+'oof_df.pkl')\n",
      "\n",
      "#         oof_df.to_csv(OUTPUT_DIR+'submission.csv',index=False)\n",
      "\n",
      "#         model.predcit \n",
      "\n",
      "    if CFG.wandb:\n",
      "\n",
      "        wandb.finish()\n",
      "\n",
      "        \n",
      "\n",
      "#################################################\n",
      "\n",
      "automl = AutoML(\n",
      "\n",
      "    mode=\"Compete\", \n",
      "\n",
      "    total_time_limit=6*60*60, # 6 hours \n",
      "\n",
      "    eval_metric='auc'\n",
      "\n",
      ")\n",
      "\n",
      "automl.fit(train[x_cols], train[y_col])\n",
      "\n",
      "#################################################\n",
      "\n",
      "# ========================================\n",
      "\n",
      "# Main\n",
      "\n",
      "# ========================================\n",
      "\n",
      "if not Config.only_inference:\n",
      "\n",
      "    # training\n",
      "\n",
      "    print(\"# ---------- # Start Training # ---------- #\")\n",
      "\n",
      "    oof_df = train_cv(train_jigsaw_01, text_col=\"comment_text\")\n",
      "\n",
      "    oof_df.to_csv(os.path.join(EXP_PREDS, \"oof.csv\"), index=False)\n",
      "\n",
      "\n",
      "\n",
      "    # score (Jigsaw01)\n",
      "\n",
      "    fold_mask = train_jigsaw_01[\"fold\"].isin(Config.trn_fold)\n",
      "\n",
      "    score = get_score(\n",
      "\n",
      "        train_jigsaw_01.loc[fold_mask, Config.target_cols].values, \n",
      "\n",
      "        oof_df.loc[fold_mask, Config.target_cols].values, \n",
      "\n",
      "        verbose=True)\n",
      "\n",
      "    logger.info(f\"Jigsaw01-MCWROC={score:.4f}\")\n",
      "\n",
      "\n",
      "\n",
      "    # validation (Jigsaw04[This Compe])\n",
      "\n",
      "    print(\"# ---------- # Start Validation # ---------- #\")\n",
      "\n",
      "    validation_preds_df = predict_cv_jigsaw04_validation(validation_data)\n",
      "\n",
      "    validation_preds_df.to_csv(os.path.join(EXP_PREDS, f\"validation_preds_df.csv\"), index=False)\n",
      "\n",
      "    scores = jigsaw04_metrics(preds_less_toxic=validation_preds_df[\"preds=less_toxic\"], \n",
      "\n",
      "                            preds_more_toxic=validation_preds_df[\"preds=more_toxic\"])\n",
      "\n",
      "    score = np.mean(scores)\n",
      "\n",
      "    logger.info(f\"Jigsaw04-Jigsaw-Rate-Severity={score:.4f}\")\n",
      "\n",
      "\n",
      "\n",
      "# prediction\n",
      "\n",
      "print(\"# ---------- # Start Inference # ---------- #\")\n",
      "\n",
      "preds, fold_preds_df = predict_cv(comments_to_score, text_col=\"text\")\n",
      "\n",
      "(pd.DataFrame(preds, columns=Config.target_cols).\n",
      "\n",
      " to_csv(os.path.join(EXP_PREDS, f\"comments_to_score_preds_df.csv\"), index=False))\n",
      "\n",
      "fold_preds_df.to_csv(os.path.join(EXP_PREDS, f\"comments_to_score_fold_preds_df.csv\"), index=False)\n",
      "\n",
      "\n",
      "\n",
      "comments_to_score[\"preds\"] = fold_preds_df.sum(axis=1)\n",
      "\n",
      "comments_to_score.to_csv(os.path.join(EXP_PREDS, f\"comments_to_score_df.csv\"), index=False)\n",
      "\n",
      "\n",
      "\n",
      "# make submission\n",
      "\n",
      "print(\"# ---------- # Make Submission # ---------- #\")\n",
      "\n",
      "sample_submission[\"score\"] = comments_to_score[\"preds\"].rank(method='first')\n",
      "\n",
      "display(sample_submission)\n",
      "\n",
      "sample_submission.to_csv(os.path.join(SUBMISSION, Config.name+\".csv\"), index=False)\n",
      "\n",
      "print(\"# ---------- # Finish Experiment!! # ---------- #\")\n",
      "\n",
      "#################################################\n",
      "\n",
      "with zipfile.ZipFile(\"train.zip\", \"w\") as file, tqdm(total=train_tiles) as bar:\n",
      "\n",
      "    for image_id in train_df[\"image_id\"]:\n",
      "\n",
      "        for i, tile in enumerate(\n",
      "\n",
      "            read_tiles(f\"train/{image_id}.tif\", filter_empty=True, verbose=False)\n",
      "\n",
      "        ):\n",
      "\n",
      "            if tile is not None:\n",
      "\n",
      "                tile = cv2.imencode(\".png\", cv2.cvtColor(tile, cv2.COLOR_RGB2BGR))[1]\n",
      "\n",
      "                file.writestr(f\"{image_id}-{i:04d}.png\", tile)\n",
      "\n",
      "            bar.update(1)\n",
      "\n",
      "#################################################\n",
      "\n",
      "history = model.fit(X_train,y_train,validation_split=0.1, epochs =25, verbose=1, batch_size=32,\n",
      "\n",
      "                   callbacks=[tensorboard,checkpoint,reduce_lr])\n",
      "\n",
      "#################################################\n",
      "\n",
      "classifier = KNeighborsClassifier(n_jobs=-1)\n",
      "\n",
      "parameter = {\n",
      "\n",
      "    'n_neighbors': range(1, 31, 2),\n",
      "\n",
      "    'weights' : ['uniform', 'distance'],\n",
      "\n",
      "    'p' : [1, 2] # manhattan or euclidean\n",
      "\n",
      "}\n",
      "\n",
      "model = GridSearchCV(classifier, \n",
      "\n",
      "                     param_grid=parameter,\n",
      "\n",
      "                     cv=3,\n",
      "\n",
      "                     n_jobs=1,\n",
      "\n",
      "                     scoring='accuracy', \n",
      "\n",
      "                     verbose=10)\n",
      "\n",
      "\n",
      "\n",
      "model.fit(Final_X, y)\n",
      "\n",
      "#################################################\n",
      "\n",
      "h = model.fit(X_train,y_train,epochs=100,validation_split=.2,callbacks=[earlystop])\n",
      "\n",
      "#################################################\n",
      "\n",
      "for country in country_list:\n",
      "\n",
      "    for store in store_list:\n",
      "\n",
      "        for product in product_list:\n",
      "\n",
      "            print(country, ' - ', store, ' - ', product)\n",
      "\n",
      "            train_temp = train_data[(train_data[country]==1)&\n",
      "\n",
      "                                    (train_data[store]==1)&\n",
      "\n",
      "                                    (train_data[product]==1)]\n",
      "\n",
      "            test_temp = test_data[(test_data[country]==1)&\n",
      "\n",
      "                                  (test_data[store]==1)&\n",
      "\n",
      "                                  (test_data[product]==1)]\n",
      "\n",
      "            \n",
      "\n",
      "            features = ['year', 'month', 'day', 'weekend', 'holiday']+day_list+month_list+year_list+feature_cyc_list\n",
      "\n",
      "            \n",
      "\n",
      "            X = train_temp[features]\n",
      "\n",
      "            y = train_temp['num_sold']\n",
      "\n",
      "            X_test = test_temp[features]\n",
      "\n",
      "            \n",
      "\n",
      "            #X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.1, random_state=2022)\n",
      "\n",
      "            X_train = X\n",
      "\n",
      "            y_train = y\n",
      "\n",
      "            params = get_params(X_train, y_train)\n",
      "\n",
      "            \n",
      "\n",
      "            #model = XGBRegressor(objective='reg:squarederror',\n",
      "\n",
      "            #                     n_estimators=50,\n",
      "\n",
      "            #                     learning_rate=0.1,\n",
      "\n",
      "            #                     colsample_bytree=0.8,\n",
      "\n",
      "            #                     max_depth=5)\n",
      "\n",
      "            model = XGBRegressor(**params)\n",
      "\n",
      "            #model = LinearRegression(normalize=False)\n",
      "\n",
      "            model.fit(X_train, y_train)\n",
      "\n",
      "            #y_val_pred = model.predict(X_val)\n",
      "\n",
      "            #print('SMAPE:', round(smape_error(y_val, y_val_pred), 2))\n",
      "\n",
      "            \n",
      "\n",
      "            y_test = model.predict(X_test)\n",
      "\n",
      "            samp_subm.loc[X_test.index, 'num_sold'] = y_test\n",
      "\n",
      "        \n",
      "\n",
      "#################################################\n",
      "\n",
      "scores = []\n",
      "\n",
      "for fold in range(4,5):\n",
      "\n",
      "    print(f\"====== FOLD RUNNING {fold}======\")\n",
      "\n",
      "    \n",
      "\n",
      "    X_train = df_train.loc[df_train['kfold'] != fold]['text'].tolist()\n",
      "\n",
      "    y_train = df_train.loc[df_train['kfold'] != fold]['discourse_effectiveness'].tolist()\n",
      "\n",
      "    \n",
      "\n",
      "    X_test = df_train.loc[df_train['kfold'] == fold]['text'].tolist()\n",
      "\n",
      "    y_test = df_train.loc[df_train['kfold'] == fold]['discourse_effectiveness'].tolist()\n",
      "\n",
      "    \n",
      "\n",
      "    print(\"Generating Train Dataset\")\n",
      "\n",
      "    train_dataset = FeedbackPrizeDataset(X_train,y_train)\n",
      "\n",
      "        \n",
      "\n",
      "    print(\"Validation Generating Dataset\")\n",
      "\n",
      "    validation_dataset = FeedbackPrizeDataset(X_test,y_test)\n",
      "\n",
      "\n",
      "\n",
      "    print(\"Generating Train DataLoader\")\n",
      "\n",
      "    train_dataloader = DataLoader(train_dataset, batch_size = config.batch_size, shuffle = True, num_workers= 2, pin_memory=False)\n",
      "\n",
      "    \n",
      "\n",
      "    print(\"Generating Validation DataLoader\")\n",
      "\n",
      "    validation_dataloader = DataLoader(validation_dataset, batch_size = config.batch_size, shuffle = False, num_workers= 2, pin_memory=False)\n",
      "\n",
      "\n",
      "\n",
      "    early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=0.00, patience=3, verbose= True, mode=\"min\")\n",
      "\n",
      "    checkpoint_callback = ModelCheckpoint(monitor='val_loss',\n",
      "\n",
      "                                          dirpath= config.save_dir,\n",
      "\n",
      "                                      save_top_k=1,\n",
      "\n",
      "                                      save_last= False,\n",
      "\n",
      "                                      save_weights_only=True,\n",
      "\n",
      "                                      filename= f'./{config.model_name}_{fold}',\n",
      "\n",
      "                                      verbose= True,\n",
      "\n",
      "                                      mode='min')\n",
      "\n",
      "    print(\"Model Creation\")\n",
      "\n",
      "    \n",
      "\n",
      "    model = FeedbackPrizeModel(train_dataloader, validation_dataloader)\n",
      "\n",
      "    \n",
      "\n",
      "    trainer = Trainer(max_epochs= config.epochs, gpus = 1, precision=16, accelerator=\"gpu\" ,progress_bar_refresh_rate=10, callbacks=[checkpoint_callback,early_stop_callback])    \n",
      "\n",
      "    print(\"Trainer Starting\")\n",
      "\n",
      "    trainer.fit(model , train_dataloader , validation_dataloader)  \n",
      "\n",
      "\n",
      "\n",
      "    print(\"prediction on validation data\")\n",
      "\n",
      "    model = FeedbackPrizeModel.load_from_checkpoint(f'{config.save_dir}/{config.model_name}_{fold}.ckpt')\n",
      "\n",
      "    preds = predict(validation_dataloader, model)    \n",
      "\n",
      "    score = competition_metrics(y_test,preds)\n",
      "\n",
      "    scores.append(score)\n",
      "\n",
      "    \n",
      "\n",
      "    del model,train_dataloader,validation_dataloader,X_train,X_test,y_train,y_test,train_dataset,validation_dataset\n",
      "\n",
      "    gc.collect()\n",
      "\n",
      "    torch.cuda.empty_cache()\n",
      "\n",
      "    \n",
      "\n",
      "    print(f\"Log Loss for Fold {fold} is {score}\")\n",
      "\n",
      "\n",
      "\n",
      "print(\"the final average Log Loss is \", np.mean(scores))\n",
      "\n",
      "\n",
      "#################################################\n",
      "\n",
      "if __name__ == '__main__':\n",
      "\n",
      "    \n",
      "\n",
      "    def get_result(oof_df):\n",
      "\n",
      "        labels = oof_df['discourse_effectiveness'].values\n",
      "\n",
      "        preds = oof_df[['pred_0','pred_1','pred_2']].values\n",
      "\n",
      "        score = get_score(labels, preds)\n",
      "\n",
      "        LOGGER.info(f'Score: {score:<.4f}')\n",
      "\n",
      "    \n",
      "\n",
      "    oof_df = pd.DataFrame()\n",
      "\n",
      "    for fold in range(CFG.n_fold):\n",
      "\n",
      "        if fold in CFG.trn_fold:\n",
      "\n",
      "            _oof_df = train_loop(train, fold)\n",
      "\n",
      "            oof_df = pd.concat([oof_df, _oof_df])\n",
      "\n",
      "            LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
      "\n",
      "            get_result(_oof_df)\n",
      "\n",
      "    oof_df = oof_df.reset_index(drop=True)\n",
      "\n",
      "    LOGGER.info(f\"========== CV ==========\")\n",
      "\n",
      "    get_result(oof_df)\n",
      "\n",
      "    oof_df.to_pickle(OUTPUT_DIR+'oof_df.pkl')\n",
      "\n",
      "        \n",
      "\n",
      "    if CFG.wandb:\n",
      "\n",
      "        wandb.finish()\n",
      "\n",
      "#################################################\n",
      "\n",
      "%%time\n",
      "\n",
      "import gc\n",
      "\n",
      "\n",
      "\n",
      "hard_targets = ['F_1_7', 'F_1_12', 'F_1_13', 'F_3_19', 'F_3_21'] + ['F_4_'+str(i) for i in range(15)]\n",
      "\n",
      "\n",
      "\n",
      "for it, TARGET_NAME in enumerate(cols_to_predict):\n",
      "\n",
      "    print('='*50)\n",
      "\n",
      "    print('START COLUMN {}/{} {}'.format(it+1, N_targets, TARGET_NAME))\n",
      "\n",
      "    train_data = data[~data[TARGET_NAME].isna()]\n",
      "\n",
      "    test_data = data[data[TARGET_NAME].isna()]\n",
      "\n",
      "    print(train_data.shape, test_data.shape)\n",
      "\n",
      "\n",
      "\n",
      "    features = [x for x in train_data.columns if x not in ['row_id', TARGET_NAME]]\n",
      "\n",
      "    NN_OOF_PRED = np.zeros(len(train_data))\n",
      "\n",
      "    NN_TEST_PRED = np.zeros(len(test_data))\n",
      "\n",
      "\n",
      "\n",
      "    y = train_data[TARGET_NAME].values\n",
      "\n",
      "    train_data = train_data[features].fillna(train_data.mean())\n",
      "\n",
      "    X_test = test_data[features].fillna(train_data.mean())\n",
      "\n",
      "    N_START = 2\n",
      "\n",
      "    print(N_START)\n",
      "\n",
      "    T0 = time.time()\n",
      "\n",
      "    for it in range(N_START):\n",
      "\n",
      "        T = time.time()\n",
      "\n",
      "        skf = KFold(n_splits = N_FOLDS, random_state = RANDOM_STATE + it, shuffle = True)\n",
      "\n",
      "        for fold, (train_idx, valid_idx) in enumerate(skf.split(y, y)):\n",
      "\n",
      "            X_train = train_data.iloc[train_idx, :]\n",
      "\n",
      "            X_valid = train_data.iloc[valid_idx, :]\n",
      "\n",
      "            y_train = y[train_idx]\n",
      "\n",
      "            y_valid = y[valid_idx]\n",
      "\n",
      "\n",
      "\n",
      "            if TARGET_NAME in hard_targets:\n",
      "\n",
      "                print('TRAIN HARD')\n",
      "\n",
      "                val_pred, test_pred = fit_model_hard(X_train, y_train, \n",
      "\n",
      "                                                    X_valid, y_valid, \n",
      "\n",
      "                                                    X_test, 50)\n",
      "\n",
      "            else:\n",
      "\n",
      "                print('TRAIN EASY')\n",
      "\n",
      "                val_pred, test_pred = fit_model(X_train, y_train, \n",
      "\n",
      "                                                X_valid, y_valid, \n",
      "\n",
      "                                                X_test, 50)\n",
      "\n",
      "\n",
      "\n",
      "            print('ITER = {} FOLD {} score {:.5f}'.format(it, fold, mean_squared_error(y_valid, val_pred, squared = False)))\n",
      "\n",
      "\n",
      "\n",
      "            NN_OOF_PRED[valid_idx] += val_pred / N_START\n",
      "\n",
      "            NN_TEST_PRED += test_pred / N_FOLDS / N_START\n",
      "\n",
      "            del X_train, X_valid\n",
      "\n",
      "            gc.collect()\n",
      "\n",
      "        print('AFTER ITER {} NN OOF score {:.5f}, time {:.2f}'.format(it, \n",
      "\n",
      "                                                                  mean_squared_error(y, NN_OOF_PRED / (it + 1) * N_START, squared = False), \n",
      "\n",
      "                                                                  time.time() - T))\n",
      "\n",
      "\n",
      "\n",
      "    print('NN OOF score {:.5f}, time {:.2f}'.format(mean_squared_error(y, NN_OOF_PRED, squared = False), time.time() - T0))\n",
      "\n",
      "    FINAL_PREDS.append(pd.DataFrame([[str(idx) + '-' + TARGET_NAME, val] for idx,val in zip(test_data['row_id'].values, NN_TEST_PRED)], \n",
      "\n",
      "                                    columns = submission.columns))\n",
      "\n",
      "#################################################\n",
      "\n",
      "%%sh\n",
      "\n",
      "#Shell script cell\n",
      "\n",
      "dataset=reut90\n",
      "\n",
      "for fold in `seq 7 9`\n",
      "\n",
      "do\n",
      "\n",
      "    python -m scripts.run_language_modeling \\\n",
      "\n",
      "            --train_data_file /kaggle/working/data/datasets/$dataset/train$fold \\\n",
      "\n",
      "            --line_by_line \\\n",
      "\n",
      "            --output_dir models/$dataset/fold$fold \\\n",
      "\n",
      "            --model_type bert \\\n",
      "\n",
      "            --model_name_or_path bert-base-cased \\\n",
      "\n",
      "            --mlm \\\n",
      "\n",
      "            --do_train \\\n",
      "\n",
      "            --num_train_epochs 10 \\\n",
      "\n",
      "            --learning_rate 5e-5 \\\n",
      "\n",
      "            --per_gpu_train_batch_size 16 \\\n",
      "\n",
      "            --block_size 256 \\\n",
      "\n",
      "            --save_steps 1000000\n",
      "\n",
      "done\n",
      "\n",
      "rm -r /kaggle/working/data/datasets/$dataset\n",
      "\n",
      "#################################################\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "\n",
      "    \"\"\"\n",
      "\n",
      "    Usage:\n",
      "\n",
      "        python run_net.py train --data_folder \"COVID-19-20_v2/Train\" # run the training pipeline\n",
      "\n",
      "        python run_net.py infer --data_folder \"COVID-19-20_v2/Validation\" # run the inference pipeline\n",
      "\n",
      "    \"\"\"\n",
      "\n",
      "    parser = argparse.ArgumentParser(description=\"Run a basic UNet segmentation baseline.\")\n",
      "\n",
      "    parser.add_argument(\n",
      "\n",
      "        \"--mode\", metavar=\"mode\", default=\"train\", choices=(\"train\", \"infer\"), type=str, help=\"mode of workflow\"\n",
      "\n",
      "    )\n",
      "\n",
      "    parser.add_argument(\"--data_folder\", default=\"\", type=str, help=\"training data folder\")\n",
      "\n",
      "    parser.add_argument(\"--data_folderV\", default=\"\", type=str, help=\"validation data folder\")\n",
      "\n",
      "    parser.add_argument(\"--model_folder\", default=\"runs\", type=str, help=\"model folder\")\n",
      "\n",
      "    parser.add_argument(\"--load_model\", default=\"\", type=str, help=\"load model\")\n",
      "\n",
      "    parser.add_argument(\"--prediction_folder\", default=\"\", type=str, help=\"prediction folder\")\n",
      "\n",
      "    args = parser.parse_args(args=[])\n",
      "\n",
      "\n",
      "\n",
      "    monai.config.print_config()\n",
      "\n",
      "    monai.utils.set_determinism(seed=0)\n",
      "\n",
      "\n",
      "\n",
      "    args.data_folder=\"../working/Train/\"\n",
      "\n",
      "    args.data_folderV=\"../working/Validation/\"\n",
      "\n",
      "    args.model_folder=\"../working/runs/\"\n",
      "\n",
      "    args.load_model=\"../input/unet-model/\"\n",
      "\n",
      "    args.prediction_folder=\"../working/output/\"\n",
      "\n",
      "    args.mode = \"train\"\n",
      "\n",
      "    #args.mode = \"infer\"\n",
      "\n",
      "    \n",
      "\n",
      "    if args.mode == \"train\":\n",
      "\n",
      "        data_folder = args.data_folder or os.path.join(\"COVID-19-20_v2\", \"Train\")\n",
      "\n",
      "        train(data_folder=data_folder, model_folder=args.model_folder, load_model=args.load_model)\n",
      "\n",
      "    elif args.mode == \"infer\":\n",
      "\n",
      "        data_folder = args.data_folderV or os.path.join(\"COVID-19-20_v2\", \"Validation\")\n",
      "\n",
      "        infer(data_folder=data_folder, model_folder=args.load_model, prediction_folder=args.prediction_folder)\n",
      "\n",
      "    else:\n",
      "\n",
      "        raise ValueError(\"Unknown mode.\")\n",
      "\n",
      "#################################################\n",
      "\n",
      "epochs = 200\n",
      "\n",
      "lr = 3e-4\n",
      "\n",
      "learner.fit_one_cycle(\n",
      "\n",
      "    epochs,\n",
      "\n",
      "    lr,\n",
      "\n",
      "    cbs=[ShowGraphCallback, SaveModelCallback(monitor=\"mae_loss\", with_opt=True, fname=\"best_model\")]\n",
      "\n",
      ")\n",
      "\n",
      "#################################################\n",
      "\n",
      "cfg = get_cfg()\n",
      "\n",
      "config_name = \"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\" \n",
      "\n",
      "#config_name = \"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\"\n",
      "\n",
      "#config_name = \"COCO-Detection/faster_rcnn_R_101_C4_3x.yaml\"\n",
      "\n",
      "\n",
      "\n",
      "cfg.merge_from_file(model_zoo.get_config_file(config_name))\n",
      "\n",
      "\n",
      "\n",
      "cfg.DATASETS.TRAIN = (Data_Resister_training,)\n",
      "\n",
      "\n",
      "\n",
      "if split_mode == \"all_train\":\n",
      "\n",
      "    cfg.DATASETS.TEST = ()\n",
      "\n",
      "else:\n",
      "\n",
      "    cfg.DATASETS.TEST = (Data_Resister_valid,)\n",
      "\n",
      "    cfg.TEST.EVAL_PERIOD = 1000\n",
      "\n",
      "\n",
      "\n",
      "cfg.DATALOADER.NUM_WORKERS = 0\n",
      "\n",
      "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(config_name)\n",
      "\n",
      "#cfg.MODEL.WEIGHTS=\"../input/nfl-extra-images-detectron2-weights/output/model_final.pth\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cfg.SOLVER.IMS_PER_BATCH = 2\n",
      "\n",
      "cfg.SOLVER.BASE_LR = 0.0025\n",
      "\n",
      "\n",
      "\n",
      "cfg.SOLVER.WARMUP_ITERS = 1000\n",
      "\n",
      "cfg.SOLVER.MAX_ITER = 20000 #adjust up if val mAP is still rising, adjust down if overfit\n",
      "\n",
      "#cfg.SOLVER.STEPS = (100, 500) # must be less than  MAX_ITER \n",
      "\n",
      "#cfg.SOLVER.GAMMA = 0.05\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "cfg.SOLVER.CHECKPOINT_PERIOD = 100000  # Small value=Frequent save need a lot of storage.\n",
      "\n",
      "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
      "\n",
      "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#Training using custom trainer defined above\n",
      "\n",
      "trainer = AugTrainer(cfg) \n",
      "\n",
      "#trainer = DefaultTrainer(cfg) \n",
      "\n",
      "trainer.resume_or_load(resume=False)\n",
      "\n",
      "trainer.train()\n",
      "\n",
      "#################################################\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "\n",
      "    main()\n",
      "\n",
      "#################################################\n",
      "\n",
      "params = [p for p in model.parameters() if p.requires_grad]\n",
      "\n",
      "optimizer = torch.optim.SGD(params, lr=0.0015, momentum=0.9, weight_decay=0.0005)\n",
      "\n",
      "# lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
      "\n",
      "lr_scheduler = None\n",
      "\n",
      "\n",
      "\n",
      "n_batches, n_batches_val = len(dl_train), len(dl_val)\n",
      "\n",
      "validation_losses = []\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "for epoch in range(NUM_EPOCHS):\n",
      "\n",
      "    time_start = time.time()\n",
      "\n",
      "    loss_accum = 0\n",
      "\n",
      "    \n",
      "\n",
      "    for batch_idx, (images, targets) in enumerate(dl_train, 1):\n",
      "\n",
      "        \n",
      "\n",
      "        images = list(image.float().to(DEVICE) for image in images)\n",
      "\n",
      "        targets = [{k: v.to(torch.float32).to(DEVICE) if \"box\" in k else v.to(DEVICE) for k, v in t.items()} for t in targets]\n",
      "\n",
      "\n",
      "\n",
      "        # Predict\n",
      "\n",
      "        loss_dict = model(images, targets)\n",
      "\n",
      "        losses = sum(loss for loss in loss_dict.values())\n",
      "\n",
      "        loss_value = losses.item()\n",
      "\n",
      "\n",
      "\n",
      "        loss_accum += loss_value\n",
      "\n",
      "\n",
      "\n",
      "        # Back-prop\n",
      "\n",
      "        optimizer.zero_grad()\n",
      "\n",
      "        losses.backward()\n",
      "\n",
      "        optimizer.step()\n",
      "\n",
      "\n",
      "\n",
      "    \n",
      "\n",
      "    # update the learning rate\n",
      "\n",
      "    if lr_scheduler is not None:\n",
      "\n",
      "        lr_scheduler.step()\n",
      "\n",
      "\n",
      "\n",
      "    # Validation \n",
      "\n",
      "    val_loss_accum = 0\n",
      "\n",
      "        \n",
      "\n",
      "    with torch.no_grad():\n",
      "\n",
      "        for batch_idx, (images, targets) in enumerate(dl_val, 1):\n",
      "\n",
      "            images = list(image.float().to(DEVICE) for image in images)\n",
      "\n",
      "            targets = [{k: v.to(torch.float32).to(DEVICE) if \"box\" in k else v.to(DEVICE) for k, v in t.items()} for t in targets]\n",
      "\n",
      "            \n",
      "\n",
      "            val_loss_dict = model(images, targets)\n",
      "\n",
      "            val_batch_loss = sum(loss for loss in val_loss_dict.values())\n",
      "\n",
      "            val_loss_accum += val_batch_loss.item()\n",
      "\n",
      "    \n",
      "\n",
      "    # Logging\n",
      "\n",
      "    val_loss = val_loss_accum / n_batches_val\n",
      "\n",
      "    train_loss = loss_accum / n_batches\n",
      "\n",
      "    validation_losses.append(val_loss)\n",
      "\n",
      "    \n",
      "\n",
      "    # Save model\n",
      "\n",
      "    chk_name = f'fasterrcnn_resnet50_fpn-e{epoch}.bin'\n",
      "\n",
      "    torch.save(model.state_dict(), chk_name)\n",
      "\n",
      "    \n",
      "\n",
      "    \n",
      "\n",
      "    elapsed = time.time() - time_start\n",
      "\n",
      "    \n",
      "\n",
      "    print(f\"[Epoch {epoch+1:2d} / {NUM_EPOCHS:2d}] Train loss: {train_loss:.3f}. Val loss: {val_loss:.3f} --> {chk_name}  [{elapsed:.0f} secs]\")   \n",
      "\n",
      "#################################################\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "\n",
      "    main()\n",
      "\n",
      "#################################################\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "\n",
      "    main()\n",
      "\n",
      "#################################################\n",
      "\n",
      "if __name__ == '__main__':\n",
      "\n",
      "    \n",
      "\n",
      "    def get_result(oof_df):\n",
      "\n",
      "        labels = oof_df['discourse_effectiveness'].values\n",
      "\n",
      "        preds = oof_df[['pred_0','pred_1','pred_2']].values\n",
      "\n",
      "        score = get_score(labels, preds)\n",
      "\n",
      "        LOGGER.info(f'Score: {score:<.4f}')\n",
      "\n",
      "    \n",
      "\n",
      "    oof_df = pd.DataFrame()\n",
      "\n",
      "    for fold in range(CFG.n_fold):\n",
      "\n",
      "        if fold in CFG.trn_fold:\n",
      "\n",
      "            _oof_df = train_loop(train, fold)\n",
      "\n",
      "            oof_df = pd.concat([oof_df, _oof_df])\n",
      "\n",
      "            LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
      "\n",
      "            get_result(_oof_df)\n",
      "\n",
      "    oof_df = oof_df.reset_index(drop=True)\n",
      "\n",
      "    LOGGER.info(f\"========== CV ==========\")\n",
      "\n",
      "    get_result(oof_df)\n",
      "\n",
      "    oof_df.to_pickle(OUTPUT_DIR+'oof_df.pkl')\n",
      "\n",
      "        \n",
      "\n",
      "    if CFG.wandb:\n",
      "\n",
      "        wandb.finish()\n",
      "\n",
      "#################################################\n",
      "\n",
      "if __name__ == '__main__':\n",
      "\n",
      "    \n",
      "\n",
      "    def get_result(oof_df):\n",
      "\n",
      "        labels = oof_df['discourse_effectiveness'].values\n",
      "\n",
      "        preds = oof_df[['pred_0','pred_1','pred_2']].values\n",
      "\n",
      "        score = get_score(labels, preds)\n",
      "\n",
      "        LOGGER.info(f'Score: {score:<.4f}')\n",
      "\n",
      "    \n",
      "\n",
      "    if True:\n",
      "\n",
      "        oof_df = pd.DataFrame()\n",
      "\n",
      "        for fold in range(CFG.n_fold):\n",
      "\n",
      "            if fold in CFG.trn_fold:\n",
      "\n",
      "                _oof_df = train_loop(train, fold)\n",
      "\n",
      "                oof_df = pd.concat([oof_df, _oof_df])\n",
      "\n",
      "                LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
      "\n",
      "                get_result(_oof_df)\n",
      "\n",
      "        oof_df = oof_df.reset_index(drop=True)\n",
      "\n",
      "        LOGGER.info(f\"========== CV ==========\")\n",
      "\n",
      "        get_result(oof_df)\n",
      "\n",
      "        oof_df.to_pickle(OUTPUT_DIR+'oof_df.pkl')\n",
      "\n",
      "        \n",
      "\n",
      "    if CFG.wandb:\n",
      "\n",
      "        wandb.finish()\n",
      "\n",
      "#################################################\n",
      "\n",
      "MODEL_NAME = \"tf_efficientnet_b4_ns\"\n",
      "\n",
      "IMAGE_SIZE = 380\n",
      "\n",
      "BATCH_SIZE = 32\n",
      "\n",
      "\n",
      "\n",
      "model, trainer, log = train(model_name=MODEL_NAME, image_size=IMAGE_SIZE, batch_size=BATCH_SIZE, max_epochs=5)\n",
      "\n",
      "#################################################\n",
      "\n",
      "best_metric = -1\n",
      "\n",
      "best_metric_epoch = -1\n",
      "\n",
      "epoch_loss_values = list()\n",
      "\n",
      "auc_metric = ROCAUCMetric()\n",
      "\n",
      "metric_values = list()\n",
      "\n",
      "\n",
      "\n",
      "for epoch in range(epoch_num):\n",
      "\n",
      "    print('-' * 10)\n",
      "\n",
      "    print(f\"epoch {epoch + 1}/{epoch_num}\")\n",
      "\n",
      "    model.train()\n",
      "\n",
      "    epoch_loss = 0\n",
      "\n",
      "    step = 0\n",
      "\n",
      "\n",
      "\n",
      "    for batch_data in train_loader:\n",
      "\n",
      "        step += 1\n",
      "\n",
      "        inputs, labels = batch_data[0].to(device), batch_data[1].to(device)\n",
      "\n",
      "        optimizer.zero_grad()\n",
      "\n",
      "        outputs = model(inputs.float())     ##### \n",
      "\n",
      "        loss = loss_function(outputs, labels)\n",
      "\n",
      "        loss.backward()\n",
      "\n",
      "        optimizer.step()\n",
      "\n",
      "        epoch_loss += loss.item()\n",
      "\n",
      "        print(f\"{step}/{len(train_ds) // train_loader.batch_size}, train_loss: {loss.item():.4f}\")\n",
      "\n",
      "        epoch_len = len(train_ds) // train_loader.batch_size\n",
      "\n",
      "\n",
      "\n",
      "    epoch_loss /= step\n",
      "\n",
      "    epoch_loss_values.append(epoch_loss)\n",
      "\n",
      "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
      "\n",
      "\n",
      "\n",
      "    if (epoch + 1) % val_interval == 0:\n",
      "\n",
      "        model.eval()\n",
      "\n",
      "        with torch.no_grad():\n",
      "\n",
      "            y_pred = torch.tensor([], dtype=torch.float32, device=device)\n",
      "\n",
      "            y = torch.tensor([], dtype=torch.long, device=device)\n",
      "\n",
      "            for val_data in val_loader:\n",
      "\n",
      "                val_images, val_labels = val_data[0].to(device), val_data[1].to(device)\n",
      "\n",
      "                y_pred = torch.cat([y_pred, model(val_images.float())], dim=0)\n",
      "\n",
      "                y = torch.cat([y, val_labels], dim=0)\n",
      "\n",
      "                \n",
      "\n",
      "            y_onehot = [to_onehot(i) for i in y]\n",
      "\n",
      "            y_pred_act = [act(i) for i in y_pred]\n",
      "\n",
      "            auc_metric(y_pred_act, y_onehot)\n",
      "\n",
      "            auc_result = auc_metric.aggregate()\n",
      "\n",
      "            auc_metric.reset()\n",
      "\n",
      "            del y_pred_act, y_onehot\n",
      "\n",
      "            metric_values.append(auc_result)\n",
      "\n",
      "            acc_value = torch.eq(y_pred.argmax(dim=1), y)\n",
      "\n",
      "            acc_metric = acc_value.sum().item() / len(acc_value)\n",
      "\n",
      "            \n",
      "\n",
      "            if acc_metric > best_metric:\n",
      "\n",
      "                best_metric = acc_metric\n",
      "\n",
      "                best_metric_epoch = epoch + 1\n",
      "\n",
      "                torch.save(model.state_dict(), 'best_metric_model.pth')\n",
      "\n",
      "                print('saved new best metric model')\n",
      "\n",
      "                \n",
      "\n",
      "            print(f\"current epoch: {epoch + 1} current AUC: {auc_result:.4f}\"\n",
      "\n",
      "                  f\" current accuracy: {acc_metric:.4f} best AUC: {best_metric:.4f}\"\n",
      "\n",
      "                  f\" at epoch: {best_metric_epoch}\")\n",
      "\n",
      "            \n",
      "\n",
      "print(f\"train completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")\n",
      "\n",
      "\n",
      "#################################################\n",
      "\n",
      "G = Generator()\n",
      "\n",
      "D = Discriminator()\n",
      "\n",
      "G.weight_init(mean=0.0, std=0.02)\n",
      "\n",
      "D.weight_init(mean=0.0, std=0.02)\n",
      "\n",
      "\n",
      "\n",
      "EPOCH = 200 \n",
      "\n",
      "trained_G, trained_D = train_loop(train_dl, G, D, EPOCH)\n",
      "\n",
      "#################################################\n",
      "\n",
      "print(f'TRAINING FOR {EPOCHS} EPOCHS WITH BATCH SIZE {BATCH_SIZE}\\n')\n",
      "\n",
      "print(f'TRAIN IMAGES: {N_TRAIN_IMGS}, VAL IMAGES: {N_VAL_IMGS}\\n')\n",
      "\n",
      "\n",
      "\n",
      "augmentations_dic = dict({\n",
      "\n",
      "    0: 'None',\n",
      "\n",
      "    1: 'MixUp',\n",
      "\n",
      "    2: 'CutMix',\n",
      "\n",
      "    3: 'GridMask',\n",
      "\n",
      "})\n",
      "\n",
      "\n",
      "\n",
      "net_choices = dict({\n",
      "\n",
      "    0: \"Efficientnet\",\n",
      "\n",
      "    1: \"ResNet\",\n",
      "\n",
      "    2: \"DenseNet\"\n",
      "\n",
      "})\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "augmentations = [2, 3] # only CutMix and GridMask is used\n",
      "\n",
      "model_choices = [0, 1, 2]   # choice as given in above dictionary\n",
      "\n",
      "history_array = []\n",
      "\n",
      "# MEAN_VAL_ACC = []\n",
      "\n",
      "# fold = 0\n",
      "\n",
      "# epochs = EPOCHS\n",
      "\n",
      "\n",
      "\n",
      "for choice in model_choices:\n",
      "\n",
      "    MEAN_VAL_ACC = []\n",
      "\n",
      "    fold = 0\n",
      "\n",
      "    epochs = EPOCHS\n",
      "\n",
      "    for idx, fold in enumerate(range(N_FOLDS)):\n",
      "\n",
      "        # callbacks\n",
      "\n",
      "        lr_callback_1 = tf.keras.callbacks.LearningRateScheduler(lambda epoch: lrfn(epoch, epochs=epochs), verbose=1)\n",
      "\n",
      "    #     lr_callback_2 = tf.keras.callbacks.LearningRateScheduler(lrfn2, verbose = True)\n",
      "\n",
      "    #     show_lr_schedule(epochs=epochs)\n",
      "\n",
      "\n",
      "\n",
      "        # get the model\n",
      "\n",
      "        model = get_model(choice)\n",
      "\n",
      "\n",
      "\n",
      "        if idx is 0:\n",
      "\n",
      "            # model summary\n",
      "\n",
      "            model.summary()\n",
      "\n",
      "            # compute and variable data types\n",
      "\n",
      "            print(f'Compute dtype: {mixed_precision.global_policy().compute_dtype}')\n",
      "\n",
      "            print(f'Variable dtype: {mixed_precision.global_policy().variable_dtype}')\n",
      "\n",
      "\n",
      "\n",
      "        print('\\n')\n",
      "\n",
      "        print('*'*25, f'augmentations {augmentations}', '*'*25, '\\n')\n",
      "\n",
      "        print(f'fold: {fold}, epochs: {epochs}')\n",
      "\n",
      "        print(' AND '.join([augmentations_dic.get(i) for i in augmentations]), '\\n')\n",
      "\n",
      "\n",
      "\n",
      "        train_dataset = get_train_dataset(bs=BATCH_SIZE, fold=fold, augmentations=augmentations)\n",
      "\n",
      "        val_dataset = get_val_dataset(bs=BATCH_SIZE_VAL, fold=fold)\n",
      "\n",
      "        \n",
      "\n",
      "        with strategy.scope():\n",
      "\n",
      "            history = model.fit(\n",
      "\n",
      "                train_dataset,\n",
      "\n",
      "                steps_per_epoch = N_TRAIN_IMGS // BATCH_SIZE,\n",
      "\n",
      "\n",
      "\n",
      "                validation_data = val_dataset,\n",
      "\n",
      "                validation_steps = N_VAL_IMGS // BATCH_SIZE_VAL,\n",
      "\n",
      "\n",
      "\n",
      "                epochs = epochs,\n",
      "\n",
      "                callbacks = [lr_callback_1],\n",
      "\n",
      "                verbose=0\n",
      "\n",
      "            )\n",
      "\n",
      "\n",
      "\n",
      "        # add val accuracy to list\n",
      "\n",
      "        MEAN_VAL_ACC.append(history.history['val_accuracy'][-1])\n",
      "\n",
      "\n",
      "\n",
      "        # # plot training histories\n",
      "\n",
      "        # plot_history_metric(history, 'loss')\n",
      "\n",
      "        # plot_history_metric(history, 'accuracy')\n",
      "\n",
      "        # plot_history_metric(history, 'top_2_accuracy')\n",
      "\n",
      "\n",
      "\n",
      "        # # show train and validation report\n",
      "\n",
      "        # show_validation_report_per_class(model, val_dataset, N_VAL_IMGS // BATCH_SIZE_VAL, 'VALIDATION', BATCH_SIZE_VAL)\n",
      "\n",
      "\n",
      "\n",
      "        # save the model\n",
      "\n",
      "        model.save_weights(f'model_fold_{fold}_weights.h5')\n",
      "\n",
      "        model.save(f'model_{net_choices.get(choice)}_fold_{fold}.h5')\n",
      "\n",
      "        # show train and validation report\n",
      "\n",
      "        \n",
      "\n",
      "        show_validation_report_per_class(model, val_dataset, N_VAL_IMGS // BATCH_SIZE_VAL, 'VALIDATION', BATCH_SIZE_VAL)\n",
      "\n",
      "        \n",
      "\n",
      "        del model, train_dataset, val_dataset\n",
      "\n",
      "        gc.collect()\n",
      "\n",
      "    # plot training histories\n",
      "\n",
      "    history_array.append(history)\n",
      "\n",
      "    \n",
      "\n",
      "plot_history_metric(history_array, 'loss')\n",
      "\n",
      "plot_history_metric(history_array, 'accuracy')\n",
      "\n",
      "plot_history_metric(history_array, 'top_2_accuracy')\n",
      "\n",
      "\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "#################################################\n",
      "\n",
      "# Path to the weights stored in the dataset\n",
      "\n",
      "yolo_model_path = '/kaggle/input/my-yolov5-for-offline-use/yolov5l.pt'\n",
      "\n",
      "\n",
      "\n",
      "# If you uncomment and run this line you will get a request to enter a \n",
      "\n",
      "# wandb password. To solve this problem we include WANDB_MODE=\"dryrun\" in\n",
      "\n",
      "# the next line.\n",
      "\n",
      "#! python train.py --img 1024 --batch 8 --epochs 2 --data my_data.yaml --cfg models/yolov5s.yaml --name my_model\n",
      "\n",
      "\n",
      "\n",
      "# Note that now hyp=my_hyp.yaml in the printout blow.\n",
      "\n",
      "!WANDB_MODE=\"dryrun\" python train.py --img $IMAGE_SIZE --batch $BATCH_SIZE --epochs $NUM_EPOCHS --data my_data.yaml --hyp my_hyp.yaml --weights $yolo_model_path\n",
      "\n",
      "#################################################\n",
      "\n",
      "# Load\n",
      "\n",
      "IoU_save = []\n",
      "\n",
      "mIoU_save = []\n",
      "\n",
      "F1_save = []\n",
      "\n",
      "mF1_save = []\n",
      "\n",
      "loss_save = []\n",
      "\n",
      "\n",
      "\n",
      "for i in range(20):\n",
      "\n",
      "    print(\" \")\n",
      "\n",
      "    print(\"Model \", (i+1)*100)\n",
      "\n",
      "\n",
      "\n",
      "    model_save_name = 'classifier_train_for_{}_batches.pt'.format(100*(i+1))\n",
      "\n",
      "    path = F\"../u-net-trained-models-gtav-2000-img-grey/{model_save_name}\" #../input/u-net-trained-models-gtav-2000-img-no-augmentation\n",
      "\n",
      "    # net = torch.load(PATH)\n",
      "\n",
      "    net = UNET(in_channels=3, out_channels=len(semantic_classes), features=[64, 128, 256, 512])\n",
      "\n",
      "    net = net.to(device)\n",
      "\n",
      "    net.load_state_dict(torch.load(path))\n",
      "\n",
      "    net.eval()\n",
      "\n",
      "\n",
      "\n",
      "    criterion = nn.CrossEntropyLoss()\n",
      "\n",
      "    criterion = criterion.to(device)\n",
      "\n",
      "\n",
      "\n",
      "    copy_test_loader = copy.copy(test_loader)\n",
      "\n",
      "    losses, TP, TN, FP, FN = test(copy_test_loader, net, criterion)\n",
      "\n",
      "    print(\" \")\n",
      "\n",
      "    \n",
      "\n",
      "    TP = np.asarray(TP)\n",
      "\n",
      "    TN = np.asarray(TN)\n",
      "\n",
      "    FP = np.asarray(FP)\n",
      "\n",
      "    FN = np.asarray(FN)\n",
      "\n",
      "\n",
      "\n",
      "    IoU_per_image = TP / (TP + FP + TN) # Jaccard\n",
      "\n",
      "    IoU = sum(IoU_per_image) / len(IoU_per_image)\n",
      "\n",
      "    mIoU = sum(IoU) / len(IoU)\n",
      "\n",
      "\n",
      "\n",
      "    F1_per_image = 2 * TP / (2 * TP + FP + TN) # Dice\n",
      "\n",
      "    F1 =  sum(F1_per_image) / len(F1_per_image)\n",
      "\n",
      "    mF1 = sum(F1) / len(F1)\n",
      "\n",
      "    \n",
      "\n",
      "    losses = torch.FloatTensor(losses)\n",
      "\n",
      "    print('Average loss = ',torch.mean(losses).item())\n",
      "\n",
      "    loss_save.append(torch.mean(losses))\n",
      "\n",
      "    IoU_save.append(IoU)\n",
      "\n",
      "    mIoU_save.append(mIoU)\n",
      "\n",
      "    F1_save.append(F1)\n",
      "\n",
      "    mF1_save.append(mF1)\n",
      "\n",
      "    \n",
      "\n",
      "save_name = 'losses.txt'\n",
      "\n",
      "path = F\"/kaggle/working/{save_name}\" \n",
      "\n",
      "np.savetxt(path, loss_save)\n",
      "\n",
      "print('Saved losses') \n",
      "\n",
      "\n",
      "\n",
      "save_name = 'IoU_save.txt'\n",
      "\n",
      "path = F\"/kaggle/working/{save_name}\" \n",
      "\n",
      "np.savetxt(path, IoU_save)\n",
      "\n",
      "print('Saved IoU_save') \n",
      "\n",
      "\n",
      "\n",
      "save_name = 'mIoU_save.txt'\n",
      "\n",
      "path = F\"/kaggle/working/{save_name}\" \n",
      "\n",
      "np.savetxt(path, mIoU_save)\n",
      "\n",
      "print('Saved mIoU_save') \n",
      "\n",
      "\n",
      "\n",
      "save_name = 'F1_save.txt'\n",
      "\n",
      "path = F\"/kaggle/working/{save_name}\" \n",
      "\n",
      "np.savetxt(path, F1_save)\n",
      "\n",
      "print('Saved F1_save') \n",
      "\n",
      "\n",
      "\n",
      "save_name = 'mF1_save.txt'\n",
      "\n",
      "path = F\"/kaggle/working/{save_name}\" \n",
      "\n",
      "np.savetxt(path, mF1_save)\n",
      "\n",
      "print('Saved mF1_save') \n",
      "\n",
      "\n",
      "#################################################\n",
      "\n",
      "%%time\n",
      "\n",
      "print('Starting training')\n",
      "\n",
      "train(ds, EPOCHS)\n",
      "\n",
      "\n",
      "#################################################\n",
      "\n",
      "# Set the range from 0 to 10 to run the whole Folds.\n",
      "\n",
      "for fold in range(1):\n",
      "\n",
      "    # Split the data into training data and validation data for cross validation\n",
      "\n",
      "    # The data that have same label as the fold will be used as Validation data, the rest as Training data.\n",
      "\n",
      "    train = data_df[data_df['fold']!=fold].reset_index(drop=True)\n",
      "\n",
      "    val = data_df[data_df['fold']==fold].reset_index(drop=True)\n",
      "\n",
      "    \n",
      "\n",
      "    # Making training and validating dataset.\n",
      "\n",
      "    train_dataset = PawDataSet(\n",
      "\n",
      "        dataset = train,\n",
      "\n",
      "        params = params,\n",
      "\n",
      "        features = params['features'],\n",
      "\n",
      "        transform = Transform_train()\n",
      "\n",
      "    )\n",
      "\n",
      "    val_dataset = PawDataSet(\n",
      "\n",
      "        dataset = val,\n",
      "\n",
      "        params = params,\n",
      "\n",
      "        features = params['features'],\n",
      "\n",
      "        transform = Transform_val()\n",
      "\n",
      "    )\n",
      "\n",
      "    \n",
      "\n",
      "    # Making data loader using PyTorch DataLoader function. This allow us to separate data into small batches to train the model.\n",
      "\n",
      "    train_loader  = DataLoader(\n",
      "\n",
      "        train_dataset, batch_size=params['batch_size'], shuffle=True, \n",
      "\n",
      "        num_workers=params['num_workers']\n",
      "\n",
      "    )\n",
      "\n",
      "    \n",
      "\n",
      "    val_loader = DataLoader(\n",
      "\n",
      "        val_dataset, batch_size=params['batch_size'], shuffle=False,\n",
      "\n",
      "        num_workers=params['num_workers']\n",
      "\n",
      "    )\n",
      "\n",
      "    \n",
      "\n",
      "    # Loading model into GPU.\n",
      "\n",
      "    model = PetNet()\n",
      "\n",
      "    model = model.to(device)\n",
      "\n",
      "    \n",
      "\n",
      "    # Setting criterion to calculate loss, optimizer and scheduler.\n",
      "\n",
      "    criterion = nn.BCEWithLogitsLoss()\n",
      "\n",
      "    optimizer = torch.optim.AdamW(model.parameters(),\n",
      "\n",
      "                                 lr=params['lr'],\n",
      "\n",
      "                                 weight_decay=params['weight_decay'],\n",
      "\n",
      "                                 amsgrad=False)\n",
      "\n",
      "    \n",
      "\n",
      "    # Use the scheduler functions that we defined at section 5.2 to update the learning rate in optimizer.\n",
      "\n",
      "    scheduler = get_scheduler(optimizer)\n",
      "\n",
      "    \n",
      "\n",
      "    # Early stopping functions to stop the training process if the model is not improving after each epoch.\n",
      "\n",
      "    early_stopping = EarlyStopping(patience=2, verbose=True)\n",
      "\n",
      "    \n",
      "\n",
      "    # Training and validation loop\n",
      "\n",
      "    best_rmse = np.inf\n",
      "\n",
      "    best_epoch = np.inf\n",
      "\n",
      "    best_model_name = None\n",
      "\n",
      "    \n",
      "\n",
      "    # Epoch = how many times to repeat the training loop.\n",
      "\n",
      "    for epoch in range(40):\n",
      "\n",
      "        train_fn(train_loader, model, criterion, optimizer, epoch, params, scheduler)\n",
      "\n",
      "        predictions, valid_targets = validate_fn(val_loader, model, criterion, epoch, params)\n",
      "\n",
      "        rmse = round(mean_squared_error(valid_targets, predictions, squared=False), 3)\n",
      "\n",
      "        \n",
      "\n",
      "        # Condition loop to save the model with best score.\n",
      "\n",
      "        if rmse < best_rmse:\n",
      "\n",
      "            best_rmse = rmse\n",
      "\n",
      "            best_epoch = epoch\n",
      "\n",
      "            if best_model_name is not None:\n",
      "\n",
      "                os.remove(best_model_name)\n",
      "\n",
      "                \n",
      "\n",
      "            # Saving state_dict of the best model to rerun it later for inference.\n",
      "\n",
      "            torch.save(model.state_dict(),\n",
      "\n",
      "                       f\"{params['model']}_epoch_f{fold}.pth\")\n",
      "\n",
      "            best_model_name = f\"{params['model']}_epoch_f{fold}.pth\"\n",
      "\n",
      "        \n",
      "\n",
      "        # Evaluate the output rmse of the model to decide whether to stop the loop or not.\n",
      "\n",
      "        early_stopping(rmse, model)\n",
      "\n",
      "        \n",
      "\n",
      "        # Stop the training loop if the score doesn't improve after each epoch.\n",
      "\n",
      "        if early_stopping.early_stop:\n",
      "\n",
      "            print(\"Early stopping\")\n",
      "\n",
      "            break\n",
      "\n",
      "            \n",
      "\n",
      "    # Print summary\n",
      "\n",
      "    print('')\n",
      "\n",
      "    print(f'The best RMSE: {best_rmse} for fold {fold+1} was achieved on epoch: {best_epoch}')\n",
      "\n",
      "    print(f'The best saved model is: {best_model_name}')\n",
      "\n",
      "    best_models_of_each_fold.append(best_model_name)\n",
      "\n",
      "    rmse_tracker.append(best_rmse)\n",
      "\n",
      "    print(''.join(['#']*50))\n",
      "\n",
      "    del model\n",
      "\n",
      "    gc.collect()\n",
      "\n",
      "    torch.cuda.empty_cache()\n",
      "\n",
      "    \n",
      "\n",
      "print('')\n",
      "\n",
      "print(f'Average RMSE of all folds: {round(np.mean(rmse_tracker), 4)}')\n",
      "\n",
      "    \n",
      "\n",
      "    \n",
      "\n",
      "#################################################\n",
      "\n",
      "def nn_model(n_feats):\n",
      "\n",
      "    inputs = Input(shape=(n_feats))\n",
      "\n",
      "    x = Dense(64, activation='swish')(inputs)\n",
      "\n",
      "    #x = Dropout(0.1)(x)\n",
      "\n",
      "    x = Dense(64, activation='swish')(x)\n",
      "\n",
      "    #x = Dropout(0.1)(x)\n",
      "\n",
      "    x = Dense(16, activation='swish')(x)\n",
      "\n",
      "    x = Dense(1, activation='sigmoid')(x)\n",
      "\n",
      "    model = Model(inputs, x)\n",
      "\n",
      "    return model\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "def fit_model(X_train, y_train, \n",
      "\n",
      "              X_valid, y_valid, \n",
      "\n",
      "              X_test):\n",
      "\n",
      "    \n",
      "\n",
      "    scaler = StandardScaler()\n",
      "\n",
      "    X_tr = scaler.fit_transform(X_train)\n",
      "\n",
      "    X_va = scaler.transform(X_valid)\n",
      "\n",
      "    X_te = scaler.transform(X_test)\n",
      "\n",
      "    valid_data = (X_va, y_valid)\n",
      "\n",
      "\n",
      "\n",
      "    lr = ReduceLROnPlateau(monitor = \"val_loss\", factor = 0.75, \n",
      "\n",
      "                           patience = 10, verbose = 0)\n",
      "\n",
      "    es = EarlyStopping(monitor = \"val_loss\", patience = 20, \n",
      "\n",
      "                       verbose = 1, restore_best_weights = True)\n",
      "\n",
      "    model = nn_model(X_train.shape[1])\n",
      "\n",
      "    model.compile(optimizer = Adam(learning_rate = 0.01),\n",
      "\n",
      "                  loss = BinaryCrossentropy())\n",
      "\n",
      "\n",
      "\n",
      "    history = model.fit(X_tr, y_train, \n",
      "\n",
      "                        validation_data = valid_data, \n",
      "\n",
      "                        epochs = 500,\n",
      "\n",
      "                        verbose = 0,\n",
      "\n",
      "                        batch_size = 4096,\n",
      "\n",
      "                        shuffle = True,\n",
      "\n",
      "                        callbacks = [lr, es])\n",
      "\n",
      "    \n",
      "\n",
      "    y_valid_pred = model.predict(X_va).reshape(1, -1)[0]\n",
      "\n",
      "    y_test_pred = model.predict(X_te).reshape(1, -1)[0]\n",
      "\n",
      "\n",
      "\n",
      "    return y_valid_pred, y_test_pred\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "features = [x for x in train_data.columns if x not in ['id', TARGET_NAME, 'f_27']]\n",
      "\n",
      "NN_OOF_PRED = np.zeros(len(train_data))\n",
      "\n",
      "NN_TEST_PRED = np.zeros(len(test_data))\n",
      "\n",
      "    \n",
      "\n",
      "y = train_data[TARGET_NAME].values\n",
      "\n",
      "X_test = test_data[features]\n",
      "\n",
      "N_START = 9\n",
      "\n",
      "for it in range(N_START):\n",
      "\n",
      "    skf = StratifiedKFold(n_splits = N_FOLDS, random_state = RANDOM_STATE + it, shuffle = True)\n",
      "\n",
      "    for fold, (train_idx, valid_idx) in enumerate(skf.split(y, y)):\n",
      "\n",
      "        X_train = train_data.iloc[train_idx, :][features]\n",
      "\n",
      "        X_valid = train_data.iloc[valid_idx, :][features]\n",
      "\n",
      "        y_train = y[train_idx]\n",
      "\n",
      "        y_valid = y[valid_idx]\n",
      "\n",
      "\n",
      "\n",
      "        val_pred, test_pred = fit_model(X_train, y_train, \n",
      "\n",
      "                                        X_valid, y_valid, \n",
      "\n",
      "                                        X_test)\n",
      "\n",
      "\n",
      "\n",
      "        print('ITER = {} FOLD {} score {:.5f}'.format(it, fold, roc_auc_score(y_valid, val_pred)))\n",
      "\n",
      "\n",
      "\n",
      "        NN_OOF_PRED[valid_idx] += val_pred / N_START\n",
      "\n",
      "        NN_TEST_PRED += test_pred / N_FOLDS / N_START\n",
      "\n",
      "    print('AFTER ITER {} NN OOF score {:.5f}'.format(it, roc_auc_score(y, NN_OOF_PRED)))\n",
      "\n",
      "    \n",
      "\n",
      "print('NN OOF score {:.5f}'.format(roc_auc_score(y, NN_OOF_PRED)))\n",
      "\n",
      "#################################################\n",
      "\n",
      "if __name__ == '__main__':\n",
      "\n",
      "    \n",
      "\n",
      "    def get_result(oof_df):\n",
      "\n",
      "        labels = oof_df['discourse_effectiveness'].values\n",
      "\n",
      "        preds = oof_df[['pred_0','pred_1','pred_2']].values\n",
      "\n",
      "        score = get_score(labels, preds)\n",
      "\n",
      "        LOGGER.info(f'Score: {score:<.4f}')\n",
      "\n",
      "    \n",
      "\n",
      "    oof_df = pd.DataFrame()\n",
      "\n",
      "    for fold in range(CFG.n_fold):\n",
      "\n",
      "        if fold in CFG.trn_fold:\n",
      "\n",
      "            _oof_df = train_loop(train, fold)\n",
      "\n",
      "            oof_df = pd.concat([oof_df, _oof_df])\n",
      "\n",
      "            LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
      "\n",
      "            get_result(_oof_df)\n",
      "\n",
      "    oof_df = oof_df.reset_index(drop=True)\n",
      "\n",
      "    LOGGER.info(f\"========== CV ==========\")\n",
      "\n",
      "    get_result(oof_df)\n",
      "\n",
      "    oof_df.to_pickle(OUTPUT_DIR+'oof_df.pkl')\n",
      "\n",
      "        \n",
      "\n",
      "    if CFG.wandb:\n",
      "\n",
      "        wandb.finish()\n",
      "\n",
      "#################################################\n",
      "\n",
      "main(config)\n",
      "\n",
      "#################################################\n",
      "\n",
      "model = FeedBackModel(CONFIG['model_name'])\n",
      "\n",
      "model.to(CONFIG['device'])\n",
      "\n",
      "\n",
      "\n",
      "optimizer = AdamW(model.parameters(), lr=CONFIG['learning_rate'])\n",
      "\n",
      "criterion = nn.CrossEntropyLoss()\n",
      "\n",
      "model, history = start_training(\n",
      "\n",
      "    model, optimizer, device=CONFIG['device'], num_epochs=CONFIG['epochs'])\n",
      "\n",
      "\n",
      "#################################################\n",
      "\n",
      "df.apply(carve_img, axis=1)\n",
      "\n",
      "#################################################\n",
      "\n",
      "if __name__ == '__main__':\n",
      "\n",
      "    \n",
      "\n",
      "    def get_result(oof_df):\n",
      "\n",
      "        labels = oof_df['discourse_effectiveness'].values\n",
      "\n",
      "        preds = oof_df[['pred_0','pred_1','pred_2']].values\n",
      "\n",
      "        score = get_score(labels, preds)\n",
      "\n",
      "        LOGGER.info(f'Score: {score:<.4f}')\n",
      "\n",
      "    \n",
      "\n",
      "    oof_df = pd.DataFrame()\n",
      "\n",
      "    for fold in range(CFG.n_fold):\n",
      "\n",
      "        if fold in CFG.trn_fold:\n",
      "\n",
      "            _oof_df = train_loop(train, fold)\n",
      "\n",
      "            oof_df = pd.concat([oof_df, _oof_df])\n",
      "\n",
      "            LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
      "\n",
      "            get_result(_oof_df)\n",
      "\n",
      "    oof_df = oof_df.reset_index(drop=True)\n",
      "\n",
      "    LOGGER.info(f\"========== CV ==========\")\n",
      "\n",
      "    get_result(oof_df)\n",
      "\n",
      "    oof_df.to_pickle(OUTPUT_DIR+'oof_df.pkl')\n",
      "\n",
      "        \n",
      "\n",
      "    if CFG.wandb:\n",
      "\n",
      "        wandb.finish()\n",
      "\n",
      "#################################################\n",
      "\n",
      "# Train model\n",
      "\n",
      "\n",
      "\n",
      "model.to(device)\n",
      "\n",
      "EPOCHS = 3\n",
      "\n",
      "criterion = nn.CrossEntropyLoss()\n",
      "\n",
      "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
      "\n",
      "\n",
      "\n",
      "last_train_loss = 0\n",
      "\n",
      "\n",
      "\n",
      "for epoch in range(EPOCHS):\n",
      "\n",
      "    print(f'Epoch: {epoch+1}/{EPOCHS}')\n",
      "\n",
      "    \n",
      "\n",
      "    correct = 0\n",
      "\n",
      "    total = 0\n",
      "\n",
      "    losses = []\n",
      "\n",
      "    \n",
      "\n",
      "    for batch_idx, data in enumerate(tqdm(train_loader)):\n",
      "\n",
      "        images, targets = data\n",
      "\n",
      "        images = images.to(device)\n",
      "\n",
      "        targets = targets.to(device)\n",
      "\n",
      "        \n",
      "\n",
      "        output = model(images)  # (batch_size, num_classes)\n",
      "\n",
      "        \n",
      "\n",
      "        loss = criterion(output, targets)\n",
      "\n",
      "        \n",
      "\n",
      "        optimizer.zero_grad()\n",
      "\n",
      "        loss.backward()\n",
      "\n",
      "        optimizer.step()\n",
      "\n",
      "        \n",
      "\n",
      "        _, pred = torch.max(output, 1)\n",
      "\n",
      "        correct += (pred == targets).sum().item()\n",
      "\n",
      "        total += pred.size(0)\n",
      "\n",
      "        \n",
      "\n",
      "        losses.append(loss.item())\n",
      "\n",
      "        \n",
      "\n",
      "    train_loss = np.mean(losses)\n",
      "\n",
      "    train_acc = correct * 1.0 / total\n",
      "\n",
      "    \n",
      "\n",
      "    last_train_loss = train_loss\n",
      "\n",
      "    print(f'Train Loss: {train_loss}\\tTrain Acc: {train_acc}')\n",
      "\n",
      "#################################################\n",
      "\n",
      "# Training\n",
      "\n",
      "\n",
      "\n",
      "epochs = 10\n",
      "\n",
      "\n",
      "\n",
      "history = model.fit(\n",
      "\n",
      "    ds_train,\n",
      "\n",
      "    validation_data=ds_val,\n",
      "\n",
      "    epochs = epochs,\n",
      "\n",
      "    callbacks=[early_stopping_cb, checkpoint_cb])\n",
      "\n",
      "#################################################\n",
      "\n",
      "best_metric = -1\n",
      "\n",
      "best_metric_epoch = -1\n",
      "\n",
      "epoch_loss_values = list()\n",
      "\n",
      "auc_metric = ROCAUCMetric()\n",
      "\n",
      "metric_values = list()\n",
      "\n",
      "\n",
      "\n",
      "for epoch in range(epoch_num):\n",
      "\n",
      "    print('-' * 10)\n",
      "\n",
      "    print(f\"epoch {epoch + 1}/{epoch_num}\")\n",
      "\n",
      "    model.train()\n",
      "\n",
      "    epoch_loss = 0\n",
      "\n",
      "    step = 0\n",
      "\n",
      "\n",
      "\n",
      "    for batch_data in train_loader:\n",
      "\n",
      "        step += 1\n",
      "\n",
      "        inputs, labels = batch_data[0].to(device), batch_data[1].to(device)\n",
      "\n",
      "        optimizer.zero_grad()\n",
      "\n",
      "        outputs = model(inputs.float())     ##### \n",
      "\n",
      "        loss = loss_function(outputs, labels)\n",
      "\n",
      "        loss.backward()\n",
      "\n",
      "        optimizer.step()\n",
      "\n",
      "        epoch_loss += loss.item()\n",
      "\n",
      "        print(f\"{step}/{len(train_ds) // train_loader.batch_size}, train_loss: {loss.item():.4f}\")\n",
      "\n",
      "        epoch_len = len(train_ds) // train_loader.batch_size\n",
      "\n",
      "\n",
      "\n",
      "    epoch_loss /= step\n",
      "\n",
      "    epoch_loss_values.append(epoch_loss)\n",
      "\n",
      "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
      "\n",
      "\n",
      "\n",
      "    if (epoch + 1) % val_interval == 0:\n",
      "\n",
      "        model.eval()\n",
      "\n",
      "        with torch.no_grad():\n",
      "\n",
      "            y_pred = torch.tensor([], dtype=torch.float32, device=device)\n",
      "\n",
      "            y = torch.tensor([], dtype=torch.long, device=device)\n",
      "\n",
      "            for val_data in val_loader:\n",
      "\n",
      "                val_images, val_labels = val_data[0].to(device), val_data[1].to(device)\n",
      "\n",
      "                y_pred = torch.cat([y_pred, model(val_images.float())], dim=0)\n",
      "\n",
      "                y = torch.cat([y, val_labels], dim=0)\n",
      "\n",
      "                \n",
      "\n",
      "            y_onehot = [to_onehot(i) for i in y]\n",
      "\n",
      "            y_pred_act = [act(i) for i in y_pred]\n",
      "\n",
      "            auc_metric(y_pred_act, y_onehot)\n",
      "\n",
      "            auc_result = auc_metric.aggregate()\n",
      "\n",
      "            auc_metric.reset()\n",
      "\n",
      "            del y_pred_act, y_onehot\n",
      "\n",
      "            metric_values.append(auc_result)\n",
      "\n",
      "            acc_value = torch.eq(y_pred.argmax(dim=1), y)\n",
      "\n",
      "            acc_metric = acc_value.sum().item() / len(acc_value)\n",
      "\n",
      "            \n",
      "\n",
      "            if acc_metric > best_metric:\n",
      "\n",
      "                best_metric = acc_metric\n",
      "\n",
      "                best_metric_epoch = epoch + 1\n",
      "\n",
      "                torch.save(model.state_dict(), 'best_metric_model.pth')\n",
      "\n",
      "                print('saved new best metric model')\n",
      "\n",
      "                \n",
      "\n",
      "            print(f\"current epoch: {epoch + 1} current AUC: {auc_result:.4f}\"\n",
      "\n",
      "                  f\" current accuracy: {acc_metric:.4f} best AUC: {best_metric:.4f}\"\n",
      "\n",
      "                  f\" at epoch: {best_metric_epoch}\")\n",
      "\n",
      "            \n",
      "\n",
      "print(f\"train completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")\n",
      "\n",
      "\n",
      "#################################################\n",
      "\n",
      "STATS = Stats()\n",
      "\n",
      "LRREDUCE = LRReduce(optimizer, LR_SCHEDULE)\n",
      "\n",
      "\n",
      "\n",
      "step_total = 0\n",
      "\n",
      "for epoch in range(EPOCHS):\n",
      "\n",
      "    print(f'***** EPOCH {epoch + 1} *****')\n",
      "\n",
      "    \n",
      "\n",
      "    t_start = time.time()\n",
      "\n",
      "    t_start_batch = time.time()\n",
      "\n",
      "    total_loss = 0\n",
      "\n",
      "    \n",
      "\n",
      "    # create distributed versions of dataset\n",
      "\n",
      "    train_dist_dataset = iter(strategy.experimental_distribute_dataset(train_dataset))\n",
      "\n",
      "    val_dist_dataset = iter(strategy.experimental_distribute_dataset(val_dataset))\n",
      "\n",
      "\n",
      "\n",
      "    for step in range(1, STEPS_PER_EPOCH + 1):\n",
      "\n",
      "        # train step\n",
      "\n",
      "        distributed_train_step(train_dist_dataset)\n",
      "\n",
      "        STATS.update_stats()\n",
      "\n",
      "        # save epoch weights\n",
      "\n",
      "        if epoch >= 16:\n",
      "\n",
      "            encoder.save_weights(f'./encoder_epoch_{epoch+1}.h5')\n",
      "\n",
      "            decoder.save_weights(f'./decoder_epoch_{epoch+1}.h5')\n",
      "\n",
      "\n",
      "\n",
      "        # end of epoch validation\n",
      "\n",
      "        if step == STEPS_PER_EPOCH:\n",
      "\n",
      "            val_ls_distance = get_val_metrics(val_dist_dataset)\n",
      "\n",
      "            # log with validation\n",
      "\n",
      "            log(step, t_start_batch, val_ls_distance)\n",
      "\n",
      "        else:\n",
      "\n",
      "            # normal log\n",
      "\n",
      "            log(step, t_start_batch)\n",
      "\n",
      "            # reset start time batch\n",
      "\n",
      "            t_start_batch = time.time()\n",
      "\n",
      "            \n",
      "\n",
      "        total_loss += train_loss.result()\n",
      "\n",
      "        \n",
      "\n",
      "        # learning rate step\n",
      "\n",
      "        LRREDUCE.step(epoch * TRAIN_STEPS + step * VERBOSE_FREQ - 1)\n",
      "\n",
      "        \n",
      "\n",
      "        # stop training when NaN loss is detected, this can be caused by exploding gradients\n",
      "\n",
      "        if np.isnan(total_loss):\n",
      "\n",
      "            break\n",
      "\n",
      "            \n",
      "\n",
      "    # stop training when NaN loss is detected\n",
      "\n",
      "    if np.isnan(total_loss):\n",
      "\n",
      "        break\n",
      "\n",
      "\n",
      "\n",
      "    print(f'Epoch {epoch} Loss {round(total_loss.numpy() / TRAIN_STEPS, 3)}, time: {int(time.time() - t_start)} sec\\n')\n",
      "\n",
      "#################################################\n",
      "\n",
      "#Setup the methods for the FeatureExtractorModel\n",
      "\n",
      "unet_model = UNetModel(1).to(DEVICE)\n",
      "\n",
      "unet_optim = torch.optim.Adam(unet_model.parameters(), lr=1e-4, weight_decay=1e-6, amsgrad=False)\n",
      "\n",
      "unet_sched = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
      "\n",
      "    unet_optim, T_max=len(train_loader),\n",
      "\n",
      "    eta_min=1e-10, last_epoch=-1\n",
      "\n",
      ")\n",
      "\n",
      "unet_loss_fn = torch.nn.BCELoss()\n",
      "\n",
      "dice_acc_fn = DiceCoef()\n",
      "\n",
      "\n",
      "\n",
      "#Load pretrained model from previous version of this notebook\n",
      "\n",
      "#unet_model.load_state_dict(torch.load(\"../input/pytorch-unet-from-scratch/unet_model.pth\",\n",
      "\n",
      "#                                      map_location=DEVICE))\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "EPOCHS = 256\n",
      "\n",
      "no_improvement_limit = 32\n",
      "\n",
      "no_impr_count = 0\n",
      "\n",
      "best_acc = -np.inf\n",
      "\n",
      "best_loss = np.inf\n",
      "\n",
      "\n",
      "\n",
      "lr_list = []\n",
      "\n",
      "for epoch in range(EPOCHS):\n",
      "\n",
      "    print(f\"Epoch [{epoch+1}/{EPOCHS}]:\")\n",
      "\n",
      "\n",
      "\n",
      "    if time.time() - start_time > time_limit:\n",
      "\n",
      "        print(\"Time Limit Exceeded! Ending Train Loop...\")\n",
      "\n",
      "        break #Avoid TimeLimitExceeded Error\n",
      "\n",
      "    \n",
      "\n",
      "    #Prime the models for training\n",
      "\n",
      "    unet_model.train()\n",
      "\n",
      "    #Reset the train losses\n",
      "\n",
      "    unet_train_loss = 0\n",
      "\n",
      "    train_dice_acc = 0\n",
      "\n",
      "    for images, organs, labels in tqdm(train_loader, desc='training'):\n",
      "\n",
      "        #Convert inputs to device (cpu or cuda)\n",
      "\n",
      "        images = images.to(DEVICE)\n",
      "\n",
      "        organs = organs.to(DEVICE)\n",
      "\n",
      "        labels = labels.to(DEVICE)\n",
      "\n",
      "        #Reset optimizer\n",
      "\n",
      "        unet_optim.zero_grad()\n",
      "\n",
      "        \n",
      "\n",
      "        preds = unet_model(images, organs)\n",
      "\n",
      "        unet_loss = unet_loss_fn(preds, labels)\n",
      "\n",
      "        unet_train_loss += unet_loss.item()\n",
      "\n",
      "        \n",
      "\n",
      "        #update loss and perform backpropagation on fe_model\n",
      "\n",
      "        unet_loss.backward()\n",
      "\n",
      "        unet_optim.step()\n",
      "\n",
      "        \n",
      "\n",
      "        with torch.no_grad():\n",
      "\n",
      "            dice_acc = dice_acc_fn(labels, preds.detach())\n",
      "\n",
      "            train_dice_acc = dice_acc.item()\n",
      "\n",
      "            \n",
      "\n",
      "    unet_sched.step()\n",
      "\n",
      "    \n",
      "\n",
      "    unet_train_loss /= len(train_loader)\n",
      "\n",
      "    train_dice_acc /= len(train_loader)\n",
      "\n",
      "    \n",
      "\n",
      "    unet_valid_loss = 0\n",
      "\n",
      "    valid_dice_acc = 0\n",
      "\n",
      "    #Next, we check for the validity of the model after some epochs\n",
      "\n",
      "    unet_model.eval()\n",
      "\n",
      "    for images, organs, labels in tqdm(valid_loader, desc='validating'):\n",
      "\n",
      "        #Convert inputs to device (cpu or cuda)\n",
      "\n",
      "        images = images.to(DEVICE)\n",
      "\n",
      "        organs = organs.to(DEVICE)\n",
      "\n",
      "        labels = labels.to(DEVICE)\n",
      "\n",
      "        \n",
      "\n",
      "        with torch.no_grad():\n",
      "\n",
      "            preds = unet_model(images, organs)\n",
      "\n",
      "            unet_val = unet_loss_fn(preds, labels)\n",
      "\n",
      "            unet_valid_loss += unet_val.item()\n",
      "\n",
      "            valid_dice_acc += dice_acc_fn(labels, preds.detach()).item()\n",
      "\n",
      "        #break\n",
      "\n",
      "    unet_valid_loss /= len(valid_loader)\n",
      "\n",
      "    valid_dice_acc /= len(valid_loader)\n",
      "\n",
      "    \n",
      "\n",
      "    print(f\"Epoch {epoch+1}/{EPOCHS}: \" +\n",
      "\n",
      "          f\"BCE_train_loss: {unet_train_loss:.4f} \" +\n",
      "\n",
      "          f\"BCE_valid_loss: {unet_valid_loss:.4f} \" +\n",
      "\n",
      "          f\"train_dice_acc: {train_dice_acc:.4f} \" +\n",
      "\n",
      "          f\"valid_dice_acc: {valid_dice_acc:.4f} \"\n",
      "\n",
      "         )\n",
      "\n",
      "        \n",
      "\n",
      "    #Finally, we'll compare the loss/acc with the saved total loss/acc\n",
      "\n",
      "    # and save the model on improvements\n",
      "\n",
      "    if valid_dice_acc >= best_acc or unet_valid_loss <= best_loss:\n",
      "\n",
      "        #Check the mask while training if loss improves\n",
      "\n",
      "        test_img = images.cpu().detach()[0]\n",
      "\n",
      "        test_lab = labels.cpu().detach()[0]\n",
      "\n",
      "        test_pred = preds.cpu().detach()[0]\n",
      "\n",
      "        show_masked_img(test_img, test_lab, f\"Original Epoch {epoch}\")\n",
      "\n",
      "        show_masked_img(test_img, test_pred, f\"Predicted Epoch {epoch}\")\n",
      "\n",
      "        \n",
      "\n",
      "        no_impr_count = 0\n",
      "\n",
      "        best_acc = max(valid_dice_acc, best_acc)\n",
      "\n",
      "        best_loss = min(unet_valid_loss, best_loss)\n",
      "\n",
      "        #if epoch != 0: #To avoid overwriting the notebook with baseline weights' score\n",
      "\n",
      "        torch.save(unet_model.state_dict(), \"unet_model.pth\")\n",
      "\n",
      "        print(\"Saved...\")\n",
      "\n",
      "        \n",
      "\n",
      "    else:\n",
      "\n",
      "        no_impr_count += 1\n",
      "\n",
      "        print(\"Loss did not improve...\")\n",
      "\n",
      "        #Uncomment to stop train upon reaching no_improvement_limit\n",
      "\n",
      "        if no_impr_count >= no_improvement_limit:\n",
      "\n",
      "            print(\"Early stopping!\")\n",
      "\n",
      "            break\n",
      "\n",
      "#################################################\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "\n",
      "    if not is_inference:\n",
      "\n",
      "        df_oof = train_loop(df_folds=df_folds, is_plot=False)\n",
      "\n",
      "        oof_cv = calc_oof(df_oof[\"oof_trues\"].values, df_oof[\"0_oof\"].values)\n",
      "\n",
      "        config.logger.info(f\"OOF RMSE: {oof_cv}\")\n",
      "\n",
      "        torch.cuda.empty_cache()\n",
      "\n",
      "    else:\n",
      "\n",
      "        model_dir = r\"C:\\Users\\reighns\\kaggle_projects\\cassava\\model\\tf_efficientnet_b0_ns\"\n",
      "\n",
      "        predictions = inference(df_test, model_dir, df_sub)\n",
      "\n",
      "        # _ = inference.show_gradcam()\n",
      "\n",
      "#################################################\n",
      "\n",
      "history=model.fit(train_ds,\n",
      "\n",
      "                  epochs=EPOCHS,\n",
      "\n",
      "                  steps_per_epoch=STEPS_PER_EPOCH,\n",
      "\n",
      "                  verbose=1,\n",
      "\n",
      "                  validation_data=eval_ds,\n",
      "\n",
      "                  validation_steps=EVAL_STEPS, \n",
      "\n",
      "                  callbacks=callbacks)\n",
      "\n",
      "#################################################\n",
      "\n",
      "if __name__ == '__main__':\n",
      "\n",
      "    \n",
      "\n",
      "    def get_result(oof_df):\n",
      "\n",
      "        labels = oof_df['discourse_effectiveness'].values\n",
      "\n",
      "        preds = oof_df[['pred_0','pred_1','pred_2']].values\n",
      "\n",
      "        score = get_score(labels, preds)\n",
      "\n",
      "        LOGGER.info(f'Score: {score:<.4f}')\n",
      "\n",
      "    \n",
      "\n",
      "    oof_df = pd.DataFrame()\n",
      "\n",
      "    for fold in range(CFG.n_fold):\n",
      "\n",
      "        if fold in CFG.trn_fold:\n",
      "\n",
      "            _oof_df = train_loop(train, fold)\n",
      "\n",
      "            oof_df = pd.concat([oof_df, _oof_df])\n",
      "\n",
      "            LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
      "\n",
      "            get_result(_oof_df)\n",
      "\n",
      "    oof_df = oof_df.reset_index(drop=True)\n",
      "\n",
      "    LOGGER.info(f\"========== CV ==========\")\n",
      "\n",
      "    get_result(oof_df)\n",
      "\n",
      "    oof_df.to_pickle(OUTPUT_DIR+'oof_df.pkl')\n",
      "\n",
      "        \n",
      "\n",
      "    if CFG.wandb:\n",
      "\n",
      "        wandb.finish()\n",
      "\n",
      "#################################################\n",
      "\n",
      "# Training settings\n",
      "\n",
      "# batch_size = 32\n",
      "\n",
      "# epochs = 50\n",
      "\n",
      "# lr = 3e-4\n",
      "\n",
      "# gamma = 0.7\n",
      "\n",
      "# seed = 42\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "from sklearn.metrics import f1_score\n",
      "\n",
      "from sklearn.metrics import recall_score\n",
      "\n",
      "from sklearn.metrics import accuracy_score\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "# loss function\n",
      "\n",
      "criterion = nn.CrossEntropyLoss()\n",
      "\n",
      "# optimizer\n",
      "\n",
      "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
      "\n",
      "# scheduler\n",
      "\n",
      "scheduler = StepLR(optimizer, step_size=1, gamma=gamma)\n",
      "\n",
      "#scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min',factor=gamma,verbose=True,min_lr=3e-10,patience=2)\n",
      "\n",
      "\n",
      "\n",
      "model.train()\n",
      "\n",
      "for epoch in range(epochs):\n",
      "\n",
      "    epoch_loss = 0\n",
      "\n",
      "    epoch_accuracy = 0\n",
      "\n",
      "\n",
      "\n",
      "    #for data, label in tqdm(train_loader):\n",
      "\n",
      "    for data, label in tqdm(train_data_loader):\n",
      "\n",
      "        data = data.to(device)\n",
      "\n",
      "        label = label.to(device)\n",
      "\n",
      "\n",
      "\n",
      "        output = model(data)\n",
      "\n",
      "        loss = criterion(output, label)\n",
      "\n",
      "\n",
      "\n",
      "        optimizer.zero_grad()\n",
      "\n",
      "        loss.backward()\n",
      "\n",
      "        optimizer.step()\n",
      "\n",
      "\n",
      "\n",
      "        acc = (output.argmax(dim=1) == label).float().mean()\n",
      "\n",
      "        epoch_accuracy += acc / len(train_data_loader)\n",
      "\n",
      "        epoch_loss += loss / len(train_data_loader)\n",
      "\n",
      "        \n",
      "\n",
      "    with torch.no_grad():\n",
      "\n",
      "        epoch_val_accuracy = 0\n",
      "\n",
      "        epoch_val_loss = 0\n",
      "\n",
      "        for data, label in val_data_loader:\n",
      "\n",
      "            data = data.to(device)\n",
      "\n",
      "            label = label.to(device)\n",
      "\n",
      "\n",
      "\n",
      "            val_output = model(data)\n",
      "\n",
      "            val_loss = criterion(val_output, label)\n",
      "\n",
      "\n",
      "\n",
      "            acc = (val_output.argmax(dim=1) == label).float().mean()\n",
      "\n",
      "            epoch_val_accuracy += acc / len(val_data_loader)\n",
      "\n",
      "            epoch_val_loss += val_loss / len(val_data_loader)\n",
      "\n",
      "            \n",
      "\n",
      "    \n",
      "\n",
      "    print(\n",
      "\n",
      "        f\"Epoch : {epoch+1} - loss : {epoch_loss:.4f} - acc: {epoch_accuracy:.4f} - val_loss : {epoch_val_loss:.4f} - val_acc: {epoch_val_accuracy:.4f}\\n\"\n",
      "\n",
      "    )\n",
      "\n",
      "\n",
      "\n",
      "    torch.save(model, './model_Swinlarge32.pt')  # 直接保存模型\n",
      "\n",
      "#################################################\n",
      "\n",
      "import gc\n",
      "\n",
      "\n",
      "\n",
      "for name in tqdm(df_train[\"image_id\"]):\n",
      "\n",
      "    img_path = os.path.join(DATASET_FOLDER, \"train\", f\"{name}.tif\")\n",
      "\n",
      "    img = image_load_scale_norm(img_path)\n",
      "\n",
      "    if not img:\n",
      "\n",
      "        continue\n",
      "\n",
      "    img.save(os.path.join(\"train_images\", f\"{name}.png\"))\n",
      "\n",
      "    del img\n",
      "\n",
      "    gc.collect()\n",
      "\n",
      "#################################################\n",
      "\n",
      "cfg.device = 'cuda'\n",
      "\n",
      "train_detector(model, datasets[0], cfg, distributed=False, validate=True)\n",
      "\n",
      "#################################################\n",
      "\n",
      "kfolds = 5\n",
      "\n",
      "createtransformer=True\n",
      "\n",
      "\n",
      "\n",
      "fold = create_folds(1, kfolds)\n",
      "\n",
      "res = train_labels.copy()\n",
      "\n",
      "res.loc[:, train_labels.columns] = 0\n",
      "\n",
      "\n",
      "\n",
      "for i in range(kfolds):\n",
      "\n",
      "    \n",
      "\n",
      "    train_index, val_index = np.where(fold!=i)[1], np.where(fold==i)[1]\n",
      "\n",
      "\n",
      "\n",
      "    train_all_features = train_features.loc[train_index, all_features].copy().reset_index(drop=True).values\n",
      "\n",
      "    t_labels = train_labels.iloc[train_index].copy().reset_index(drop=True).values\n",
      "\n",
      "    valid_all_features = train_features.loc[val_index, all_features].copy().reset_index(drop=True).values\n",
      "\n",
      "    v_labels = train_labels.iloc[val_index].copy().reset_index(drop=True).values\n",
      "\n",
      "    test_all_features = train_features[all_features].copy().reset_index(drop=True).values\n",
      "\n",
      "    print(train_all_features.shape, t_labels.shape, valid_all_features.shape, v_labels.shape, test_all_features.shape)\n",
      "\n",
      "\n",
      "\n",
      "    T_max = math.floor(len(t_labels)/batch_size)\n",
      "\n",
      "\n",
      "\n",
      "    if createtransformer:\n",
      "\n",
      "        all_scaler = LogScaler()\n",
      "\n",
      "        train_all_features = all_scaler.fit_transform(train_all_features)\n",
      "\n",
      "        valid_all_features = all_scaler.transform(valid_all_features)\n",
      "\n",
      "        test_all_features = all_scaler.transform(test_all_features)\n",
      "\n",
      "        save_pickle(all_scaler, model_output_folder, i, \"log-scaler\")\n",
      "\n",
      "\n",
      "\n",
      "        transformer= DeepInsightTransformer(pixels=resolution,\n",
      "\n",
      "                                        perplexity=perplexity)\n",
      "\n",
      "        transformer=transformer.fit(train_all_features)\n",
      "\n",
      "        save_pickle(transformer, model_output_folder, i, \"deepinsight-transform\")\n",
      "\n",
      "    else: \n",
      "\n",
      "        scaler = load_pickle(model_info['model_path'], i, \"log-scaler\")\n",
      "\n",
      "        train_all_features = scaler.transform(train_all_features)\n",
      "\n",
      "        valid_all_features = scaler.transform(valid_all_features)\n",
      "\n",
      "        transformer = load_pickle(model_info['model_path'], i, \"deepinsight-transform\")\n",
      "\n",
      "    model = get_train_model(training_set=(train_all_features, t_labels), valid_set=(valid_all_features, v_labels), test_set=valid_all_features, transformer=transformer)\n",
      "\n",
      "    callbacks = [\n",
      "\n",
      "        pl.callbacks.EarlyStopping(monitor='val_loss_epoch',\n",
      "\n",
      "                    min_delta=1e-6,\n",
      "\n",
      "                    patience=patience,\n",
      "\n",
      "                    verbose=True,\n",
      "\n",
      "                    mode='min',\n",
      "\n",
      "                    strict=True),\n",
      "\n",
      "        pl.callbacks.LearningRateMonitor(logging_interval='step')\n",
      "\n",
      "    ]\n",
      "\n",
      "\n",
      "\n",
      "    checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
      "\n",
      "        filepath=f\"{model_output_folder}/fold{i}\" +\n",
      "\n",
      "        \"/{epoch}-{train_loss_epoch:.6f}-{val_loss_epoch:.6f}\" +\n",
      "\n",
      "        f\"-image_size={image_size}-resolution={resolution}-perplexity={perplexity}-fc={fc_size}\",\n",
      "\n",
      "        save_top_k=1,\n",
      "\n",
      "        save_weights_only=False,\n",
      "\n",
      "        save_last=False,\n",
      "\n",
      "        verbose=True,\n",
      "\n",
      "        monitor='val_loss_epoch',\n",
      "\n",
      "        mode='min',\n",
      "\n",
      "        prefix='')\n",
      "\n",
      "\n",
      "\n",
      "    trainer = pl.Trainer(\n",
      "\n",
      "        gpus=gpus,\n",
      "\n",
      "        distributed_backend=\"dp\",  # multiple-gpus, 1 machine\n",
      "\n",
      "        max_epochs=epochs,\n",
      "\n",
      "        benchmark=False,\n",
      "\n",
      "        deterministic=True,\n",
      "\n",
      "        checkpoint_callback=checkpoint_callback,\n",
      "\n",
      "        callbacks=callbacks,\n",
      "\n",
      "        #accumulate_grad_batches=accumulate_grad_batches,\n",
      "\n",
      "        #gradient_clip_val=gradient_clip_val,\n",
      "\n",
      "        precision=16,\n",
      "\n",
      "        #logger=logger\n",
      "\n",
      "        )\n",
      "\n",
      "    trainer.fit(model)\n",
      "\n",
      "\n",
      "\n",
      "    output = trainer.test(model, verbose=False)[0]\n",
      "\n",
      "    res.iloc[val_index] += output[\"pred_probs\"]\n",
      "\n",
      "\n",
      "\n",
      "res.to_csv('res.csv', index=False)\n",
      "\n",
      "\n",
      "\n",
      "res.loc[train_features['cp_type'] == 0, train_labels.columns] = 0\n",
      "\n",
      "\n",
      "\n",
      "metrics = []\n",
      "\n",
      "for _target in train_labels.columns:\n",
      "\n",
      "    metrics.append(log_loss(train_labels.loc[:, _target], res.loc[:, _target]))\n",
      "\n",
      "print(f'OOF Metric with postprocessing: {np.mean(metrics)}')\n",
      "\n",
      "#################################################\n",
      "\n",
      "oof_pred = automl.fit_predict(train_data, roles = roles, verbose=3)\n",
      "\n",
      "print(f'oof_pred:\\n{oof_pred}\\nShape = {oof_pred.shape}')\n",
      "\n",
      "#################################################\n",
      "\n",
      "if __name__ == '__main__':\n",
      "\n",
      "    \n",
      "\n",
      "    def get_result(oof_df):\n",
      "\n",
      "        labels = oof_df['discourse_effectiveness'].values\n",
      "\n",
      "        preds = oof_df[['pred_0','pred_1','pred_2']].values\n",
      "\n",
      "        score = get_score(labels, preds)\n",
      "\n",
      "        LOGGER.info(f'Score: {score:<.4f}')\n",
      "\n",
      "    \n",
      "\n",
      "    oof_df = pd.DataFrame()\n",
      "\n",
      "    for fold in range(CFG.n_fold):\n",
      "\n",
      "        if fold in CFG.trn_fold:\n",
      "\n",
      "            _oof_df = train_loop(train, fold)\n",
      "\n",
      "            oof_df = pd.concat([oof_df, _oof_df])\n",
      "\n",
      "            LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
      "\n",
      "            get_result(_oof_df)\n",
      "\n",
      "    oof_df = oof_df.reset_index(drop=True)\n",
      "\n",
      "    LOGGER.info(f\"========== CV ==========\")\n",
      "\n",
      "    get_result(oof_df)\n",
      "\n",
      "    oof_df.to_pickle(OUTPUT_DIR+'oof_df.pkl')\n",
      "\n",
      "        \n",
      "\n",
      "    if CFG.wandb:\n",
      "\n",
      "        wandb.finish()\n",
      "\n",
      "#################################################\n",
      "\n",
      "# +!CUDA_LAUNCH_BLOCKING=1.\n",
      "\n",
      "report_df = fine_tuning(config)\n",
      "\n",
      "#################################################\n",
      "\n",
      "fold =0\n",
      "\n",
      "train(fold)\n",
      "\n",
      "#################################################\n",
      "\n",
      "if __name__ == '__main__':\n",
      "\n",
      "    \n",
      "\n",
      "    def get_result(oof_df):\n",
      "\n",
      "        labels = oof_df['discourse_effectiveness'].values\n",
      "\n",
      "        preds = oof_df[['pred_0','pred_1','pred_2']].values\n",
      "\n",
      "        score = get_score(labels, preds)\n",
      "\n",
      "        LOGGER.info(f'Score: {score:<.4f}')\n",
      "\n",
      "    \n",
      "\n",
      "    oof_df = pd.DataFrame()\n",
      "\n",
      "    for fold in range(CFG.n_fold):\n",
      "\n",
      "        if fold in CFG.trn_fold:\n",
      "\n",
      "            _oof_df = train_loop(train, fold)\n",
      "\n",
      "            oof_df = pd.concat([oof_df, _oof_df])\n",
      "\n",
      "            LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
      "\n",
      "            get_result(_oof_df)\n",
      "\n",
      "    oof_df = oof_df.reset_index(drop=True)\n",
      "\n",
      "    LOGGER.info(f\"========== CV ==========\")\n",
      "\n",
      "    get_result(oof_df)\n",
      "\n",
      "    oof_df.to_pickle(OUTPUT_DIR+'oof_df.pkl')\n",
      "\n",
      "        \n",
      "\n",
      "    if CFG.wandb:\n",
      "\n",
      "        wandb.finish()\n",
      "\n",
      "#################################################\n",
      "\n",
      "dataset=\"reut90\"\n",
      "\n",
      "for fold in range(7, 10):\n",
      "\n",
      "    model_path = f\"../input/dont-stop-pretraining/models/{dataset}/fold{fold}\"\n",
      "\n",
      "    represent_tecbench_data(dataset, model_path, fold=fold)\n",
      "\n",
      "#################################################\n",
      "\n",
      "# fixed latent code for image generation over training period\n",
      "\n",
      "torch.manual_seed(1234)\n",
      "\n",
      "fixed_noise = torch.fmod(torch.randn((64, latent_dim), device=device), 2)\n",
      "\n",
      "\n",
      "\n",
      "chkpt_intv = 10  # save a checkpoint every 5 epochs\n",
      "\n",
      "output_dir = \"/kaggle/working\"\n",
      "\n",
      "chkpt_path = os.path.join(output_dir, \"anime-sngan.pt\")\n",
      "\n",
      "\n",
      "\n",
      "if torch.backends.cudnn.is_available():\n",
      "\n",
      "    torch.backends.cudnn.benchmark = True\n",
      "\n",
      "\n",
      "\n",
      "# total epochs to train\n",
      "\n",
      "n_epochs = 50\n",
      "\n",
      "for e in range(n_epochs):\n",
      "\n",
      "    total_dis_loss = 0\n",
      "\n",
      "    total_gen_loss = 0\n",
      "\n",
      "    total_dis_cnt = 0\n",
      "\n",
      "    total_gen_cnt = 0\n",
      "\n",
      "    with tqdm(trainloader, desc=f\"{e+1}/{n_epochs} epochs\", ncols=100) as t:\n",
      "\n",
      "        netG.train()\n",
      "\n",
      "        gen_loss = 0\n",
      "\n",
      "        for i, x_real in enumerate(t):\n",
      "\n",
      "            cnt, dis_loss, gen_loss_ = train_step(i, x_real)\n",
      "\n",
      "            gen_loss = gen_loss_ or gen_loss\n",
      "\n",
      "            # keep track of running statistics\n",
      "\n",
      "            total_dis_loss += dis_loss * cnt \n",
      "\n",
      "            total_dis_cnt += cnt\n",
      "\n",
      "            total_gen_loss += gen_loss * cnt * g_batches\n",
      "\n",
      "            total_gen_cnt += cnt * g_batches\n",
      "\n",
      "\n",
      "\n",
      "            t.set_postfix({\n",
      "\n",
      "                \"dis_loss\": total_dis_loss / total_dis_cnt,\n",
      "\n",
      "                \"gen_loss\": total_gen_loss / total_gen_cnt\n",
      "\n",
      "            })\n",
      "\n",
      "            if i == len(trainloader) - 1:\n",
      "\n",
      "                netG.eval()\n",
      "\n",
      "                with torch.no_grad():\n",
      "\n",
      "                    ema.apply(netG)\n",
      "\n",
      "                    x = netG.sample(64, fixed_noise).cpu()\n",
      "\n",
      "                    ema.restore(netG)\n",
      "\n",
      "                img = make_grid(\n",
      "\n",
      "                    x, nrow=8, normalize=True, value_range=(-1, 1)\n",
      "\n",
      "                ).numpy().transpose(1, 2, 0)\n",
      "\n",
      "                plt.imsave(os.path.join(output_dir, f\"{e+1}.jpg\"), img)\n",
      "\n",
      "                if (e+1) % chkpt_intv == 0:\n",
      "\n",
      "                    torch.save(\n",
      "\n",
      "                        {\n",
      "\n",
      "                            \"netD\": netD.state_dict(),\n",
      "\n",
      "                            \"netG\": netG.state_dict(),\n",
      "\n",
      "                            \"optD\": optD.state_dict(),\n",
      "\n",
      "                            \"optG\": optG.state_dict(),\n",
      "\n",
      "                            \"ema\": ema.__dict__,\n",
      "\n",
      "                            \"epoch\": e+1\n",
      "\n",
      "                        }, chkpt_path)\n",
      "\n",
      "#################################################\n",
      "\n",
      "trainer.train()\n",
      "\n",
      "#################################################\n",
      "\n",
      "%%time \n",
      "\n",
      "\n",
      "\n",
      "class args:\n",
      "\n",
      "    epochs = 10\n",
      "\n",
      "    lr = 1e-3\n",
      "\n",
      "    batch_size = 8\n",
      "\n",
      "    num_workers = 2\n",
      "\n",
      "    embed_size = 4096\n",
      "\n",
      "    val_samples = 1\n",
      "\n",
      "    backbone_name=\"resnest101e\"\n",
      "\n",
      "    n_classes = data_df[\"hotel_id_code\"].nunique()\n",
      "\n",
      "    device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
      "\n",
      "    continue_from_checkpoint = False\n",
      "\n",
      "\n",
      "\n",
      "train_and_validate(args, data_df)\n",
      "\n",
      "#################################################\n",
      "\n",
      "# Training settings\n",
      "\n",
      "# batch_size = 32\n",
      "\n",
      "epochs = 50\n",
      "\n",
      "# lr = 3e-4\n",
      "\n",
      "# gamma = 0.7\n",
      "\n",
      "# seed = 42\n",
      "\n",
      "#lr = 0.000005403\n",
      "\n",
      "lr=0.0000022288\n",
      "\n",
      "\n",
      "\n",
      "from sklearn.metrics import f1_score\n",
      "\n",
      "from sklearn.metrics import recall_score\n",
      "\n",
      "from sklearn.metrics import accuracy_score\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "# loss function\n",
      "\n",
      "criterion = nn.CrossEntropyLoss()\n",
      "\n",
      "# optimizer\n",
      "\n",
      "optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=0.01)\n",
      "\n",
      "\n",
      "\n",
      "#optimizer =  optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
      "\n",
      "# scheduler\n",
      "\n",
      "#scheduler = StepLR(optimizer, step_size=1, gamma=gamma)\n",
      "\n",
      "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=30, eta_min=0, last_epoch=- 1, verbose=True)\n",
      "\n",
      "#scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min',factor=0.9,verbose=True,min_lr=3e-10,patience=1)\n",
      "\n",
      "scheduler1 = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
      "\n",
      "scheduler2 = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[10,15,20,25,28], gamma=0.5)\n",
      "\n",
      "\n",
      "\n",
      "weight_name1= './model_ViTlarge32_'\n",
      "\n",
      "weight_name2= '.pt'\n",
      "\n",
      "\n",
      "\n",
      "model.train()\n",
      "\n",
      "for epoch in range(epochs):\n",
      "\n",
      "    epoch_loss = 0\n",
      "\n",
      "    epoch_accuracy = 0\n",
      "\n",
      "    learn_rate = 0\n",
      "\n",
      "    \n",
      "\n",
      "    weight_name= weight_name1 + str(epoch) + weight_name2\n",
      "\n",
      "\n",
      "\n",
      "    #for data, label in tqdm(train_loader):\n",
      "\n",
      "    for data, label in tqdm(train_data_loader):\n",
      "\n",
      "        data = data.to(device)\n",
      "\n",
      "        label = label.to(device)\n",
      "\n",
      "\n",
      "\n",
      "        output = model(data)\n",
      "\n",
      "        loss = criterion(output, label)\n",
      "\n",
      "\n",
      "\n",
      "        optimizer.zero_grad()\n",
      "\n",
      "        loss.backward()\n",
      "\n",
      "        optimizer.step()\n",
      "\n",
      "\n",
      "\n",
      "        acc = (output.argmax(dim=1) == label).float().mean()\n",
      "\n",
      "        epoch_accuracy += acc / len(train_data_loader)\n",
      "\n",
      "        epoch_loss += loss / len(train_data_loader)\n",
      "\n",
      "        \n",
      "\n",
      "        learn_rate = optimizer.state_dict()['param_groups'][0]['lr']\n",
      "\n",
      "        \n",
      "\n",
      "    scheduler.step()\n",
      "\n",
      "#     scheduler1.step()\n",
      "\n",
      "#     scheduler2.step()\n",
      "\n",
      "        \n",
      "\n",
      "    with torch.no_grad():\n",
      "\n",
      "        epoch_val_accuracy = 0\n",
      "\n",
      "        epoch_val_loss = 0\n",
      "\n",
      "        epoch_best_accuracy = 0\n",
      "\n",
      "        \n",
      "\n",
      "        for data, label in val_data_loader:\n",
      "\n",
      "            data = data.to(device)\n",
      "\n",
      "            label = label.to(device)\n",
      "\n",
      "\n",
      "\n",
      "            val_output = model(data)\n",
      "\n",
      "            val_loss = criterion(val_output, label)\n",
      "\n",
      "\n",
      "\n",
      "            acc = (val_output.argmax(dim=1) == label).float().mean()\n",
      "\n",
      "            epoch_val_accuracy += acc / len(val_data_loader)\n",
      "\n",
      "            epoch_val_loss += val_loss / len(val_data_loader)\n",
      "\n",
      "\n",
      "\n",
      "        if(epoch_val_accuracy>0.958):\n",
      "\n",
      "            epoch_best_accuracy=epoch_val_accuracy\n",
      "\n",
      "            torch.save(model, weight_name)  # 直接保存模型\n",
      "\n",
      "    \n",
      "\n",
      "    if(epoch_val_accuracy>0.93):\n",
      "\n",
      "        scheduler1.step()\n",
      "\n",
      "    if(epoch_val_accuracy>0.94):\n",
      "\n",
      "        scheduler2.step()\n",
      "\n",
      "        \n",
      "\n",
      "    print(\n",
      "\n",
      "        f\"Epoch : {epoch+1} - loss : {epoch_loss:.4f} - acc: {epoch_accuracy:.4f} - learn_rate : {learn_rate:.10f} - val_loss : {epoch_val_loss:.4f} - val_acc: {epoch_val_accuracy:.4f}\\n\"\n",
      "\n",
      "    )\n",
      "\n",
      "    if(epoch_val_accuracy>0.96):\n",
      "\n",
      "        torch.save(model, weight_name)  # 直接保存模型\n",
      "\n",
      "#################################################\n",
      "\n",
      "%%time \n",
      "\n",
      "\n",
      "\n",
      "class args:\n",
      "\n",
      "    epochs = 10\n",
      "\n",
      "    lr = 1e-3\n",
      "\n",
      "    batch_size = 16\n",
      "\n",
      "    num_workers = 2\n",
      "\n",
      "    embed_size = 2048\n",
      "\n",
      "    val_samples = 1\n",
      "\n",
      "    backbone_name=\"regnety_120\"\n",
      "\n",
      "    n_classes = data_df[\"hotel_id_code\"].nunique()\n",
      "\n",
      "    device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
      "\n",
      "    continue_from_checkpoint = False\n",
      "\n",
      "\n",
      "\n",
      "train_and_validate(args, data_df)\n",
      "\n",
      "#################################################\n",
      "\n",
      "!python train.py\n",
      "\n",
      "#################################################\n",
      "\n",
      "model_name = \"tf_efficientnet_b5\"\n",
      "\n",
      "image_size = 512\n",
      "\n",
      "batch_size = 16\n",
      "\n",
      "\n",
      "\n",
      "train(model_name=model_name,\n",
      "\n",
      "      image_size=image_size,\n",
      "\n",
      "      batch_size=batch_size)\n",
      "\n",
      "#################################################\n",
      "\n",
      "from mlxtend.classifier import StackingCVClassifier,EnsembleVoteClassifier\n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "\n",
      "\n",
      "\n",
      "cl1 = CatBoostClassifier(**cat_params)\n",
      "\n",
      "cl2 = LGBMClassifier(**lgbm_params)\n",
      "\n",
      "cl3 = ExtraTreesClassifier(**ETC_params)\n",
      "\n",
      "\n",
      "\n",
      "mlr = LogisticRegression()\n",
      "\n",
      "\n",
      "\n",
      "ann_clf = KerasClassifier(lambda: ann_network(), epochs=4)\n",
      "\n",
      "\n",
      "\n",
      "# ANN Ensembling\n",
      "\n",
      "clf = StackingCVClassifier(classifiers= [cl1,cl2,cl3], \n",
      "\n",
      "                            meta_classifier = ann_clf, \n",
      "\n",
      "                            use_probas = True, \n",
      "\n",
      "                            random_state = SEED) \n",
      "\n",
      "\n",
      "\n",
      "# Hard Voting Ensemble\n",
      "\n",
      "S_eclf = EnsembleVoteClassifier(clfs=[cl1, cl2, cl3],\n",
      "\n",
      "                              weights=[1, 1, 2], voting='soft')\n",
      "\n",
      "\n",
      "\n",
      "#Soft Voting Ensemble\n",
      "\n",
      "H_eclf = EnsembleVoteClassifier(clfs=[cl1, cl2, cl3],\n",
      "\n",
      "                              weights=[1, 1, 3], voting='hard')\n",
      "\n",
      "\n",
      "\n",
      "#PseudoMeta classifier\n",
      "\n",
      "AnnStakced_clf =  StackingCVClassifier(classifiers= [cl1,cl2,cl3],\n",
      "\n",
      "                            meta_classifier = S_eclf, \n",
      "\n",
      "                            use_probas = True,    \n",
      "\n",
      "                            random_state = SEED) \n",
      "\n",
      "\n",
      "\n",
      "classifiers = [clf,H_eclf,S_eclf,AnnStakced_clf]\n",
      "\n",
      "\n",
      "\n",
      "# Fit the classifier variations\n",
      "\n",
      "clf.fit(X_train, y_train) \n",
      "\n",
      "H_eclf.fit(X_train, y_train) \n",
      "\n",
      "S_eclf.fit(X_train, y_train)\n",
      "\n",
      "AnnStakced_clf.fit(X_train, y_train) \n",
      "\n",
      "#################################################\n",
      "\n",
      "for fold in range(0, CONFIG['n_fold']):\n",
      "\n",
      "    print(f\"{y_}====== Fold: {fold} ======{sr_}\")\n",
      "\n",
      "    #run = wandb.init(project='Jigsaw', \n",
      "\n",
      "                     #config=CONFIG,\n",
      "\n",
      "                     #job_type='Train',\n",
      "\n",
      "                     #group=CONFIG['group'],\n",
      "\n",
      "                     #tags=['RoBerta-Large-CT-STSb', f'{HASH_NAME}', 'margin-loss'],\n",
      "\n",
      "                     #name=f'{HASH_NAME}-fold-{fold}',\n",
      "\n",
      "                     #anonymous='must')\n",
      "\n",
      "    \n",
      "\n",
      "    # Create Dataloaders\n",
      "\n",
      "    train_loader, valid_loader = prepare_loaders(fold=fold)\n",
      "\n",
      "    \n",
      "\n",
      "    model = CT_Roberta(CONFIG['model_name'])\n",
      "\n",
      "    model.to(CONFIG['device'])\n",
      "\n",
      "    \n",
      "\n",
      "    # Define Optimizer and Scheduler\n",
      "\n",
      "    optimizer = AdamW(model.parameters(), lr=CONFIG['learning_rate'], weight_decay=CONFIG['weight_decay'])\n",
      "\n",
      "    scheduler = fetch_scheduler(optimizer)\n",
      "\n",
      "    \n",
      "\n",
      "    model, history = run_training(model, optimizer, scheduler,\n",
      "\n",
      "                                  device=CONFIG['device'],\n",
      "\n",
      "                                  num_epochs=CONFIG['epochs'],\n",
      "\n",
      "                                  fold=fold)\n",
      "\n",
      "    \n",
      "\n",
      "    #run.finish()\n",
      "\n",
      "    _ = gc.collect()\n",
      "\n",
      "    print()\n",
      "\n",
      "#################################################\n",
      "\n",
      "best_metric = -1\n",
      "\n",
      "best_metric_epoch = -1\n",
      "\n",
      "epoch_loss_values = list()\n",
      "\n",
      "auc_metric = ROCAUCMetric()\n",
      "\n",
      "metric_values = list()\n",
      "\n",
      "\n",
      "\n",
      "for epoch in range(epoch_num):\n",
      "\n",
      "    print('-' * 10)\n",
      "\n",
      "    print(f\"epoch {epoch + 1}/{epoch_num}\")\n",
      "\n",
      "    model.train()\n",
      "\n",
      "    epoch_loss = 0\n",
      "\n",
      "    step = 0\n",
      "\n",
      "\n",
      "\n",
      "    for batch_data in train_loader:\n",
      "\n",
      "        step += 1\n",
      "\n",
      "        inputs, labels = batch_data[0].to(device), batch_data[1].to(device)\n",
      "\n",
      "        optimizer.zero_grad()\n",
      "\n",
      "        outputs = model(inputs.float())     ##### \n",
      "\n",
      "        loss = loss_function(outputs, labels)\n",
      "\n",
      "        loss.backward()\n",
      "\n",
      "        optimizer.step()\n",
      "\n",
      "        epoch_loss += loss.item()\n",
      "\n",
      "        print(f\"{step}/{len(train_ds) // train_loader.batch_size}, train_loss: {loss.item():.4f}\")\n",
      "\n",
      "        epoch_len = len(train_ds) // train_loader.batch_size\n",
      "\n",
      "\n",
      "\n",
      "    epoch_loss /= step\n",
      "\n",
      "    epoch_loss_values.append(epoch_loss)\n",
      "\n",
      "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
      "\n",
      "\n",
      "\n",
      "    if (epoch + 1) % val_interval == 0:\n",
      "\n",
      "        model.eval()\n",
      "\n",
      "        with torch.no_grad():\n",
      "\n",
      "            y_pred = torch.tensor([], dtype=torch.float32, device=device)\n",
      "\n",
      "            y = torch.tensor([], dtype=torch.long, device=device)\n",
      "\n",
      "            for val_data in val_loader:\n",
      "\n",
      "                val_images, val_labels = val_data[0].to(device), val_data[1].to(device)\n",
      "\n",
      "                y_pred = torch.cat([y_pred, model(val_images.float())], dim=0)\n",
      "\n",
      "                y = torch.cat([y, val_labels], dim=0)\n",
      "\n",
      "                \n",
      "\n",
      "            y_onehot = [to_onehot(i) for i in y]\n",
      "\n",
      "            y_pred_act = [act(i) for i in y_pred]\n",
      "\n",
      "            auc_metric(y_pred_act, y_onehot)\n",
      "\n",
      "            auc_result = auc_metric.aggregate()\n",
      "\n",
      "            auc_metric.reset()\n",
      "\n",
      "            del y_pred_act, y_onehot\n",
      "\n",
      "            metric_values.append(auc_result)\n",
      "\n",
      "            acc_value = torch.eq(y_pred.argmax(dim=1), y)\n",
      "\n",
      "            acc_metric = acc_value.sum().item() / len(acc_value)\n",
      "\n",
      "            \n",
      "\n",
      "            if acc_metric > best_metric:\n",
      "\n",
      "                best_metric = acc_metric\n",
      "\n",
      "                best_metric_epoch = epoch + 1\n",
      "\n",
      "                torch.save(model.state_dict(), 'best_metric_model.pth')\n",
      "\n",
      "                print('saved new best metric model')\n",
      "\n",
      "                \n",
      "\n",
      "            print(f\"current epoch: {epoch + 1} current AUC: {auc_result:.4f}\"\n",
      "\n",
      "                  f\" current accuracy: {acc_metric:.4f} best AUC: {best_metric:.4f}\"\n",
      "\n",
      "                  f\" at epoch: {best_metric_epoch}\")\n",
      "\n",
      "            \n",
      "\n",
      "print(f\"train completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")\n",
      "\n",
      "\n",
      "#################################################\n",
      "\n",
      "%%time \n",
      "\n",
      "\n",
      "\n",
      "class args:\n",
      "\n",
      "    epochs = 10\n",
      "\n",
      "    lr = 1e-3\n",
      "\n",
      "    batch_size = 10\n",
      "\n",
      "    num_workers = 2\n",
      "\n",
      "    val_samples = 1\n",
      "\n",
      "    embedding_size = 128\n",
      "\n",
      "    backbone_name = \"efficientnet_b5\"\n",
      "\n",
      "    n_classes = data_df[\"hotel_id_code\"].nunique()\n",
      "\n",
      "    device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
      "\n",
      "\n",
      "\n",
      "train_and_validate(args, data_df)\n",
      "\n",
      "#################################################\n",
      "\n",
      "if __name__ == '__main__':\n",
      "\n",
      "    \n",
      "\n",
      "    def get_result(oof_df):\n",
      "\n",
      "        labels = oof_df['score'].values\n",
      "\n",
      "        preds = oof_df['pred'].values\n",
      "\n",
      "        score = get_score(labels, preds)\n",
      "\n",
      "        LOGGER.info(f'Score: {score:<.4f}')\n",
      "\n",
      "    \n",
      "\n",
      "    if CFG.train:\n",
      "\n",
      "        oof_df = pd.DataFrame()\n",
      "\n",
      "        for fold in range(CFG.n_fold):\n",
      "\n",
      "            if fold in CFG.trn_fold:\n",
      "\n",
      "                _oof_df = train_loop(train, fold)\n",
      "\n",
      "                oof_df = pd.concat([oof_df, _oof_df])\n",
      "\n",
      "                LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
      "\n",
      "                get_result(_oof_df)\n",
      "\n",
      "        oof_df = oof_df.reset_index(drop=True)\n",
      "\n",
      "        LOGGER.info(f\"========== CV ==========\")\n",
      "\n",
      "        get_result(oof_df)\n",
      "\n",
      "        oof_df.to_pickle(OUTPUT_DIR+'oof_df.pkl')\n",
      "\n",
      "        \n",
      "\n",
      "    if CFG.wandb:\n",
      "\n",
      "        wandb.finish()\n",
      "\n",
      "#################################################\n",
      "\n",
      "# initialize the model and move to the computation device\n",
      "\n",
      "model = create_model(num_classes=NUM_CLASSES)\n",
      "\n",
      "model = model.to(DEVICE)\n",
      "\n",
      "# get the mdel parameters\n",
      "\n",
      "params = [p for p in model.parameters() if p.requires_grad]\n",
      "\n",
      "# define the optimizer\n",
      "\n",
      "optimizer = torch.optim.SGD(params, lr=0.001, momentum=0.9, weight_decay=0.0005)\n",
      "\n",
      "\n",
      "\n",
      "# initialize the Averager class\n",
      "\n",
      "train_loss_hist = Averager()\n",
      "\n",
      "val_loss_hist = Averager()\n",
      "\n",
      "train_itr = 1\n",
      "\n",
      "val_itr = 1\n",
      "\n",
      "# train and validation loss lists to store loss values of all...\n",
      "\n",
      "# ... iterations till end and prot graphs for all iterations\n",
      "\n",
      "train_loss_list = []\n",
      "\n",
      "val_loss_list = []\n",
      "\n",
      "\n",
      "\n",
      "# mean losses for train and validation at every epoch\n",
      "\n",
      "epoch_train_losses = []\n",
      "\n",
      "epoch_validation_losses = []\n",
      "\n",
      "\n",
      "\n",
      "# name to save the trained model with\n",
      "\n",
      "MODEL_NAME = \"MODEL_MASK_1920_aug_1\"\n",
      "\n",
      "\n",
      "\n",
      "# initialize SaveBestModel class\n",
      "\n",
      "save_best_model = SaveBestModel(model_name=MODEL_NAME)\n",
      "\n",
      "\n",
      "\n",
      "# start the training epochs\n",
      "\n",
      "for epoch in range(NUM_EPOCHS):\n",
      "\n",
      "    print(f\"\\nEPOCH {epoch+1} of {NUM_EPOCHS}\")\n",
      "\n",
      "\n",
      "\n",
      "    # reset the training and valitation loss histories for the current epoch\n",
      "\n",
      "    train_loss_hist.reset()\n",
      "\n",
      "    val_loss_hist.reset()\n",
      "\n",
      "\n",
      "\n",
      "    # create two subplots, one for each, training and validation\n",
      "\n",
      "    figure_1, train_ax = plt.subplots()\n",
      "\n",
      "    figure_2, valid_ax = plt.subplots()\n",
      "\n",
      "\n",
      "\n",
      "    # start timer and carry out training and validation\n",
      "\n",
      "    start = time.time()\n",
      "\n",
      "    train_loss = train(train_loader, model, DEVICE)\n",
      "\n",
      "    val_loss = validate(valid_loader, model, DEVICE)\n",
      "\n",
      "    print(f\"Epoch #{epoch+1} train_loss: {train_loss_hist.value:.3f}\")\n",
      "\n",
      "    print(f\"Epoch #{epoch+1} validation_loss: {val_loss_hist.value:.3f}\")\n",
      "\n",
      "    end = time.time()\n",
      "\n",
      "    print(f\"Took {(end - start):.3f} seconds for epoch {epoch+1}\")\n",
      "\n",
      "\n",
      "\n",
      "    # save the mean train and validation losses of this epoch\n",
      "\n",
      "    epoch_train_losses.append(train_loss_hist.value)\n",
      "\n",
      "    epoch_validation_losses.append(val_loss_hist.value)\n",
      "\n",
      "    \n",
      "\n",
      "    # save the best model until now if we have the minimum val loss this epoch\n",
      "\n",
      "    save_best_model(val_loss_hist.value, epoch, model, optimizer)\n",
      "\n",
      "    \n",
      "\n",
      "    #save the current epoch model\n",
      "\n",
      "    save_model(epoch, model, optimizer, model_name=MODEL_NAME)\n",
      "\n",
      "    \n",
      "\n",
      "    #save the loss plot\n",
      "\n",
      "    save_loss_plot(OUT_DIR, train_loss, val_loss, epoch_train_losses, epoch_validation_losses, epoch+1, MODEL_NAME)\n",
      "\n",
      "#################################################\n",
      "\n",
      "model, history = run_training(model, optimizer, scheduler,\n",
      "\n",
      "                              device=CONFIG['device'],\n",
      "\n",
      "                              num_epochs=CONFIG['epochs'])\n",
      "\n",
      "#################################################\n",
      "\n",
      "global sheet_no\n",
      "\n",
      "\n",
      "\n",
      "position_variation=[[2,1,0], [1,0,2], [1,2,0], [1,0,2], [0,2, 1],\n",
      "\n",
      "                    [2 ,1,0] ,[2,0,1] ,[0,2,1] , [2,0,1] ,[1,2,0],\n",
      "\n",
      "                    [2 ,0,1] ,[0,1,2] ,[0,2,1] , [1,0,2] ,[1,2,0],\n",
      "\n",
      "                    [0 ,2,1] ,[2,0,1] ,[0,2,1] , [1,0,2] ,[2,1,0]\n",
      "\n",
      "                   ] \n",
      "\n",
      "\n",
      "\n",
      "for model in ['word2vecDict']:\n",
      "\n",
      "    if model == 'word2vecDict':\n",
      "\n",
      "        print(\"word2vec\")        \n",
      "\n",
      "        row_position = 10 # strating excel row position \n",
      "\n",
      "        top_analogies = 2 # Consider top 2 analogies from all discovered analogies. \n",
      "\n",
      "        word2vecDict = load_word2vec()\n",
      "\n",
      "        workbook = execel_definition()            \n",
      "\n",
      "        \n",
      "\n",
      "        all_ipt_words =  ['girl','king','germany','bike','jupiter','canada','google','eye' ,'dollar', 'book', 'university', 'mobile', 'columbia', 'taxi', 'bread', 'doctor', 'shirt', 'gold', 'earth',  'fish']\n",
      "\n",
      "        ipt_words = ['earth'] \n",
      "\n",
      "        for input_word, windex in zip(ipt_words, range(len(ipt_words))):                  \n",
      "\n",
      "            \n",
      "\n",
      "             \n",
      "\n",
      "            random_selected_word = select_random_word(word2vecDict, select_wft_thesold[:1000])\n",
      "\n",
      "            \n",
      "\n",
      "            near_by_words = faiss_process(input_word, select_wft_thesold, word2vecDict, 'word2vecDict', 300)\n",
      "\n",
      "            word_1_near_by_words_dictionary = { near_by_words.index(word) : word  for word in near_by_words }\n",
      "\n",
      "           \n",
      "\n",
      "            # Create/Discover Analogies \n",
      "\n",
      "            create_analogies(input_word, word_1_near_by_words_dictionary, random_selected_word, word2vecDict,'word2vecDict', top_analogies, row_position, workbook, position_variation[all_ipt_words.index(input_word)])\n",
      "\n",
      "            row_position = row_position + 9 \n",
      "\n",
      "        \n",
      "\n",
      "        \n",
      "\n",
      "        del word2vecDict          \n",
      "\n",
      "    \n",
      "\n",
      "#################################################\n",
      "\n",
      "train_detector(model, datasets[0], cfg, distributed=False, validate=True)\n",
      "\n",
      "#################################################\n",
      "\n",
      "if __name__ == '__main__':\n",
      "\n",
      "    \n",
      "\n",
      "    def get_result(oof_df):\n",
      "\n",
      "        labels = oof_df['score'].values\n",
      "\n",
      "        preds = oof_df['pred'].values\n",
      "\n",
      "        score = get_score(labels, preds)\n",
      "\n",
      "        LOGGER.info(f'Score: {score:<.4f}')\n",
      "\n",
      "    \n",
      "\n",
      "    if CFG.train:\n",
      "\n",
      "        oof_df = pd.DataFrame()\n",
      "\n",
      "        for fold in range(CFG.n_fold):\n",
      "\n",
      "            if fold in CFG.trn_fold:\n",
      "\n",
      "                _oof_df = train_loop(train, fold)\n",
      "\n",
      "                oof_df = pd.concat([oof_df, _oof_df])\n",
      "\n",
      "                LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
      "\n",
      "                get_result(_oof_df)\n",
      "\n",
      "        oof_df = oof_df.reset_index(drop=True)\n",
      "\n",
      "        LOGGER.info(f\"========== CV ==========\")\n",
      "\n",
      "        get_result(oof_df)\n",
      "\n",
      "        oof_df.to_pickle(OUTPUT_DIR+'oof_df.pkl')\n",
      "\n",
      "        \n",
      "\n",
      "    if CFG.wandb:\n",
      "\n",
      "        wandb.finish()\n",
      "\n",
      "#################################################\n",
      "\n",
      "history = trainer.fit(epochs, device)\n",
      "\n",
      "#################################################\n",
      "\n",
      "if __name__ == '__main__':\n",
      "\n",
      "    \n",
      "\n",
      "    def get_result(oof_df):\n",
      "\n",
      "        labels = oof_df['discourse_effectiveness'].values\n",
      "\n",
      "        preds = oof_df[['pred_0','pred_1','pred_2']].values\n",
      "\n",
      "        score = get_score(labels, preds)\n",
      "\n",
      "        LOGGER.info(f'Score: {score:<.4f}')\n",
      "\n",
      "    \n",
      "\n",
      "    oof_df = pd.DataFrame()\n",
      "\n",
      "    for fold in range(CFG.n_fold):\n",
      "\n",
      "        if fold in CFG.trn_fold:\n",
      "\n",
      "            _oof_df = train_loop(train, fold)\n",
      "\n",
      "            oof_df = pd.concat([oof_df, _oof_df])\n",
      "\n",
      "            LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
      "\n",
      "            get_result(_oof_df)\n",
      "\n",
      "    oof_df = oof_df.reset_index(drop=True)\n",
      "\n",
      "    LOGGER.info(f\"========== CV ==========\")\n",
      "\n",
      "    get_result(oof_df)\n",
      "\n",
      "    oof_df.to_pickle(OUTPUT_DIR+'oof_df.pkl')\n",
      "\n",
      "        \n",
      "\n",
      "    if CFG.wandb:\n",
      "\n",
      "        wandb.finish()\n",
      "\n",
      "#################################################\n",
      "\n",
      "# Load\n",
      "\n",
      "IoU_save = []\n",
      "\n",
      "mIoU_save = []\n",
      "\n",
      "F1_save = []\n",
      "\n",
      "mF1_save = []\n",
      "\n",
      "loss_save = []\n",
      "\n",
      "\n",
      "\n",
      "for i in range(20):\n",
      "\n",
      "    print(\" \")\n",
      "\n",
      "    print(\"Model \", (i+1)*100)\n",
      "\n",
      "\n",
      "\n",
      "    model_save_name = 'classifier_train_for_{}_batches.pt'.format(100*(i+1))\n",
      "\n",
      "    path = F\"../u-net-trained-models-gtav-2000-img-no-augmentation/{model_save_name}\" #../input/u-net-trained-models-gtav-2000-img-no-augmentation\n",
      "\n",
      "    # net = torch.load(PATH)\n",
      "\n",
      "    net = UNET(in_channels=3, out_channels=len(semantic_classes), features=[64, 128, 256, 512])\n",
      "\n",
      "    net = net.to(device)\n",
      "\n",
      "    net.load_state_dict(torch.load(path))\n",
      "\n",
      "    net.eval()\n",
      "\n",
      "\n",
      "\n",
      "    criterion = nn.CrossEntropyLoss()\n",
      "\n",
      "    criterion = criterion.to(device)\n",
      "\n",
      "\n",
      "\n",
      "    copy_test_loader = copy.copy(test_loader)\n",
      "\n",
      "    losses, TP, TN, FP, FN = test(copy_test_loader, net, criterion)\n",
      "\n",
      "    print(\" \")\n",
      "\n",
      "    \n",
      "\n",
      "    TP = np.asarray(TP)\n",
      "\n",
      "    TN = np.asarray(TN)\n",
      "\n",
      "    FP = np.asarray(FP)\n",
      "\n",
      "    FN = np.asarray(FN)\n",
      "\n",
      "\n",
      "\n",
      "    IoU_per_image = TP / (TP + FP + TN) # Jaccard\n",
      "\n",
      "    IoU = sum(IoU_per_image) / len(IoU_per_image)\n",
      "\n",
      "    mIoU = sum(IoU) / len(IoU)\n",
      "\n",
      "\n",
      "\n",
      "    F1_per_image = 2 * TP / (2 * TP + FP + TN) # Dice\n",
      "\n",
      "    F1 =  sum(F1_per_image) / len(F1_per_image)\n",
      "\n",
      "    mF1 = sum(F1) / len(F1)\n",
      "\n",
      "    \n",
      "\n",
      "    losses = torch.FloatTensor(losses)\n",
      "\n",
      "    print('Average loss = ',torch.mean(losses).item())\n",
      "\n",
      "    loss_save.append(torch.mean(losses))\n",
      "\n",
      "    IoU_save.append(IoU)\n",
      "\n",
      "    mIoU_save.append(mIoU)\n",
      "\n",
      "    F1_save.append(F1)\n",
      "\n",
      "    mF1_save.append(mF1)\n",
      "\n",
      "    \n",
      "\n",
      "save_name = 'losses.txt'\n",
      "\n",
      "path = F\"/kaggle/working/{save_name}\" \n",
      "\n",
      "np.savetxt(path, loss_save)\n",
      "\n",
      "print('Saved losses') \n",
      "\n",
      "\n",
      "\n",
      "save_name = 'IoU_save.txt'\n",
      "\n",
      "path = F\"/kaggle/working/{save_name}\" \n",
      "\n",
      "np.savetxt(path, IoU_save)\n",
      "\n",
      "print('Saved IoU_save') \n",
      "\n",
      "\n",
      "\n",
      "save_name = 'mIoU_save.txt'\n",
      "\n",
      "path = F\"/kaggle/working/{save_name}\" \n",
      "\n",
      "np.savetxt(path, mIoU_save)\n",
      "\n",
      "print('Saved mIoU_save') \n",
      "\n",
      "\n",
      "\n",
      "save_name = 'F1_save.txt'\n",
      "\n",
      "path = F\"/kaggle/working/{save_name}\" \n",
      "\n",
      "np.savetxt(path, F1_save)\n",
      "\n",
      "print('Saved F1_save') \n",
      "\n",
      "\n",
      "\n",
      "save_name = 'mF1_save.txt'\n",
      "\n",
      "path = F\"/kaggle/working/{save_name}\" \n",
      "\n",
      "np.savetxt(path, mF1_save)\n",
      "\n",
      "print('Saved mF1_save') \n",
      "\n",
      "\n",
      "#################################################\n",
      "\n",
      "model.train()\n",
      "\n",
      "#################################################\n",
      "\n",
      "best_metric = -1\n",
      "\n",
      "best_metric_epoch = -1\n",
      "\n",
      "epoch_loss_values = list()\n",
      "\n",
      "auc_metric = ROCAUCMetric()\n",
      "\n",
      "metric_values = list()\n",
      "\n",
      "\n",
      "\n",
      "for epoch in range(epoch_num):\n",
      "\n",
      "    print('-' * 10)\n",
      "\n",
      "    print(f\"epoch {epoch + 1}/{epoch_num}\")\n",
      "\n",
      "    model.train()\n",
      "\n",
      "    epoch_loss = 0\n",
      "\n",
      "    step = 0\n",
      "\n",
      "\n",
      "\n",
      "    for batch_data in train_loader:\n",
      "\n",
      "        step += 1\n",
      "\n",
      "        inputs, labels = batch_data[0].to(device), batch_data[1].to(device)\n",
      "\n",
      "        optimizer.zero_grad()\n",
      "\n",
      "        outputs = model(inputs.float())     ##### \n",
      "\n",
      "        loss = loss_function(outputs, labels)\n",
      "\n",
      "        loss.backward()\n",
      "\n",
      "        optimizer.step()\n",
      "\n",
      "        epoch_loss += loss.item()\n",
      "\n",
      "        print(f\"{step}/{len(train_ds) // train_loader.batch_size}, train_loss: {loss.item():.4f}\")\n",
      "\n",
      "        epoch_len = len(train_ds) // train_loader.batch_size\n",
      "\n",
      "\n",
      "\n",
      "    epoch_loss /= step\n",
      "\n",
      "    epoch_loss_values.append(epoch_loss)\n",
      "\n",
      "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
      "\n",
      "\n",
      "\n",
      "    if (epoch + 1) % val_interval == 0:\n",
      "\n",
      "        model.eval()\n",
      "\n",
      "        with torch.no_grad():\n",
      "\n",
      "            y_pred = torch.tensor([], dtype=torch.float32, device=device)\n",
      "\n",
      "            y = torch.tensor([], dtype=torch.long, device=device)\n",
      "\n",
      "            for val_data in val_loader:\n",
      "\n",
      "                val_images, val_labels = val_data[0].to(device), val_data[1].to(device)\n",
      "\n",
      "                y_pred = torch.cat([y_pred, model(val_images.float())], dim=0)\n",
      "\n",
      "                y = torch.cat([y, val_labels], dim=0)\n",
      "\n",
      "                \n",
      "\n",
      "            y_onehot = [to_onehot(i) for i in y]\n",
      "\n",
      "            y_pred_act = [act(i) for i in y_pred]\n",
      "\n",
      "            auc_metric(y_pred_act, y_onehot)\n",
      "\n",
      "            auc_result = auc_metric.aggregate()\n",
      "\n",
      "            auc_metric.reset()\n",
      "\n",
      "            del y_pred_act, y_onehot\n",
      "\n",
      "            metric_values.append(auc_result)\n",
      "\n",
      "            acc_value = torch.eq(y_pred.argmax(dim=1), y)\n",
      "\n",
      "            acc_metric = acc_value.sum().item() / len(acc_value)\n",
      "\n",
      "            \n",
      "\n",
      "            if acc_metric > best_metric:\n",
      "\n",
      "                best_metric = acc_metric\n",
      "\n",
      "                best_metric_epoch = epoch + 1\n",
      "\n",
      "                torch.save(model.state_dict(), 'best_metric_model.pth')\n",
      "\n",
      "                print('saved new best metric model')\n",
      "\n",
      "                \n",
      "\n",
      "            print(f\"current epoch: {epoch + 1} current AUC: {auc_result:.4f}\"\n",
      "\n",
      "                  f\" current accuracy: {acc_metric:.4f} best AUC: {best_metric:.4f}\"\n",
      "\n",
      "                  f\" at epoch: {best_metric_epoch}\")\n",
      "\n",
      "            \n",
      "\n",
      "print(f\"train completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")\n",
      "\n",
      "\n",
      "#################################################\n",
      "\n",
      "df = shuffle(df, random_state=RANDOM_STATE)\n",
      "\n",
      "\n",
      "\n",
      "for fold, (_, split) in enumerate(\n",
      "\n",
      "    GroupKFold(K_FOLDS).split(df, groups=df[\"ancestor_id\"])\n",
      "\n",
      "):\n",
      "\n",
      "    print(\"=\" * 36, f\"Fold {fold}\", \"=\" * 36)\n",
      "\n",
      "    fold_dir = f\"tfrec/{fold}\"\n",
      "\n",
      "    if not os.path.exists(fold_dir):\n",
      "\n",
      "        os.mkdir(fold_dir)\n",
      "\n",
      "\n",
      "\n",
      "    data = tokenize(df.iloc[split], features)\n",
      "\n",
      "\n",
      "\n",
      "    np.savez_compressed(\n",
      "\n",
      "        f\"raw/{fold}.npz\",\n",
      "\n",
      "        input_ids=data[\"input_ids\"],\n",
      "\n",
      "        attention_mask=data[\"attention_mask\"],\n",
      "\n",
      "        features=data[\"features\"],\n",
      "\n",
      "        labels=data[\"labels\"],\n",
      "\n",
      "            )\n",
      "\n",
      "\n",
      "\n",
      "    for split, index in tqdm(\n",
      "\n",
      "        enumerate(np.array_split(np.arange(data[\"labels\"].shape[0]), FILES_PER_FOLD)),\n",
      "\n",
      "        desc=f\"Saving\",\n",
      "\n",
      "        total=FILES_PER_FOLD,\n",
      "\n",
      "    ):\n",
      "\n",
      "        serialize(\n",
      "\n",
      "            input_ids=data[\"input_ids\"][index],\n",
      "\n",
      "            attention_mask=data[\"attention_mask\"][index],\n",
      "\n",
      "            features=data[\"features\"][index],\n",
      "\n",
      "            labels=data[\"labels\"][index],\n",
      "\n",
      "            path=os.path.join(fold_dir, f\"{split:02d}-{len(index):06d}.tfrec\"),\n",
      "\n",
      "        )\n",
      "\n",
      "    \n",
      "\n",
      "#################################################\n",
      "\n",
      "for fold in range(0, CONFIG['n_fold']):\n",
      "\n",
      "    print(f\"{y_}====== Fold: {fold} ======{sr_}\")\n",
      "\n",
      "    run = wandb.init(project='FeedBack', \n",
      "\n",
      "                     config=CONFIG,\n",
      "\n",
      "                     job_type='Train',\n",
      "\n",
      "                     group=CONFIG['group'],\n",
      "\n",
      "                     tags=[CONFIG['model_name'], f'{HASH_NAME}'],\n",
      "\n",
      "                     name=f'{HASH_NAME}-fold-{fold}',\n",
      "\n",
      "                     anonymous='must')\n",
      "\n",
      "    \n",
      "\n",
      "    # Create Dataloaders\n",
      "\n",
      "    train_loader, valid_loader = prepare_loaders(fold=fold)\n",
      "\n",
      "    \n",
      "\n",
      "    model = FeedBackModel(CONFIG['model_name'])\n",
      "\n",
      "    model.to(CONFIG['device'])\n",
      "\n",
      "    \n",
      "\n",
      "    # Define Optimizer and Scheduler\n",
      "\n",
      "    optimizer = AdamW(model.parameters(), lr=CONFIG['learning_rate'], weight_decay=CONFIG['weight_decay'])\n",
      "\n",
      "    scheduler = fetch_scheduler(optimizer)\n",
      "\n",
      "    \n",
      "\n",
      "    model, history = run_training(model, optimizer, scheduler,\n",
      "\n",
      "                                  device=CONFIG['device'],\n",
      "\n",
      "                                  num_epochs=CONFIG['epochs'],\n",
      "\n",
      "                                  fold=fold)\n",
      "\n",
      "    \n",
      "\n",
      "    run.finish()\n",
      "\n",
      "    \n",
      "\n",
      "    del model, history, train_loader, valid_loader\n",
      "\n",
      "    _ = gc.collect()\n",
      "\n",
      "    print()\n",
      "\n",
      "#################################################\n",
      "\n",
      "def read_data(data):\n",
      "\n",
      "    return tuple(d.cuda() for d in data[:-1]), data[-1].cuda()\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "def validate(model, val_loader):\n",
      "\n",
      "    model.eval()\n",
      "\n",
      "    \n",
      "\n",
      "    tbar = tqdm(val_loader, file=sys.stdout)\n",
      "\n",
      "    \n",
      "\n",
      "    preds = []\n",
      "\n",
      "    labels = []\n",
      "\n",
      "\n",
      "\n",
      "    with torch.no_grad():\n",
      "\n",
      "        for idx, data in enumerate(tbar):\n",
      "\n",
      "            inputs, target = read_data(data)\n",
      "\n",
      "\n",
      "\n",
      "            pred = model(inputs[0], inputs[1])\n",
      "\n",
      "\n",
      "\n",
      "            preds.append(pred.detach().cpu().numpy().ravel())\n",
      "\n",
      "            labels.append(target.detach().cpu().numpy().ravel())\n",
      "\n",
      "    \n",
      "\n",
      "    return np.concatenate(labels), np.concatenate(preds)\n",
      "\n",
      "\n",
      "\n",
      "def train(model, train_loader, val_loader, epochs):\n",
      "\n",
      "    np.random.seed(SEED)\n",
      "\n",
      "    \n",
      "\n",
      "    optimizer = get_optimizer(model)\n",
      "\n",
      "\n",
      "\n",
      "    criterion = torch.nn.MSELoss()\n",
      "\n",
      "    \n",
      "\n",
      "    best_valid_loss = np.inf\n",
      "\n",
      "    \n",
      "\n",
      "    for e in range(epochs):   \n",
      "\n",
      "        model.train()\n",
      "\n",
      "        tbar = tqdm(train_loader, file=sys.stdout)\n",
      "\n",
      "        \n",
      "\n",
      "        lr = adjust_lr(optimizer, e)\n",
      "\n",
      "        \n",
      "\n",
      "        loss_list = []\n",
      "\n",
      "        preds = []\n",
      "\n",
      "        labels = []\n",
      "\n",
      "\n",
      "\n",
      "        for idx, data in enumerate(tbar):\n",
      "\n",
      "            inputs, target = read_data(data)\n",
      "\n",
      "\n",
      "\n",
      "            optimizer.zero_grad()\n",
      "\n",
      "            pred = model(inputs[0], inputs[1])\n",
      "\n",
      "\n",
      "\n",
      "            loss = criterion(pred, target)\n",
      "\n",
      "            loss.backward()\n",
      "\n",
      "            optimizer.step()\n",
      "\n",
      "            \n",
      "\n",
      "            loss_list.append(loss.detach().cpu().item())\n",
      "\n",
      "            preds.append(pred.detach().cpu().numpy().ravel())\n",
      "\n",
      "            labels.append(target.detach().cpu().numpy().ravel())\n",
      "\n",
      "            \n",
      "\n",
      "            avg_loss = np.round(np.mean(loss_list), 4)\n",
      "\n",
      "\n",
      "\n",
      "            tbar.set_description(f\"Epoch {e+1} Loss: {avg_loss} lr: {lr}\")\n",
      "\n",
      "            \n",
      "\n",
      "        y_val, y_pred = validate(model, val_loader)\n",
      "\n",
      "        \n",
      "\n",
      "        print(\"Validation MSE:\", np.round(mean_squared_error(y_val, y_pred), 4))\n",
      "\n",
      "        if best_valid_loss > mean_squared_error(y_val, y_pred):\n",
      "\n",
      "            torch.save(model.state_dict(), f\"pytorch_best_model.bin\")\n",
      "\n",
      "        print()\n",
      "\n",
      "    return model, y_pred\n",
      "\n",
      "\n",
      "\n",
      "model = MarkdownModel()\n",
      "\n",
      "model = model.cuda()\n",
      "\n",
      "model, y_pred = train(model, train_loader, val_loader, epochs=EPOCHS)\n",
      "\n",
      "#################################################\n",
      "\n",
      "learn.fit_one_cycle(10,lr_max = params.LR,wd=params.WEIGHT_DECAY)\n",
      "\n",
      "#################################################\n",
      "\n",
      "best_metric = -1\n",
      "\n",
      "best_metric_epoch = -1\n",
      "\n",
      "epoch_loss_values = list()\n",
      "\n",
      "auc_metric = ROCAUCMetric()\n",
      "\n",
      "metric_values = list()\n",
      "\n",
      "\n",
      "\n",
      "for epoch in range(epoch_num):\n",
      "\n",
      "    print('-' * 10)\n",
      "\n",
      "    print(f\"epoch {epoch + 1}/{epoch_num}\")\n",
      "\n",
      "    model.train()\n",
      "\n",
      "    epoch_loss = 0\n",
      "\n",
      "    step = 0\n",
      "\n",
      "\n",
      "\n",
      "    for batch_data in train_loader:\n",
      "\n",
      "        step += 1\n",
      "\n",
      "        inputs, labels = batch_data[0].to(device), batch_data[1].to(device)\n",
      "\n",
      "        optimizer.zero_grad()\n",
      "\n",
      "        outputs = model(inputs.float())     ##### .float()\n",
      "\n",
      "        loss = loss_function(outputs, labels)\n",
      "\n",
      "        loss.backward()\n",
      "\n",
      "        optimizer.step()\n",
      "\n",
      "        epoch_loss += loss.item()\n",
      "\n",
      "        print(f\"{step}/{len(train_ds) // train_loader.batch_size}, train_loss: {loss.item():.4f}\")\n",
      "\n",
      "        epoch_len = len(train_ds) // train_loader.batch_size\n",
      "\n",
      "\n",
      "\n",
      "    epoch_loss /= step\n",
      "\n",
      "    epoch_loss_values.append(epoch_loss)\n",
      "\n",
      "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
      "\n",
      "\n",
      "\n",
      "    if (epoch + 1) % val_interval == 0:\n",
      "\n",
      "        model.eval()\n",
      "\n",
      "        with torch.no_grad():\n",
      "\n",
      "            y_pred = torch.tensor([], dtype=torch.float32, device=device)\n",
      "\n",
      "            y = torch.tensor([], dtype=torch.long, device=device)\n",
      "\n",
      "            for val_data in val_loader:\n",
      "\n",
      "                val_images, val_labels = val_data[0].to(device), val_data[1].to(device)\n",
      "\n",
      "                y_pred = torch.cat([y_pred, model(val_images)], dim=0)\n",
      "\n",
      "                y = torch.cat([y, val_labels], dim=0)\n",
      "\n",
      "                \n",
      "\n",
      "            y_onehot = [to_onehot(i) for i in y]\n",
      "\n",
      "            y_pred_act = [act(i) for i in y_pred]\n",
      "\n",
      "            auc_metric(y_pred_act, y_onehot)\n",
      "\n",
      "            auc_result = auc_metric.aggregate()\n",
      "\n",
      "            auc_metric.reset()\n",
      "\n",
      "            del y_pred_act, y_onehot\n",
      "\n",
      "            metric_values.append(auc_result)\n",
      "\n",
      "            acc_value = torch.eq(y_pred.argmax(dim=1), y)\n",
      "\n",
      "            acc_metric = acc_value.sum().item() / len(acc_value)\n",
      "\n",
      "            \n",
      "\n",
      "            if acc_metric > best_metric:\n",
      "\n",
      "                best_metric = acc_metric\n",
      "\n",
      "                best_metric_epoch = epoch + 1\n",
      "\n",
      "                torch.save(model.state_dict(), 'best_metric_model.pth')\n",
      "\n",
      "                print('saved new best metric model')\n",
      "\n",
      "                \n",
      "\n",
      "            print(f\"current epoch: {epoch + 1} current AUC: {auc_result:.4f}\"\n",
      "\n",
      "                  f\" current accuracy: {acc_metric:.4f} best AUC: {best_metric:.4f}\"\n",
      "\n",
      "                  f\" at epoch: {best_metric_epoch}\")\n",
      "\n",
      "            \n",
      "\n",
      "print(f\"train completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")\n",
      "\n",
      "\n",
      "#################################################\n",
      "\n",
      "gridcv.fit(X_train, y_train)\n",
      "\n",
      "#################################################\n",
      "\n",
      "if __name__ == '__main__':\n",
      "\n",
      "    \n",
      "\n",
      "    def get_result(oof_df):\n",
      "\n",
      "        labels = oof_df['score'].values\n",
      "\n",
      "        preds = oof_df['pred'].values\n",
      "\n",
      "        score = get_score(labels, preds)\n",
      "\n",
      "        LOGGER.info(f'Score: {score:<.4f}')\n",
      "\n",
      "    \n",
      "\n",
      "    if CFG.train:\n",
      "\n",
      "        oof_df = pd.DataFrame()\n",
      "\n",
      "        for fold in range(CFG.n_fold):\n",
      "\n",
      "            if fold in CFG.trn_fold:\n",
      "\n",
      "                _oof_df = train_loop(train, fold)\n",
      "\n",
      "                oof_df = pd.concat([oof_df, _oof_df])\n",
      "\n",
      "                LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
      "\n",
      "                get_result(_oof_df)\n",
      "\n",
      "        oof_df = oof_df.reset_index(drop=True)\n",
      "\n",
      "        LOGGER.info(f\"========== CV ==========\")\n",
      "\n",
      "        get_result(oof_df)\n",
      "\n",
      "        oof_df.to_pickle(OUTPUT_DIR+'oof_df.pkl')\n",
      "\n",
      "        \n",
      "\n",
      "    if CFG.wandb:\n",
      "\n",
      "        wandb.finish()\n",
      "\n",
      "#################################################\n",
      "\n",
      "%%time\n",
      "\n",
      "loop()\n",
      "\n",
      "#################################################\n",
      "\n",
      "N_targets = len(F4_features)\n",
      "\n",
      "for it, TARGET_NAME in enumerate(F4_features):\n",
      "\n",
      "    print('='*50)\n",
      "\n",
      "    print('START COLUMN {}/{} {}'.format(it+1, N_targets, TARGET_NAME))\n",
      "\n",
      "    train_data = data[~data[TARGET_NAME].isna()][F4_features + ['row_id']]\n",
      "\n",
      "    test_data = data[data[TARGET_NAME].isna()][F4_features + ['row_id']]\n",
      "\n",
      "    print(train_data.shape, test_data.shape)\n",
      "\n",
      "\n",
      "\n",
      "    # Task setup\n",
      "\n",
      "    task = Task('reg',)\n",
      "\n",
      "\n",
      "\n",
      "    # Feature roles\n",
      "\n",
      "    roles = {\n",
      "\n",
      "        'target': TARGET_NAME,\n",
      "\n",
      "        'drop': ['row_id']\n",
      "\n",
      "    }\n",
      "\n",
      "\n",
      "\n",
      "    # Pipeline creation\n",
      "\n",
      "    reader = PandasToPandasReader(task, **{**tabular_params['reader_params'], \n",
      "\n",
      "                                         \"random_state\": RANDOM_STATE,\n",
      "\n",
      "                                         \"cv\": N_FOLDS})\n",
      "\n",
      "    train_ds = reader.fit_read(train_data, roles=roles)\n",
      "\n",
      "    test_ds = reader.read(test_data)\n",
      "\n",
      "\n",
      "\n",
      "    pipe = TorchBaseFeatures()\n",
      "\n",
      "    iterator = FoldsIterator(train=train_ds)\n",
      "\n",
      "\n",
      "\n",
      "    model = TorchModel(name_to_model_params[MODEL_NAME])\n",
      "\n",
      "    ml_pipe = MLPipeline([\n",
      "\n",
      "        model\n",
      "\n",
      "    ], pre_selection=None, features_pipeline=pipe, post_selection=None)\n",
      "\n",
      "\n",
      "\n",
      "    # Fit_predict using created pipelien\n",
      "\n",
      "    oof_pred = ml_pipe.fit_predict(iterator)\n",
      "\n",
      "\n",
      "\n",
      "    # Results calculation\n",
      "\n",
      "    mask = ~np.isnan(oof_pred.data[:, 0])\n",
      "\n",
      "    print(sum(mask) == len(train_data))\n",
      "\n",
      "    print(f'{it+1}/{N_targets} {TARGET_NAME} TRAIN out-of-fold score: {mean_squared_error(train_data[TARGET_NAME].values[mask], oof_pred.data[:, 0][mask], squared = False)}')\n",
      "\n",
      "    \n",
      "\n",
      "    # Test prediction using the trained pipeline\n",
      "\n",
      "    test_pred = ml_pipe.predict(test_ds)\n",
      "\n",
      "    FINAL_PREDS.append(pd.DataFrame([[str(idx) + '-' + TARGET_NAME, val] for idx,val in zip(test_data['row_id'].values, test_pred.data[:, 0])], \n",
      "\n",
      "                                    columns = submission.columns))\n",
      "\n",
      "#################################################\n",
      "\n",
      "history = History()\n",
      "\n",
      "buffer_monet = Buffer()\n",
      "\n",
      "buffer_photo = Buffer()\n",
      "\n",
      "\n",
      "\n",
      "for epoch in range(num_epochs):\n",
      "\n",
      "    avg_generators_loss = 0\n",
      "\n",
      "    avg_discriminators_loss = 0\n",
      "\n",
      "    \n",
      "\n",
      "    for i, (real_monet, real_photo) in enumerate(tqdm(dataloader, leave=False, total=len(dataloader))):\n",
      "\n",
      "        real_monet, real_photo = real_monet.to(device), real_photo.to(device)\n",
      "\n",
      "                \n",
      "\n",
      "        \"\"\" Train Generators \"\"\"\n",
      "\n",
      "        # switching models parameters so that only generators are trained\n",
      "\n",
      "        update_req_grad([generator_monet2photo, generator_photo2monet], True)\n",
      "\n",
      "        update_req_grad([discriminator_monet, discriminator_photo], False)\n",
      "\n",
      "        \n",
      "\n",
      "        # zero the parameters gradients\n",
      "\n",
      "        optim_generators.zero_grad()\n",
      "\n",
      "        \n",
      "\n",
      "        # forward-pass\n",
      "\n",
      "        fake_photo = generator_monet2photo(real_monet)\n",
      "\n",
      "        fake_monet = generator_photo2monet(real_photo)\n",
      "\n",
      "        \n",
      "\n",
      "        cycle_photo = generator_monet2photo(fake_monet)\n",
      "\n",
      "        cycle_monet = generator_photo2monet(fake_photo)\n",
      "\n",
      "        \n",
      "\n",
      "        identity_photo = generator_monet2photo(real_photo)\n",
      "\n",
      "        identity_monet = generator_photo2monet(real_monet)\n",
      "\n",
      "        \n",
      "\n",
      "        # update photos that are used to feed up discriminators\n",
      "\n",
      "        buffer_photo.update(fake_photo)\n",
      "\n",
      "        buffer_monet.update(fake_monet)\n",
      "\n",
      "        \n",
      "\n",
      "        # discriminators outputs that are used in adversarial loss\n",
      "\n",
      "        discriminator_outputs_photo = discriminator_photo(fake_photo)\n",
      "\n",
      "        discriminator_outputs_monet = discriminator_monet(fake_monet)\n",
      "\n",
      "        \n",
      "\n",
      "        # labels that are used as ground truth\n",
      "\n",
      "        labels_real = torch.ones(discriminator_outputs_monet.size()).to(device)\n",
      "\n",
      "        labels_fake = torch.zeros(discriminator_outputs_monet.size()).to(device)\n",
      "\n",
      "        \n",
      "\n",
      "        # adversarial loss - enforces that the generated output be of the appropriate domain\n",
      "\n",
      "        loss_GAN_monet2photo = criterion_GAN(discriminator_outputs_photo, labels_real)\n",
      "\n",
      "        loss_GAN_photo2monet = criterion_GAN(discriminator_outputs_monet, labels_real)\n",
      "\n",
      "        loss_GAN = (loss_GAN_monet2photo + loss_GAN_photo2monet) / 2\n",
      "\n",
      "        \n",
      "\n",
      "        # cycle consistency loss - enforces that the input and output are recognizably the same\n",
      "\n",
      "        loss_cycle_photo = criterion_cycle(cycle_photo, real_photo)\n",
      "\n",
      "        loss_cycle_monet = criterion_cycle(cycle_monet, real_monet)\n",
      "\n",
      "        loss_cycle = (loss_cycle_photo + loss_cycle_monet) / 2\n",
      "\n",
      "        \n",
      "\n",
      "        # identity mapping loss - helps preserve the color of the input images\n",
      "\n",
      "        loss_identity_photo = criterion_identity(identity_photo, real_photo)\n",
      "\n",
      "        loss_identity_monet = criterion_identity(identity_monet, real_monet)\n",
      "\n",
      "        loss_identity = (loss_identity_photo + loss_identity_monet) / 2\n",
      "\n",
      "        \n",
      "\n",
      "        # total loss\n",
      "\n",
      "        loss_generators_total = loss_GAN + 10 * loss_cycle + 5 * loss_identity\n",
      "\n",
      "        \n",
      "\n",
      "        # backward-pass\n",
      "\n",
      "        loss_generators_total.backward()\n",
      "\n",
      "        optim_generators.step()\n",
      "\n",
      "        \n",
      "\n",
      "        # limiting gradient norms - if they exceed 100, something went wrong\n",
      "\n",
      "        clip_grad_norm_(generator_photo2monet.parameters(), 100)\n",
      "\n",
      "        clip_grad_norm_(generator_monet2photo.parameters(), 100)\n",
      "\n",
      "        \n",
      "\n",
      "        \n",
      "\n",
      "        \"\"\" Train Discriminators \"\"\"\n",
      "\n",
      "        # switching models parameters so that only discriminators are trained\n",
      "\n",
      "        update_req_grad([discriminator_monet, discriminator_photo], True)\n",
      "\n",
      "        update_req_grad([generator_monet2photo, generator_photo2monet], False)\n",
      "\n",
      "        \n",
      "\n",
      "        # zero the parameters gradients\n",
      "\n",
      "        optim_discriminators.zero_grad()\n",
      "\n",
      "        \n",
      "\n",
      "        # sample images from 50 stored\n",
      "\n",
      "        fake_photo = buffer_photo.sample(num_images=batch_size).to(device)\n",
      "\n",
      "        fake_monet = buffer_monet.sample(num_images=batch_size).to(device)\n",
      "\n",
      "        \n",
      "\n",
      "        # making labels noisy for discriminators so that they don't prevail over generators\n",
      "\n",
      "        threshold = min(1, 0.85 + (1 - 0.85) * epoch / (num_epochs // 2))\n",
      "\n",
      "        noisy_labels_real = (torch.rand(discriminator_outputs_monet.size()) < threshold).float().to(device)\n",
      "\n",
      "        \n",
      "\n",
      "        # forward-pass + losses\n",
      "\n",
      "        loss_real_photo = criterion_GAN(discriminator_photo(real_photo), noisy_labels_real)\n",
      "\n",
      "        loss_fake_photo = criterion_GAN(discriminator_photo(fake_photo.detach()), labels_fake)\n",
      "\n",
      "        loss_photo = (loss_real_photo + loss_fake_photo) / 2\n",
      "\n",
      "        \n",
      "\n",
      "        loss_real_monet = criterion_GAN(discriminator_monet(real_monet), noisy_labels_real)\n",
      "\n",
      "        loss_fake_monet = criterion_GAN(discriminator_monet(fake_monet.detach()), labels_fake)\n",
      "\n",
      "        loss_monet = (loss_real_monet + loss_fake_monet) / 2\n",
      "\n",
      "        \n",
      "\n",
      "        loss_discriminators_total = loss_monet + loss_photo\n",
      "\n",
      "        \n",
      "\n",
      "        # backward-pass\n",
      "\n",
      "        loss_discriminators_total.backward()\n",
      "\n",
      "        optim_discriminators.step()\n",
      "\n",
      "        \n",
      "\n",
      "        # clipping gradients to avoid gradients explosion\n",
      "\n",
      "        clip_grad_norm_(discriminator_monet.parameters(), 100)\n",
      "\n",
      "        clip_grad_norm_(discriminator_photo.parameters(), 100)\n",
      "\n",
      "        \n",
      "\n",
      "        # updating intermediate results\n",
      "\n",
      "        avg_generators_loss += loss_generators_total.item()\n",
      "\n",
      "        avg_discriminators_loss += loss_discriminators_total.item()\n",
      "\n",
      "        \n",
      "\n",
      "    # saving intermediate results\n",
      "\n",
      "    avg_generators_loss /= len(dataloader)\n",
      "\n",
      "    avg_discriminators_loss /= len(dataloader)\n",
      "\n",
      "    history.update(avg_generators_loss, avg_discriminators_loss)\n",
      "\n",
      "    \n",
      "\n",
      "    # showing intermediate results\n",
      "\n",
      "    print(\"Epoch: %d/%d | Generators Loss: %.4f | Discriminators Loss: %.4f\"\n",
      "\n",
      "              % (epoch+1, num_epochs, avg_generators_loss, avg_discriminators_loss))\n",
      "\n",
      "    \n",
      "\n",
      "    # showing generated images\n",
      "\n",
      "    if (epoch + 1) % 10 == 0:\n",
      "\n",
      "        _, sample_real_photo = next(iter(dataloader))\n",
      "\n",
      "        \n",
      "\n",
      "        sample_fake_monet = generator_photo2monet(sample_real_photo.to(device)).detach().cpu()\n",
      "\n",
      "        \n",
      "\n",
      "        num_photos = min(batch_size, 5)\n",
      "\n",
      "        plt.figure(figsize=(20, 8))\n",
      "\n",
      "        for k in range(num_photos):\n",
      "\n",
      "            plt.subplot(2, num_photos, k + 1)\n",
      "\n",
      "            plt.imshow(unnorm(sample_real_photo[k]).permute(1, 2, 0))\n",
      "\n",
      "            plt.title('Input photo')\n",
      "\n",
      "            plt.axis('off')\n",
      "\n",
      "\n",
      "\n",
      "            plt.subplot(2, num_photos, k + num_photos + 1)\n",
      "\n",
      "            plt.imshow(unnorm(sample_fake_monet[k]).permute(1, 2, 0))\n",
      "\n",
      "            plt.title('Output image')\n",
      "\n",
      "            plt.axis('off')\n",
      "\n",
      "        plt.show()\n",
      "\n",
      "    \n",
      "\n",
      "    lr_sched_generators.step()\n",
      "\n",
      "    lr_sched_discriminators.step()\n",
      "\n",
      "#################################################\n",
      "\n",
      "%%time \n",
      "\n",
      "\n",
      "\n",
      "class args:\n",
      "\n",
      "    epochs = 6\n",
      "\n",
      "    lr = 1e-3\n",
      "\n",
      "    batch_size = 10\n",
      "\n",
      "    num_workers = 2\n",
      "\n",
      "    val_samples = 1\n",
      "\n",
      "    embedding_size = 4096\n",
      "\n",
      "    backbone_name = \"efficientnet_b0\"\n",
      "\n",
      "    n_classes = data_df[\"hotel_id_code\"].nunique()\n",
      "\n",
      "    device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
      "\n",
      "\n",
      "\n",
      "train_and_validate(args, data_df)\n",
      "\n",
      "#################################################\n",
      "\n",
      "# Instantiate our tool for logging\n",
      "\n",
      "stat_logger = StatLogger()\n",
      "\n",
      "    \n",
      "\n",
      "for epoch in range(1,EPOCHS+1):\n",
      "\n",
      "    print(f'\\n\\n{\"=\"*100}\\n{\"=\"*25:<25}{\"EPOCH #\"+str(epoch): ^50}{\"=\"*25:>25}\\n{\"=\"*100}\\n')\n",
      "\n",
      "    \n",
      "\n",
      "    stat_logger.current_step=0\n",
      "\n",
      "    stat_logger.epoch_start_time = time.time() # to compute epoch duration\n",
      "\n",
      "    \n",
      "\n",
      "    # create distributed versions of dataset to run on TPU with 8 computation units\n",
      "\n",
      "    train_dist_ds = strategy.experimental_distribute_dataset(train_ds)\n",
      "\n",
      "    val_dist_ds = iter(strategy.experimental_distribute_dataset(val_ds))\n",
      "\n",
      "    \n",
      "\n",
      "    for image_batch, inchi_batch in train_dist_ds:\n",
      "\n",
      "                \n",
      "\n",
      "        # Update current step\n",
      "\n",
      "        stat_logger.batch_start_time = time.time()\n",
      "\n",
      "        \n",
      "\n",
      "        # Update the current step\n",
      "\n",
      "        stat_logger.current_step += 1\n",
      "\n",
      "        \n",
      "\n",
      "        # Calculate training step\n",
      "\n",
      "        dist_train_step(image_batch, inchi_batch)\n",
      "\n",
      "        \n",
      "\n",
      "        # end of epoch validation step\n",
      "\n",
      "        if stat_logger.current_step == TRAIN_STEPS and epoch%2==0:\n",
      "\n",
      "            print(\"\\n... VALIDATION DATASET STATISTICS ... \\n\")\n",
      "\n",
      "            for _ in range(VAL_STEPS):\n",
      "\n",
      "                preds, lbls = dist_val_step(val_dist_ds)\n",
      "\n",
      "                metrics[\"val_lsd\"].update_state(get_levenshtein_distance(preds, lbls))\n",
      "\n",
      "                \n",
      "\n",
      "            # Record this epochs statistics\n",
      "\n",
      "            stat_logger.train_loss.append(metrics[\"train_loss\"].result().numpy())\n",
      "\n",
      "            stat_logger.train_acc.append(metrics[\"train_acc\"].result().numpy())\n",
      "\n",
      "            stat_logger.val_loss.append(metrics[\"val_loss\"].result().numpy())\n",
      "\n",
      "            stat_logger.val_acc.append(metrics[\"val_acc\"].result().numpy())\n",
      "\n",
      "            stat_logger.val_lsd.append(metrics[\"val_lsd\"].result().numpy())\n",
      "\n",
      "            stat_logger.step.append(stat_logger.current_step)\n",
      "\n",
      "            stat_logger.epoch.append(epoch)\n",
      "\n",
      "            stat_logger.lr.append(lr_scheduler(tf.cast(stat_logger.current_step+TRAIN_STEPS*(epoch-1), tf.float32)))\n",
      "\n",
      "            \n",
      "\n",
      "            # Reset the validation metrics as one epoch should not effect the next\n",
      "\n",
      "            metrics[\"val_lsd\"].reset_states()\n",
      "\n",
      "            metrics[\"val_acc\"].reset_states()\n",
      "\n",
      "            metrics[\"val_loss\"].reset_states()\n",
      "\n",
      "            metrics[\"train_acc\"].reset_states()\n",
      "\n",
      "            metrics[\"train_loss\"].reset_states()\n",
      "\n",
      "            metrics[\"batch_loss\"].reset_states()\n",
      "\n",
      "            \n",
      "\n",
      "            # Print validation scores\n",
      "\n",
      "            stat_logger.print_last_val(current_time=time.time())\n",
      "\n",
      "        \n",
      "\n",
      "        # verbose logging step\n",
      "\n",
      "        if stat_logger.current_step % stat_logger.verbose_frequency == 0:    \n",
      "\n",
      "            stat_logger.print_current_train(\n",
      "\n",
      "                stat_logger.current_step,\n",
      "\n",
      "                metrics[\"train_acc\"].result().numpy(), \n",
      "\n",
      "                metrics[\"train_loss\"].result().numpy(), \n",
      "\n",
      "                metrics[\"batch_loss\"].result().numpy(), \n",
      "\n",
      "                current_time=time.time(),\n",
      "\n",
      "                current_lr=lr_scheduler(tf.cast(stat_logger.current_step+TRAIN_STEPS*(epoch-1), tf.float32))\n",
      "\n",
      "            )\n",
      "\n",
      "            metrics[\"train_acc\"].reset_states()\n",
      "\n",
      "            metrics[\"train_loss\"].reset_states()\n",
      "\n",
      "            metrics[\"batch_loss\"].reset_states()\n",
      "\n",
      "\n",
      "\n",
      "        # stop training when NaN loss is detected\n",
      "\n",
      "        if stat_logger.current_step == TRAIN_STEPS:\n",
      "\n",
      "            break\n",
      "\n",
      "            \n",
      "\n",
      "        # update learning rate\n",
      "\n",
      "        # lr_scheduler.step(stat_logger.current_step+((epoch-1)*TRAIN_STEPS))\n",
      "\n",
      "        \n",
      "\n",
      "    # Save every other epoch (starting with first epoch)\n",
      "\n",
      "    # Save after last epoch too...\n",
      "\n",
      "    # if epoch%2==1 or epoch==EPOCHS:\n",
      "\n",
      "    # save weights\n",
      "\n",
      "    print(\"\\n...SAVING MODELS TO DISK ... \\n\")\n",
      "\n",
      "    transformer.save_weights(f'./transformer_epoch_{epoch}.h5')\n",
      "\n",
      "    encoder.save_weights(f'./encoder_epoch_{epoch}.h5')\n",
      "\n",
      "#################################################\n",
      "\n",
      "if __name__ == '__main__':\n",
      "\n",
      "    \n",
      "\n",
      "    def get_result(oof_df):\n",
      "\n",
      "        labels = oof_df['score'].values\n",
      "\n",
      "        preds = oof_df['pred'].values\n",
      "\n",
      "        score = get_score(labels, preds)\n",
      "\n",
      "        LOGGER.info(f'Score: {score:<.4f}')\n",
      "\n",
      "    \n",
      "\n",
      "    if CFG.train:\n",
      "\n",
      "        oof_df = pd.DataFrame()\n",
      "\n",
      "        for fold in range(CFG.n_fold):\n",
      "\n",
      "            if fold in CFG.trn_fold:\n",
      "\n",
      "                _oof_df = train_loop(train, fold)\n",
      "\n",
      "                oof_df = pd.concat([oof_df, _oof_df])\n",
      "\n",
      "                LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
      "\n",
      "                get_result(_oof_df)\n",
      "\n",
      "        oof_df = oof_df.reset_index(drop=True)\n",
      "\n",
      "        LOGGER.info(f\"========== CV ==========\")\n",
      "\n",
      "        get_result(oof_df)\n",
      "\n",
      "        oof_df.to_pickle(OUTPUT_DIR+'oof_df.pkl')\n",
      "\n",
      "        \n",
      "\n",
      "    if CFG.wandb:\n",
      "\n",
      "        wandb.finish()\n",
      "\n",
      "#################################################\n",
      "\n",
      "best_metric = -1\n",
      "\n",
      "best_metric_epoch = -1\n",
      "\n",
      "epoch_loss_values = list()\n",
      "\n",
      "auc_metric = ROCAUCMetric()\n",
      "\n",
      "metric_values = list()\n",
      "\n",
      "\n",
      "\n",
      "for epoch in range(epoch_num):\n",
      "\n",
      "    print('-' * 10)\n",
      "\n",
      "    print(f\"epoch {epoch + 1}/{epoch_num}\")\n",
      "\n",
      "    model.train()\n",
      "\n",
      "    epoch_loss = 0\n",
      "\n",
      "    step = 0\n",
      "\n",
      "\n",
      "\n",
      "    for batch_data in train_loader:\n",
      "\n",
      "        step += 1\n",
      "\n",
      "        inputs, labels = batch_data[0].to(device), batch_data[1].to(device)\n",
      "\n",
      "        optimizer.zero_grad()\n",
      "\n",
      "        outputs = model(inputs.float())     ##### \n",
      "\n",
      "        loss = loss_function(outputs, labels)\n",
      "\n",
      "        loss.backward()\n",
      "\n",
      "        optimizer.step()\n",
      "\n",
      "        epoch_loss += loss.item()\n",
      "\n",
      "        print(f\"{step}/{len(train_ds) // train_loader.batch_size}, train_loss: {loss.item():.4f}\")\n",
      "\n",
      "        epoch_len = len(train_ds) // train_loader.batch_size\n",
      "\n",
      "\n",
      "\n",
      "    epoch_loss /= step\n",
      "\n",
      "    epoch_loss_values.append(epoch_loss)\n",
      "\n",
      "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
      "\n",
      "\n",
      "\n",
      "    if (epoch + 1) % val_interval == 0:\n",
      "\n",
      "        model.eval()\n",
      "\n",
      "        with torch.no_grad():\n",
      "\n",
      "            y_pred = torch.tensor([], dtype=torch.float32, device=device)\n",
      "\n",
      "            y = torch.tensor([], dtype=torch.long, device=device)\n",
      "\n",
      "            for val_data in val_loader:\n",
      "\n",
      "                val_images, val_labels = val_data[0].to(device), val_data[1].to(device)\n",
      "\n",
      "                y_pred = torch.cat([y_pred, model(val_images.float())], dim=0)\n",
      "\n",
      "                y = torch.cat([y, val_labels], dim=0)\n",
      "\n",
      "                \n",
      "\n",
      "            y_onehot = [to_onehot(i) for i in y]\n",
      "\n",
      "            y_pred_act = [act(i) for i in y_pred]\n",
      "\n",
      "            auc_metric(y_pred_act, y_onehot)\n",
      "\n",
      "            auc_result = auc_metric.aggregate()\n",
      "\n",
      "            auc_metric.reset()\n",
      "\n",
      "            del y_pred_act, y_onehot\n",
      "\n",
      "            metric_values.append(auc_result)\n",
      "\n",
      "            acc_value = torch.eq(y_pred.argmax(dim=1), y)\n",
      "\n",
      "            acc_metric = acc_value.sum().item() / len(acc_value)\n",
      "\n",
      "            \n",
      "\n",
      "            if acc_metric > best_metric:\n",
      "\n",
      "                best_metric = acc_metric\n",
      "\n",
      "                best_metric_epoch = epoch + 1\n",
      "\n",
      "                torch.save(model.state_dict(), 'best_metric_model.pth')\n",
      "\n",
      "                print('saved new best metric model')\n",
      "\n",
      "                \n",
      "\n",
      "            print(f\"current epoch: {epoch + 1} current AUC: {auc_result:.4f}\"\n",
      "\n",
      "                  f\" current accuracy: {acc_metric:.4f} best AUC: {best_metric:.4f}\"\n",
      "\n",
      "                  f\" at epoch: {best_metric_epoch}\")\n",
      "\n",
      "            \n",
      "\n",
      "print(f\"train completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")\n",
      "\n",
      "\n",
      "#################################################\n",
      "\n",
      "%%time\n",
      "\n",
      "\n",
      "\n",
      "training_args = TrainingArguments(\n",
      "\n",
      "    output_dir=\"./\",\n",
      "\n",
      "    num_train_epochs=EPOCHS,\n",
      "\n",
      "    per_device_train_batch_size=TRAIN_BATCHSIZE,\n",
      "\n",
      "    per_device_eval_batch_size=TRAIN_BATCHSIZE,\n",
      "\n",
      "    gradient_accumulation_steps=BATCH_UPDATE,\n",
      "\n",
      "    evaluation_strategy=\"epoch\",\n",
      "\n",
      "    save_strategy = 'epoch',\n",
      "\n",
      "    fp16=True,\n",
      "\n",
      "    fp16_opt_level=APEX_OPT_LEVEL,\n",
      "\n",
      "    warmup_steps=WARMUP_STEPS,    \n",
      "\n",
      "    learning_rate=LR,\n",
      "\n",
      "    adam_epsilon=EPS,\n",
      "\n",
      "    weight_decay=0.01,        \n",
      "\n",
      "    save_total_limit=1,\n",
      "\n",
      "    load_best_model_at_end=True,\n",
      "\n",
      "    report_to = None,\n",
      "\n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "#---------------------------------------------------#\n",
      "\n",
      "trainer = Trainer(\n",
      "\n",
      "    model=model,\n",
      "\n",
      "    args=training_args,    \n",
      "\n",
      "    train_dataset=train_dataset,\n",
      "\n",
      "    eval_dataset=val_dataset,\n",
      "\n",
      "    tokenizer=tokenizer\n",
      "\n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "#---------------------------------------------------#\n",
      "\n",
      "trainer.train()\n",
      "\n",
      "trainer.save_model()    \n",
      "\n",
      "#################################################\n",
      "\n",
      "if __name__ == '__main__':\n",
      "\n",
      "    \n",
      "\n",
      "    def get_result(oof_df):\n",
      "\n",
      "        labels = oof_df['score'].values\n",
      "\n",
      "        preds = oof_df['pred'].values\n",
      "\n",
      "        score = get_score(labels, preds)\n",
      "\n",
      "        LOGGER.info(f'Score: {score:<.4f}')\n",
      "\n",
      "    \n",
      "\n",
      "    if CFG.train:\n",
      "\n",
      "        oof_df = pd.DataFrame()\n",
      "\n",
      "        for fold in range(CFG.n_fold):\n",
      "\n",
      "            if fold in CFG.trn_fold:\n",
      "\n",
      "                _oof_df = train_loop(train, fold)\n",
      "\n",
      "                oof_df = pd.concat([oof_df, _oof_df])\n",
      "\n",
      "                LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
      "\n",
      "                get_result(_oof_df)\n",
      "\n",
      "        oof_df = oof_df.reset_index(drop=True)\n",
      "\n",
      "        LOGGER.info(f\"========== CV ==========\")\n",
      "\n",
      "        get_result(oof_df)\n",
      "\n",
      "        oof_df.to_pickle(OUTPUT_DIR+'oof_df.pkl')\n",
      "\n",
      "        \n",
      "\n",
      "    if CFG.wandb:\n",
      "\n",
      "        wandb.finish()\n",
      "\n",
      "#################################################\n",
      "\n",
      "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3) # Callback for earlystopping\n",
      "\n",
      "\n",
      "\n",
      "model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
      "\n",
      "\n",
      "\n",
      "epochs=20\n",
      "\n",
      "history = model.fit(train_images, y_train, batch_size=32,  epochs=epochs, validation_data=(test_images, y_test), callbacks=[callback])\n",
      "\n",
      "\n",
      "#################################################\n",
      "\n",
      "callback = tf.keras.callbacks.TensorBoard(\n",
      "\n",
      "    log_dir='logs', histogram_freq=0, write_graph=True,\n",
      "\n",
      "    write_images=False, update_freq='epoch', profile_batch=2,\n",
      "\n",
      "    embeddings_freq=0, embeddings_metadata=None ) # Callback for TensorBoard\n",
      "\n",
      "\n",
      "\n",
      "model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
      "\n",
      "\n",
      "\n",
      "history = model.fit(train_images, y_train, batch_size=32,  epochs=epochs, validation_data=(test_images, y_test), callbacks=[callback])\n",
      "\n",
      "#################################################\n",
      "\n",
      "# list with predicted InChI's\n",
      "\n",
      "predictions_inchi = []\n",
      "\n",
      "# List with image id's\n",
      "\n",
      "predictions_img_ids = []\n",
      "\n",
      "# Distributed test set, needed for TPU\n",
      "\n",
      "test_dist_dataset = strategy.experimental_distribute_dataset(test_dataset)\n",
      "\n",
      "\n",
      "\n",
      "# Prediction Loop\n",
      "\n",
      "for step, (per_replica_imgs, per_repliac_img_ids) in tqdm(enumerate(test_dist_dataset), total=N_TEST_STEPS):\n",
      "\n",
      "    # make test step and get predictions\n",
      "\n",
      "    preds = distributed_test_step(per_replica_imgs)\n",
      "\n",
      "    # get image ids\n",
      "\n",
      "    img_ids = strategy.gather(per_repliac_img_ids, axis=0)\n",
      "\n",
      "    \n",
      "\n",
      "    # decode integer encoded predictions to characters and add to InChI's prediction list\n",
      "\n",
      "    predictions_inchi += [int2char(p) for p in preds.numpy()]\n",
      "\n",
      "    # add image id's to list\n",
      "\n",
      "    predictions_img_ids += [e.decode() for e in img_ids.numpy()]\n",
      "\n",
      "#################################################\n",
      "\n",
      "best_metric = -1\n",
      "\n",
      "best_metric_epoch = -1\n",
      "\n",
      "epoch_loss_values = list()\n",
      "\n",
      "auc_metric = ROCAUCMetric()\n",
      "\n",
      "metric_values = list()\n",
      "\n",
      "\n",
      "\n",
      "for epoch in range(epoch_num):\n",
      "\n",
      "    print('-' * 10)\n",
      "\n",
      "    print(f\"epoch {epoch + 1}/{epoch_num}\")\n",
      "\n",
      "    model.train()\n",
      "\n",
      "    epoch_loss = 0\n",
      "\n",
      "    step = 0\n",
      "\n",
      "\n",
      "\n",
      "    for batch_data in train_loader:\n",
      "\n",
      "        step += 1\n",
      "\n",
      "        inputs, labels = batch_data[0].to(device), batch_data[1].to(device)\n",
      "\n",
      "        optimizer.zero_grad()\n",
      "\n",
      "        outputs = model(inputs.float())     ##### \n",
      "\n",
      "        loss = loss_function(outputs, labels)\n",
      "\n",
      "        loss.backward()\n",
      "\n",
      "        optimizer.step()\n",
      "\n",
      "        epoch_loss += loss.item()\n",
      "\n",
      "        print(f\"{step}/{len(train_ds) // train_loader.batch_size}, train_loss: {loss.item():.4f}\")\n",
      "\n",
      "        epoch_len = len(train_ds) // train_loader.batch_size\n",
      "\n",
      "\n",
      "\n",
      "    epoch_loss /= step\n",
      "\n",
      "    epoch_loss_values.append(epoch_loss)\n",
      "\n",
      "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
      "\n",
      "\n",
      "\n",
      "    if (epoch + 1) % val_interval == 0:\n",
      "\n",
      "        model.eval()\n",
      "\n",
      "        with torch.no_grad():\n",
      "\n",
      "            y_pred = torch.tensor([], dtype=torch.float32, device=device)\n",
      "\n",
      "            y = torch.tensor([], dtype=torch.long, device=device)\n",
      "\n",
      "            for val_data in val_loader:\n",
      "\n",
      "                val_images, val_labels = val_data[0].to(device), val_data[1].to(device)\n",
      "\n",
      "                y_pred = torch.cat([y_pred, model(val_images.float())], dim=0)\n",
      "\n",
      "                y = torch.cat([y, val_labels], dim=0)\n",
      "\n",
      "                \n",
      "\n",
      "            y_onehot = [to_onehot(i) for i in y]\n",
      "\n",
      "            y_pred_act = [act(i) for i in y_pred]\n",
      "\n",
      "            auc_metric(y_pred_act, y_onehot)\n",
      "\n",
      "            auc_result = auc_metric.aggregate()\n",
      "\n",
      "            auc_metric.reset()\n",
      "\n",
      "            del y_pred_act, y_onehot\n",
      "\n",
      "            metric_values.append(auc_result)\n",
      "\n",
      "            acc_value = torch.eq(y_pred.argmax(dim=1), y)\n",
      "\n",
      "            acc_metric = acc_value.sum().item() / len(acc_value)\n",
      "\n",
      "            \n",
      "\n",
      "            if acc_metric > best_metric:\n",
      "\n",
      "                best_metric = acc_metric\n",
      "\n",
      "                best_metric_epoch = epoch + 1\n",
      "\n",
      "                torch.save(model.state_dict(), 'best_metric_model.pth')\n",
      "\n",
      "                print('saved new best metric model')\n",
      "\n",
      "                \n",
      "\n",
      "            print(f\"current epoch: {epoch + 1} current AUC: {auc_result:.4f}\"\n",
      "\n",
      "                  f\" current accuracy: {acc_metric:.4f} best AUC: {best_metric:.4f}\"\n",
      "\n",
      "                  f\" at epoch: {best_metric_epoch}\")\n",
      "\n",
      "            \n",
      "\n",
      "print(f\"train completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")\n",
      "\n",
      "\n",
      "#################################################\n",
      "\n",
      "trainer.train()\n",
      "\n",
      "wandb.finish()\n",
      "\n",
      "#################################################\n",
      "\n",
      "model_name_prefix = datetime.datetime.now().strftime('%m%d%H%M%S')\n",
      "\n",
      "\n",
      "\n",
      "for cnt in range(0, na_cnt_max):  # uso cnt+1\n",
      "\n",
      "    print(\"=\"*10, \"na_cnt {}/{}\".format(cnt+1, na_cnt_max), \"=\"*10)\n",
      "\n",
      "    result_f4data = copy.deepcopy(f4data)\n",
      "\n",
      "    for col in na_col_list:\n",
      "\n",
      "        print(\"=\"*10, col, \"=\"*10)\n",
      "\n",
      "        # split data\n",
      "\n",
      "        # train cnt == 0 then test cnt == 1\n",
      "\n",
      "        _, no_na_index = na_no_na_index_of(col, 0)  # select non na records.\n",
      "\n",
      "        train = f4data.loc[no_na_index]\n",
      "\n",
      "        na_index, _ = na_no_na_index_of(col, cnt+1)\n",
      "\n",
      "        if len(na_index) == 0:\n",
      "\n",
      "            break\n",
      "\n",
      "        test = f4data.loc[na_index]\n",
      "\n",
      "        X = train.drop(col, axis=1)\n",
      "\n",
      "        y = train[col]\n",
      "\n",
      "        X_test = test.drop(col, axis=1)\n",
      "\n",
      "        X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, random_state=42)\n",
      "\n",
      "\n",
      "\n",
      "        # data module\n",
      "\n",
      "        batch_size = min(CFG.max_batch_size, (len(X_train)+100-1)//100)  # len(X) == batch then raise errer.\n",
      "\n",
      "        print(\"batch_size :{}\".format(batch_size))\n",
      "\n",
      "        dm = DataModule(X_train, y_train, X_valid, y_valid, X_test, cnt, batch_size)\n",
      "\n",
      "\n",
      "\n",
      "        # create model\n",
      "\n",
      "        cur_model_name = \"model\" + model_name_prefix+\"_\" + col+ \"_\" + str(cnt)\n",
      "\n",
      "        dirpath = \"./model/\"\n",
      "\n",
      "        dnn = DNN(X_train.shape[1])\n",
      "\n",
      "        model = NNModel(dnn)\n",
      "\n",
      "\n",
      "\n",
      "        # train\n",
      "\n",
      "        logger = WandbLogger()\n",
      "\n",
      "        logger.log_hyperparams(CFG.__dict__)\n",
      "\n",
      "        callbacks = [\n",
      "\n",
      "                    pl.callbacks.EarlyStopping('valid_avg_loss', patience=10),  # validation_epoch_endの戻値が10ターン改善がなかったら打ち止め\n",
      "\n",
      "                    pl.callbacks.ModelCheckpoint(dirpath=\"./model/\", filename=cur_model_name, save_top_k=1, monitor=\"valid_avg_loss\", save_weights_only=False),  # model保存の設定\n",
      "\n",
      "                    pl.callbacks.LearningRateMonitor(),  # ログに学習率を吐き出す設定\n",
      "\n",
      "        ]\n",
      "\n",
      "        trainer = pl.Trainer(accelerator=\"auto\", devices=\"auto\", max_epochs=CFG.max_epochs, logger=logger, callbacks=callbacks, enable_progress_bar=False)\n",
      "\n",
      "        trainer.fit(model, datamodule=dm)\n",
      "\n",
      "        wandb.finish()\n",
      "\n",
      "\n",
      "\n",
      "        # load_best_model\n",
      "\n",
      "        checkpoint_path = glob.glob(dirpath+cur_model_name+\"*.ckpt\")[0]\n",
      "\n",
      "        model.load_from_checkpoint(checkpoint_path, model=dnn)\n",
      "\n",
      "        checkpoint_path_of[cur_model_name] = checkpoint_path\n",
      "\n",
      "\n",
      "\n",
      "        # predict\n",
      "\n",
      "        dm = DataModule(X_train, y_train, X_valid, y_valid, X_test, cnt, batch_size)\n",
      "\n",
      "        results = trainer.predict(model=model, datamodule=dm)\n",
      "\n",
      "        preds = []\n",
      "\n",
      "        for batch in results:\n",
      "\n",
      "            preds.append(batch)\n",
      "\n",
      "        outputs = torch.cat(preds, dim=0)\n",
      "\n",
      "\n",
      "\n",
      "        # write result\n",
      "\n",
      "        result_f4data.loc[na_index, col] = outputs.tolist()\n",
      "\n",
      "        display(result_f4data.loc[na_index, col].head())\n",
      "\n",
      "\n",
      "\n",
      "        torch.cuda.empty_cache()\n",
      "\n",
      "        gc.collect()\n",
      "\n",
      "    f4data = result_f4data\n",
      "\n",
      "    f4data.to_pickle(\"f4data_{}.pkl\".format(cnt))\n",
      "\n",
      "\n",
      "#################################################\n",
      "\n",
      "# Train the model, each epoch takes just ~23 minutes!\n",
      "\n",
      "history = model.fit(\n",
      "\n",
      "    train_dataset,\n",
      "\n",
      "    steps_per_epoch = STEPS_PER_EPOCH,\n",
      "\n",
      "    epochs = EPOCHS,\n",
      "\n",
      "    verbose = 2,\n",
      "\n",
      "    callbacks = [\n",
      "\n",
      "        lr_callback,\n",
      "\n",
      "        model_checkpoint_callback,\n",
      "\n",
      "    ],\n",
      "\n",
      ")\n",
      "\n",
      "#################################################\n",
      "\n",
      "epochs = 20\n",
      "\n",
      "batch_size = 32\n",
      "\n",
      "steps = len(train) // batch_size\n",
      "\n",
      "\n",
      "\n",
      "for i in range(epochs):\n",
      "\n",
      "    # create data generator\n",
      "\n",
      "    generator = data_generator(train, mapping, features, tokenizer, max_length, vocab_size, batch_size)\n",
      "\n",
      "    # fit for one epoch\n",
      "\n",
      "    model.fit(generator, epochs=1, steps_per_epoch=steps, verbose=1)\n",
      "\n",
      "#################################################\n",
      "\n",
      "best_metric = -1\n",
      "\n",
      "best_metric_epoch = -1\n",
      "\n",
      "epoch_loss_values = list()\n",
      "\n",
      "auc_metric = ROCAUCMetric()\n",
      "\n",
      "metric_values = list()\n",
      "\n",
      "\n",
      "\n",
      "for epoch in range(epoch_num):\n",
      "\n",
      "    print('-' * 10)\n",
      "\n",
      "    print(f\"epoch {epoch + 1}/{epoch_num}\")\n",
      "\n",
      "    model.train()\n",
      "\n",
      "    epoch_loss = 0\n",
      "\n",
      "    step = 0\n",
      "\n",
      "\n",
      "\n",
      "    for batch_data in train_loader:\n",
      "\n",
      "        step += 1\n",
      "\n",
      "        inputs, labels = batch_data[0].to(device), batch_data[1].to(device)\n",
      "\n",
      "        optimizer.zero_grad()\n",
      "\n",
      "        outputs = model(inputs.float())     ##### .float()\n",
      "\n",
      "        loss = loss_function(outputs, labels)\n",
      "\n",
      "        loss.backward()\n",
      "\n",
      "        optimizer.step()\n",
      "\n",
      "        epoch_loss += loss.item()\n",
      "\n",
      "        print(f\"{step}/{len(train_ds) // train_loader.batch_size}, train_loss: {loss.item():.4f}\")\n",
      "\n",
      "        epoch_len = len(train_ds) // train_loader.batch_size\n",
      "\n",
      "\n",
      "\n",
      "    epoch_loss /= step\n",
      "\n",
      "    epoch_loss_values.append(epoch_loss)\n",
      "\n",
      "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
      "\n",
      "\n",
      "\n",
      "    if (epoch + 1) % val_interval == 0:\n",
      "\n",
      "        model.eval()\n",
      "\n",
      "        with torch.no_grad():\n",
      "\n",
      "            y_pred = torch.tensor([], dtype=torch.float32, device=device)\n",
      "\n",
      "            y = torch.tensor([], dtype=torch.long, device=device)\n",
      "\n",
      "            for val_data in val_loader:\n",
      "\n",
      "                val_images, val_labels = val_data[0].to(device), val_data[1].to(device)\n",
      "\n",
      "                y_pred = torch.cat([y_pred, model(val_images)], dim=0)\n",
      "\n",
      "                y = torch.cat([y, val_labels], dim=0)\n",
      "\n",
      "                \n",
      "\n",
      "            y_onehot = [to_onehot(i) for i in y]\n",
      "\n",
      "            y_pred_act = [act(i) for i in y_pred]\n",
      "\n",
      "            auc_metric(y_pred_act, y_onehot)\n",
      "\n",
      "            auc_result = auc_metric.aggregate()\n",
      "\n",
      "            auc_metric.reset()\n",
      "\n",
      "            del y_pred_act, y_onehot\n",
      "\n",
      "            metric_values.append(auc_result)\n",
      "\n",
      "            acc_value = torch.eq(y_pred.argmax(dim=1), y)\n",
      "\n",
      "            acc_metric = acc_value.sum().item() / len(acc_value)\n",
      "\n",
      "            \n",
      "\n",
      "            if acc_metric > best_metric:\n",
      "\n",
      "                best_metric = acc_metric\n",
      "\n",
      "                best_metric_epoch = epoch + 1\n",
      "\n",
      "                torch.save(model.state_dict(), 'best_metric_model.pth')\n",
      "\n",
      "                print('saved new best metric model')\n",
      "\n",
      "                \n",
      "\n",
      "            print(f\"current epoch: {epoch + 1} current AUC: {auc_result:.4f}\"\n",
      "\n",
      "                  f\" current accuracy: {acc_metric:.4f} best AUC: {best_metric:.4f}\"\n",
      "\n",
      "                  f\" at epoch: {best_metric_epoch}\")\n",
      "\n",
      "            \n",
      "\n",
      "print(f\"train completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")\n",
      "\n",
      "\n",
      "#################################################\n",
      "\n",
      "model = SegmentationModel()\n",
      "\n",
      "earlystopping_callback = pl.callbacks.EarlyStopping(monitor='val_metric', mode='max')\n",
      "\n",
      "checkpoint_callback = pl.callbacks.ModelCheckpoint(dirpath='/kaggle/working', filename='model.ckpt', monitor='val_metric')\n",
      "\n",
      "trainer = pl.Trainer(accelerator=\"gpu\", precision=16,default_root_dir=\"/kaggle/working\", max_epochs=7, \\\n",
      "\n",
      "                     callbacks=[earlystopping_callback, checkpoint_callback])\n",
      "\n",
      "trainer.fit(model)\n",
      "\n",
      "#################################################\n",
      "\n",
      "if __name__ == '__main__':\n",
      "\n",
      "    \n",
      "\n",
      "    def get_result(oof_df):\n",
      "\n",
      "        labels = oof_df['score'].values\n",
      "\n",
      "        preds = oof_df['pred'].values\n",
      "\n",
      "        score = get_score(labels, preds)\n",
      "\n",
      "        LOGGER.info(f'Score: {score:<.4f}')\n",
      "\n",
      "    \n",
      "\n",
      "    if CFG.train:\n",
      "\n",
      "        oof_df = pd.DataFrame()\n",
      "\n",
      "        for fold in range(CFG.n_fold):\n",
      "\n",
      "            if fold in CFG.trn_fold:\n",
      "\n",
      "                _oof_df = train_loop(train, fold)\n",
      "\n",
      "                oof_df = pd.concat([oof_df, _oof_df])\n",
      "\n",
      "                LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
      "\n",
      "                get_result(_oof_df)\n",
      "\n",
      "        oof_df = oof_df.reset_index(drop=True)\n",
      "\n",
      "        LOGGER.info(f\"========== CV ==========\")\n",
      "\n",
      "        get_result(oof_df)\n",
      "\n",
      "        oof_df.to_pickle(OUTPUT_DIR+'oof_df.pkl')\n",
      "\n",
      "        \n",
      "\n",
      "    if CFG.wandb:\n",
      "\n",
      "        wandb.finish()\n",
      "\n",
      "#################################################\n",
      "\n",
      "if __name__ == '__main__':\n",
      "\n",
      "    \n",
      "\n",
      "    def get_result(oof_df):\n",
      "\n",
      "        labels = oof_df['discourse_effectiveness'].values\n",
      "\n",
      "        preds = oof_df[['pred_0','pred_1','pred_2']].values\n",
      "\n",
      "        score = get_score(labels, preds)\n",
      "\n",
      "        LOGGER.info(f'Score: {score:<.4f}')\n",
      "\n",
      "    \n",
      "\n",
      "    oof_df = pd.DataFrame()\n",
      "\n",
      "    for fold in range(CFG.n_fold):\n",
      "\n",
      "        if fold in CFG.trn_fold:\n",
      "\n",
      "            _oof_df = train_loop(train, fold)\n",
      "\n",
      "            oof_df = pd.concat([oof_df, _oof_df])\n",
      "\n",
      "            LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
      "\n",
      "            get_result(_oof_df)\n",
      "\n",
      "    oof_df = oof_df.reset_index(drop=True)\n",
      "\n",
      "    LOGGER.info(f\"========== CV ==========\")\n",
      "\n",
      "    get_result(oof_df)\n",
      "\n",
      "    oof_df.to_pickle(OUTPUT_DIR+'oof_df.pkl')\n",
      "\n",
      "        \n",
      "\n",
      "    if CFG.wandb:\n",
      "\n",
      "        wandb.finish()\n",
      "\n",
      "#################################################\n",
      "\n",
      "trainer.fit(lit_model, train_dataloaders=train_loader, val_dataloaders=valid_loader)\n",
      "\n",
      "#################################################\n",
      "\n",
      "for fold in range(params['num_fold']):\n",
      "\n",
      "    print(''.join(['#']*51))\n",
      "\n",
      "    print(f\"{''.join(['=']*15)} TRAINING FOLD: {fold+1}/{train_df['kfold'].nunique()} {''.join(['=']*15)}\")\n",
      "\n",
      "    # Data Split to train and Validation\n",
      "\n",
      "    train = train_df[train_df['kfold'] != fold]\n",
      "\n",
      "    valid = train_df[train_df['kfold'] == fold]\n",
      "\n",
      "    \n",
      "\n",
      "    X_train = train['image_path']\n",
      "\n",
      "    y_train = train['label_enc']\n",
      "\n",
      "    X_valid = valid['image_path']\n",
      "\n",
      "    y_valid = valid['label_enc']\n",
      "\n",
      "    \n",
      "\n",
      "    # Pytorch Dataset Creation\n",
      "\n",
      "    train_dataset = PaddyDataset(\n",
      "\n",
      "        images_filepaths=X_train.values,\n",
      "\n",
      "        targets=y_train.values,\n",
      "\n",
      "        transform=get_train_transforms()\n",
      "\n",
      "    )\n",
      "\n",
      "\n",
      "\n",
      "    valid_dataset = PaddyDataset(\n",
      "\n",
      "        images_filepaths=X_valid.values,\n",
      "\n",
      "        targets=y_valid.values,\n",
      "\n",
      "        transform=get_valid_transforms()\n",
      "\n",
      "    )\n",
      "\n",
      "    \n",
      "\n",
      "    # Pytorch Dataloader creation\n",
      "\n",
      "    train_loader = DataLoader(\n",
      "\n",
      "        train_dataset, batch_size=params['batch_size'], shuffle=True,\n",
      "\n",
      "        num_workers=params['num_workers'], pin_memory=True\n",
      "\n",
      "        )\n",
      "\n",
      "\n",
      "\n",
      "    val_loader = DataLoader(\n",
      "\n",
      "        valid_dataset, batch_size=params['batch_size'], shuffle=False,\n",
      "\n",
      "        num_workers=params['num_workers'], pin_memory=True\n",
      "\n",
      "        )\n",
      "\n",
      "    \n",
      "\n",
      "    # Model, cost function and optimizer instancing\n",
      "\n",
      "    model = PaddyNet()\n",
      "\n",
      "    model = model.to(params['device'])\n",
      "\n",
      "    criterion = nn.CrossEntropyLoss()\n",
      "\n",
      "    optimizer = torch.optim.AdamW(model.parameters(), lr=params['lr'],\n",
      "\n",
      "                                  weight_decay=params['weight_decay'],\n",
      "\n",
      "                                  amsgrad=False)\n",
      "\n",
      "    scheduler = get_scheduler(optimizer)\n",
      "\n",
      "\n",
      "\n",
      "    if params['fp16']:\n",
      "\n",
      "        scaler = torch.cuda.amp.GradScaler()\n",
      "\n",
      "    else:\n",
      "\n",
      "        scaler = None\n",
      "\n",
      "    \n",
      "\n",
      "    # Training and Validation Loop\n",
      "\n",
      "    best_accracy = -np.inf\n",
      "\n",
      "    best_epoch = np.inf\n",
      "\n",
      "    best_model_name = None\n",
      "\n",
      "    for epoch in range(1, params['epochs'] + 1):\n",
      "\n",
      "        train_fn(train_loader, model, criterion, optimizer, epoch, params, scheduler, scaler)\n",
      "\n",
      "        predictions, valid_targets = validate_fn(val_loader, model, criterion, epoch, params)\n",
      "\n",
      "        accuracy = round(accuracy_score(valid_targets, predictions), 3)\n",
      "\n",
      "        if accuracy > best_accracy:\n",
      "\n",
      "            best_accracy = accuracy\n",
      "\n",
      "            best_epoch = epoch\n",
      "\n",
      "            if best_model_name is not None:\n",
      "\n",
      "                os.remove(best_model_name)\n",
      "\n",
      "            torch.save(model.state_dict(), f\"{params['model']}_{epoch}_epoch_f{fold+1}_{accuracy}_accuracy.pth\")\n",
      "\n",
      "            best_model_name = f\"{params['model']}_{epoch}_epoch_f{fold+1}_{accuracy}_accuracy.pth\"\n",
      "\n",
      "\n",
      "\n",
      "    # Print summary of this fold\n",
      "\n",
      "    print('')\n",
      "\n",
      "    print(f'The best Accuracy: {best_accracy} for fold {fold+1} was achieved on epoch: {best_epoch}.')\n",
      "\n",
      "    print(f'The Best saved model is: {best_model_name}')\n",
      "\n",
      "    best_models_of_each_fold.append(best_model_name)\n",
      "\n",
      "    accuracy_tracker.append(best_accracy)\n",
      "\n",
      "    print(''.join(['#']*50))\n",
      "\n",
      "    del model\n",
      "\n",
      "    gc.collect()\n",
      "\n",
      "    torch.cuda.empty_cache()\n",
      "\n",
      "\n",
      "\n",
      "print('')\n",
      "\n",
      "print(f'Average Accuracy of all folds: {round(np.mean(accuracy_tracker), 4)}')\n",
      "\n",
      "#################################################\n",
      "\n",
      "best_metric = -1\n",
      "\n",
      "best_metric_epoch = -1\n",
      "\n",
      "epoch_loss_values = list()\n",
      "\n",
      "auc_metric = ROCAUCMetric()\n",
      "\n",
      "metric_values = list()\n",
      "\n",
      "\n",
      "\n",
      "for epoch in range(epoch_num):\n",
      "\n",
      "    print('-' * 10)\n",
      "\n",
      "    print(f\"epoch {epoch + 1}/{epoch_num}\")\n",
      "\n",
      "    model.train()\n",
      "\n",
      "    epoch_loss = 0\n",
      "\n",
      "    step = 0\n",
      "\n",
      "\n",
      "\n",
      "    for batch_data in train_loader:\n",
      "\n",
      "        step += 1\n",
      "\n",
      "        inputs, labels = batch_data[0].to(device), batch_data[1].to(device)\n",
      "\n",
      "        optimizer.zero_grad()\n",
      "\n",
      "        outputs = model(inputs.float())     ##### .float()\n",
      "\n",
      "        loss = loss_function(outputs, labels)\n",
      "\n",
      "        loss.backward()\n",
      "\n",
      "        optimizer.step()\n",
      "\n",
      "        epoch_loss += loss.item()\n",
      "\n",
      "        print(f\"{step}/{len(train_ds) // train_loader.batch_size}, train_loss: {loss.item():.4f}\")\n",
      "\n",
      "        epoch_len = len(train_ds) // train_loader.batch_size\n",
      "\n",
      "\n",
      "\n",
      "    epoch_loss /= step\n",
      "\n",
      "    epoch_loss_values.append(epoch_loss)\n",
      "\n",
      "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
      "\n",
      "\n",
      "\n",
      "    if (epoch + 1) % val_interval == 0:\n",
      "\n",
      "        model.eval()\n",
      "\n",
      "        with torch.no_grad():\n",
      "\n",
      "            y_pred = torch.tensor([], dtype=torch.float32, device=device)\n",
      "\n",
      "            y = torch.tensor([], dtype=torch.long, device=device)\n",
      "\n",
      "            for val_data in val_loader:\n",
      "\n",
      "                val_images, val_labels = val_data[0].to(device), val_data[1].to(device)\n",
      "\n",
      "                y_pred = torch.cat([y_pred, model(val_images)], dim=0)\n",
      "\n",
      "                y = torch.cat([y, val_labels], dim=0)\n",
      "\n",
      "                \n",
      "\n",
      "            y_onehot = [to_onehot(i) for i in y]\n",
      "\n",
      "            y_pred_act = [act(i) for i in y_pred]\n",
      "\n",
      "            auc_metric(y_pred_act, y_onehot)\n",
      "\n",
      "            auc_result = auc_metric.aggregate()\n",
      "\n",
      "            auc_metric.reset()\n",
      "\n",
      "            del y_pred_act, y_onehot\n",
      "\n",
      "            metric_values.append(auc_result)\n",
      "\n",
      "            acc_value = torch.eq(y_pred.argmax(dim=1), y)\n",
      "\n",
      "            acc_metric = acc_value.sum().item() / len(acc_value)\n",
      "\n",
      "            \n",
      "\n",
      "            if acc_metric > best_metric:\n",
      "\n",
      "                best_metric = acc_metric\n",
      "\n",
      "                best_metric_epoch = epoch + 1\n",
      "\n",
      "                torch.save(model.state_dict(), 'best_metric_model.pth')\n",
      "\n",
      "                print('saved new best metric model')\n",
      "\n",
      "                \n",
      "\n",
      "            print(f\"current epoch: {epoch + 1} current AUC: {auc_result:.4f}\"\n",
      "\n",
      "                  f\" current accuracy: {acc_metric:.4f} best AUC: {best_metric:.4f}\"\n",
      "\n",
      "                  f\" at epoch: {best_metric_epoch}\")\n",
      "\n",
      "            \n",
      "\n",
      "print(f\"train completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")\n",
      "\n",
      "\n",
      "#################################################\n",
      "\n",
      "if __name__ == '__main__':\n",
      "\n",
      "    \n",
      "\n",
      "    def get_result(oof_df):\n",
      "\n",
      "        labels = oof_df['score'].values\n",
      "\n",
      "        preds = oof_df['pred'].values\n",
      "\n",
      "        score = get_score(labels, preds)\n",
      "\n",
      "        LOGGER.info(f'Score: {score:<.4f}')\n",
      "\n",
      "    \n",
      "\n",
      "    if CFG.train:\n",
      "\n",
      "        oof_df = pd.DataFrame()\n",
      "\n",
      "        for fold in range(CFG.n_fold):\n",
      "\n",
      "            if fold in CFG.trn_fold:\n",
      "\n",
      "                _oof_df = train_loop(train, fold)\n",
      "\n",
      "                oof_df = pd.concat([oof_df, _oof_df])\n",
      "\n",
      "                LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
      "\n",
      "                get_result(_oof_df)\n",
      "\n",
      "        oof_df = oof_df.reset_index(drop=True)\n",
      "\n",
      "        LOGGER.info(f\"========== CV ==========\")\n",
      "\n",
      "        get_result(oof_df)\n",
      "\n",
      "        oof_df.to_pickle(OUTPUT_DIR+'oof_df.pkl')\n",
      "\n",
      "        \n",
      "\n",
      "    if CFG.wandb:\n",
      "\n",
      "        wandb.finish()\n",
      "\n",
      "#################################################\n",
      "\n",
      "_ = model.fit(\n",
      "\n",
      "    X_test_padded,\n",
      "\n",
      "    y_test1h,\n",
      "\n",
      "    batch_size=32,\n",
      "\n",
      "    epochs=2,\n",
      "\n",
      "    verbose=1,\n",
      "\n",
      "#     validation_data=(X_test_padded, y_test1h),\n",
      "\n",
      "    validation_split=.2\n",
      "\n",
      ")\n",
      "\n",
      "\n",
      "#################################################\n",
      "\n",
      "if __name__ == '__main__':\n",
      "\n",
      "    \n",
      "\n",
      "    def get_result(oof_df):\n",
      "\n",
      "        labels = oof_df['discourse_effectiveness'].values\n",
      "\n",
      "        preds = oof_df[['pred_0','pred_1','pred_2']].values\n",
      "\n",
      "        score = get_score(labels, preds)\n",
      "\n",
      "        LOGGER.info(f'Score: {score:<.4f}')\n",
      "\n",
      "    \n",
      "\n",
      "    oof_df = pd.DataFrame()\n",
      "\n",
      "    for fold in range(CFG.n_fold):\n",
      "\n",
      "        if fold in CFG.trn_fold:\n",
      "\n",
      "            _oof_df = train_loop(train, fold)\n",
      "\n",
      "            oof_df = pd.concat([oof_df, _oof_df])\n",
      "\n",
      "            LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
      "\n",
      "            get_result(_oof_df)\n",
      "\n",
      "    oof_df = oof_df.reset_index(drop=True)\n",
      "\n",
      "    LOGGER.info(f\"========== CV ==========\")\n",
      "\n",
      "    get_result(oof_df)\n",
      "\n",
      "    oof_df.to_pickle(OUTPUT_DIR+'oof_df.pkl')\n",
      "\n",
      "        \n",
      "\n",
      "    if CFG.wandb:\n",
      "\n",
      "        wandb.finish()\n",
      "\n",
      "#################################################\n",
      "\n",
      "dice = Dice_th_pred(np.arange(0.2,0.7,0.01))\n",
      "\n",
      "for fold in range(nfolds):\n",
      "\n",
      "    ds_t = HuBMAPDataset(fold=fold, train=True, tfms=get_aug())\n",
      "\n",
      "    ds_v = HuBMAPDataset(fold=fold, train=False)\n",
      "\n",
      "    data = ImageDataLoaders.from_dsets(ds_t,ds_v,bs=bs,\n",
      "\n",
      "                num_workers=NUM_WORKERS,pin_memory=True).cuda()\n",
      "\n",
      "    model = EffUnet('efficientnet-b5').cuda()\n",
      "\n",
      "    learn = Learner(data, model, loss_func=symmetric_lovasz,\n",
      "\n",
      "                metrics=[Dice_soft(),Dice_th()], \n",
      "\n",
      "                splitter=split_layers).to_fp16(clip=0.5)\n",
      "\n",
      "    \n",
      "\n",
      "    #start with training the head\n",
      "\n",
      "    learn.freeze_to(-1) #doesn't work\n",
      "\n",
      "    for param in learn.opt.param_groups[0]['params']:\n",
      "\n",
      "        param.requires_grad = False\n",
      "\n",
      "    learn.fit_one_cycle(6, lr_max=0.5e-2)\n",
      "\n",
      "\n",
      "\n",
      "    #continue training full model\n",
      "\n",
      "    learn.unfreeze()\n",
      "\n",
      "    learn.fit_one_cycle(32, lr_max=slice(2e-4,2e-3),\n",
      "\n",
      "        cbs=SaveModelCallback(monitor='dice_th',comp=np.greater))\n",
      "\n",
      "    torch.save(learn.model.state_dict(),f'model_{fold}.pth')\n",
      "\n",
      "    \n",
      "\n",
      "    #model evaluation on val and saving the masks\n",
      "\n",
      "    mp = Model_pred(learn.model,learn.dls.loaders[1])\n",
      "\n",
      "    with zipfile.ZipFile('val_masks_tta.zip', 'a') as out:\n",
      "\n",
      "        for p in progress_bar(mp):\n",
      "\n",
      "            dice.accumulate(p[0],p[1])\n",
      "\n",
      "            save_img(p[0],p[2],out)\n",
      "\n",
      "    gc.collect()\n",
      "\n",
      "#################################################\n",
      "\n",
      "%%time\n",
      "\n",
      "\n",
      "\n",
      "train_and_validate(args, model, data_df)\n",
      "\n",
      "# Final - Accuracy: 0.4339, MAP@5: 0.6098\n",
      "\n",
      "#################################################\n",
      "\n",
      "transformers.logging.set_verbosity_error()\n",
      "\n",
      "for fold in range(CFG.n_fold):\n",
      "\n",
      "    print(f'================ Fold: {fold} =================')\n",
      "\n",
      "    \n",
      "\n",
      "    cfg = dict(CFG.__dict__)\n",
      "\n",
      "    del cfg['__dict__'], cfg['__weakref__']\n",
      "\n",
      "    run = wandb.init(\n",
      "\n",
      "        project = 'FeedBack',\n",
      "\n",
      "        config = cfg,\n",
      "\n",
      "        job_type = 'Train',\n",
      "\n",
      "        group = CFG.group,\n",
      "\n",
      "        tags = [CFG.model_name, CFG.wandb_id],\n",
      "\n",
      "        name = f'{CFG.wandb_id}-Fold-{fold}',\n",
      "\n",
      "        anonymous='must'\n",
      "\n",
      "    )\n",
      "\n",
      "    \n",
      "\n",
      "    train_loader, valid_loader = prepare_loaders(fold)\n",
      "\n",
      "    model = FeedbackModel(CFG.model_name)\n",
      "\n",
      "    model.to(CFG.device)\n",
      "\n",
      "\n",
      "\n",
      "    if torch.cuda.is_available():\n",
      "\n",
      "        print(\"[INFO] Using GPU: {}\\n\".format(torch.cuda.get_device_name()))\n",
      "\n",
      "\n",
      "\n",
      "    model.set_optimizer_scheduler(\"Adam8bit\")\n",
      "\n",
      "            \n",
      "\n",
      "    model, history = run_training(model, CFG.device, CFG.epoch, fold, train_loader, valid_loader)\n",
      "\n",
      "    \n",
      "\n",
      "    run.finish()\n",
      "\n",
      "    gc.collect()          \n",
      "\n",
      "#################################################\n",
      "\n",
      "all_preds = []\n",
      "\n",
      "\n",
      "\n",
      "for i in range(N_FOLDS):\n",
      "\n",
      "\n",
      "\n",
      "    print(f'Fold {i} results')\n",
      "\n",
      "    \n",
      "\n",
      "    learn = get_learner(fold_num=i)\n",
      "\n",
      "\n",
      "\n",
      "    learn.fit_one_cycle(5, 2e-5, cbs=[SaveModelCallback(), EarlyStoppingCallback(monitor='petfinder_rmse', comp=np.less, patience=2)]) \n",
      "\n",
      "    \n",
      "\n",
      "    learn.recorder.plot_loss()\n",
      "\n",
      "\n",
      "\n",
      "    learn = learn.to_fp32()\n",
      "\n",
      "    \n",
      "\n",
      "    learn.export(f'model_fold_{i}.pkl')\n",
      "\n",
      "    learn.save(f'model_fold_{i}.pkl')\n",
      "\n",
      "    \n",
      "\n",
      "    dls = ImageDataLoaders.from_df(train_df, #pass in train DataFrame\n",
      "\n",
      "                               valid_pct=0.2, #80-20 train-validation random split\n",
      "\n",
      "                               seed=999, #seed\n",
      "\n",
      "                               fn_col='path', #filename/path is in the second column of the DataFrame\n",
      "\n",
      "                               label_col='norm_score', #label is in the first column of the DataFrame\n",
      "\n",
      "                               y_block=RegressionBlock, #The type of target\n",
      "\n",
      "                               bs=BATCH_SIZE, #pass in batch size\n",
      "\n",
      "                               num_workers=8,\n",
      "\n",
      "                               item_tfms=Resize(224), #pass in item_tfms\n",
      "\n",
      "                               batch_tfms=setup_aug_tfms([Brightness(), Contrast(), Hue(), Saturation()])) \n",
      "\n",
      "    \n",
      "\n",
      "    test_dl = dls.test_dl(test_df)\n",
      "\n",
      "    \n",
      "\n",
      "    preds, _ = learn.tta(dl=test_dl, n=5, beta=0)\n",
      "\n",
      "    \n",
      "\n",
      "    all_preds.append(preds)\n",
      "\n",
      "    \n",
      "\n",
      "    del learn\n",
      "\n",
      "\n",
      "\n",
      "    torch.cuda.empty_cache()\n",
      "\n",
      "\n",
      "\n",
      "    gc.collect()\n",
      "\n",
      "#################################################\n",
      "\n",
      "# # LOAD MODEL\n",
      "\n",
      "# if LOAD_MODEL_FROM:\n",
      "\n",
      "#     model.load_weights(f'{LOAD_MODEL_FROM}/long_v{VER}.h5')\n",
      "\n",
      "    \n",
      "\n",
      "# # OR TRAIN MODEL\n",
      "\n",
      "# else:\n",
      "\n",
      "model.fit(x = [train_tokens[train_idx,], train_attention[train_idx,]],\n",
      "\n",
      "      y = targets[train_idx,],\n",
      "\n",
      "      validation_data = ([train_tokens[valid_idx,], train_attention[valid_idx,]],\n",
      "\n",
      "                         targets[valid_idx,]),\n",
      "\n",
      "      callbacks = [lr_callback],\n",
      "\n",
      "      epochs = EPOCHS,\n",
      "\n",
      "      batch_size = BATCH_SIZE,\n",
      "\n",
      "      verbose = 2)\n",
      "\n",
      "\n",
      "\n",
      "# SAVE MODEL WEIGHTS\n",
      "\n",
      "model.save_weights(f'long_v{VER}.h5')\n",
      "\n",
      "#################################################\n",
      "\n",
      "def train(model, train_loader, val_loader, epochs):\n",
      "\n",
      "    np.random.seed(0)\n",
      "\n",
      "    # Creating optimizer and lr schedulers\n",
      "\n",
      "    param_optimizer = list(model.named_parameters())\n",
      "\n",
      "    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
      "\n",
      "    optimizer_grouped_parameters = [\n",
      "\n",
      "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
      "\n",
      "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
      "\n",
      "    ]\n",
      "\n",
      "\n",
      "\n",
      "    num_train_optimization_steps = int(EPOCHS * len(train_loader) / ACCUMULATE)\n",
      "\n",
      "    optimizer = AdamW(optimizer_grouped_parameters, lr=3e-5,\n",
      "\n",
      "                      correct_bias=False)  # To reproduce BertAdam specific behavior set correct_bias=False\n",
      "\n",
      "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0.05 * num_train_optimization_steps,\n",
      "\n",
      "                                                num_training_steps=num_train_optimization_steps)  # PyTorch scheduler\n",
      "\n",
      "\n",
      "\n",
      "    criterion = torch.nn.L1Loss()\n",
      "\n",
      "    scaler = torch.cuda.amp.GradScaler()\n",
      "\n",
      "\n",
      "\n",
      "    for e in range(epochs):\n",
      "\n",
      "        model.train()\n",
      "\n",
      "        tbar = tqdm(train_loader, file=sys.stdout)\n",
      "\n",
      "        loss_list = []\n",
      "\n",
      "        preds = []\n",
      "\n",
      "        labels = []\n",
      "\n",
      "\n",
      "\n",
      "        for idx, data in enumerate(tbar):\n",
      "\n",
      "            inputs, target = read_data(data)\n",
      "\n",
      "\n",
      "\n",
      "            with torch.cuda.amp.autocast():\n",
      "\n",
      "                pred = model(*inputs)\n",
      "\n",
      "                loss = criterion(pred, target)\n",
      "\n",
      "            scaler.scale(loss).backward()\n",
      "\n",
      "            if idx % ACCUMULATE == 0 or idx == len(tbar) - 1:\n",
      "\n",
      "                scaler.step(optimizer)\n",
      "\n",
      "                scaler.update()\n",
      "\n",
      "                optimizer.zero_grad()\n",
      "\n",
      "                scheduler.step()\n",
      "\n",
      "\n",
      "\n",
      "            loss_list.append(loss.detach().cpu().item())\n",
      "\n",
      "            preds.append(pred.detach().cpu().numpy().ravel())\n",
      "\n",
      "            labels.append(target.detach().cpu().numpy().ravel())\n",
      "\n",
      "\n",
      "\n",
      "            avg_loss = np.round(np.mean(loss_list), 4)\n",
      "\n",
      "\n",
      "\n",
      "            tbar.set_description(f\"Epoch {e + 1} Loss: {avg_loss} lr: {scheduler.get_last_lr()}\")\n",
      "\n",
      "\n",
      "\n",
      "        y_val, y_pred = validate(model, val_loader)\n",
      "\n",
      "        val_df[\"pred\"] = val_df.groupby([\"id\", \"cell_type\"])[\"rank\"].rank(pct=True)\n",
      "\n",
      "        val_df.loc[val_df[\"cell_type\"] == \"markdown\", \"pred\"] = y_pred\n",
      "\n",
      "        y_dummy = val_df.sort_values(\"pred\").groupby('id')['cell_id'].apply(list)\n",
      "\n",
      "        print(\"Preds score\", kendall_tau(df_orders.loc[y_dummy.index], y_dummy))\n",
      "\n",
      "        torch.save(model.state_dict(), \"./model.bin\")\n",
      "\n",
      "\n",
      "\n",
      "    return model, y_pred\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model = MarkdownModel()\n",
      "\n",
      "model = model.cuda()\n",
      "\n",
      "#validate(model,val_loader)\n",
      "\n",
      "model, y_pred = train(model, train_loader, val_loader, epochs=EPOCHS)\n",
      "\n",
      "#################################################\n",
      "\n",
      "for fold in CFG.folds:\n",
      "\n",
      "    print(f'#'*15)\n",
      "\n",
      "    print(f'### Fold: {fold}')\n",
      "\n",
      "    print(f'#'*15)\n",
      "\n",
      "    run = wandb.init(project='uw-maddison-gi-tract', \n",
      "\n",
      "                     config={k:v for k, v in dict(vars(CFG)).items() if '__' not in k},\n",
      "\n",
      "                     anonymous=anonymous,\n",
      "\n",
      "                     name=f\"fold-{fold}|dim-{CFG.img_size[0]}x{CFG.img_size[1]}|model-{CFG.model_name}\",\n",
      "\n",
      "                     group=CFG.comment,\n",
      "\n",
      "                    )\n",
      "\n",
      "    train_loader, valid_loader = prepare_loaders(fold=fold, debug=CFG.debug)\n",
      "\n",
      "    model     = build_model()\n",
      "\n",
      "    optimizer = optim.Adam(model.parameters(), lr=CFG.lr, weight_decay=CFG.wd)\n",
      "\n",
      "    scheduler = fetch_scheduler(optimizer)\n",
      "\n",
      "    model, history = run_training(model, optimizer, scheduler,\n",
      "\n",
      "                                  device=CFG.device,\n",
      "\n",
      "                                  num_epochs=CFG.epochs)\n",
      "\n",
      "    run.finish()\n",
      "\n",
      "    display(ipd.IFrame(run.url, width=1000, height=720))\n",
      "\n",
      "#################################################\n",
      "\n",
      "if __name__ == '__main__':\n",
      "\n",
      "    \n",
      "\n",
      "    def get_result(oof_df):\n",
      "\n",
      "        labels = oof_df['discourse_effectiveness'].values\n",
      "\n",
      "        preds = oof_df[['pred_0','pred_1','pred_2']].values\n",
      "\n",
      "        score = get_score(labels, preds)\n",
      "\n",
      "        LOGGER.info(f'Score: {score:<.4f}')\n",
      "\n",
      "    \n",
      "\n",
      "    oof_df = pd.DataFrame()\n",
      "\n",
      "    for fold in range(CFG.n_fold):\n",
      "\n",
      "        if fold in CFG.trn_fold:\n",
      "\n",
      "            _oof_df = train_loop(train, fold)\n",
      "\n",
      "            oof_df = pd.concat([oof_df, _oof_df])\n",
      "\n",
      "            LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
      "\n",
      "            get_result(_oof_df)\n",
      "\n",
      "    oof_df = oof_df.reset_index(drop=True)\n",
      "\n",
      "    LOGGER.info(f\"========== CV ==========\")\n",
      "\n",
      "    get_result(oof_df)\n",
      "\n",
      "    oof_df.to_pickle(OUTPUT_DIR+'oof_df.pkl')\n",
      "\n",
      "        \n",
      "\n",
      "    if CFG.wandb:\n",
      "\n",
      "        wandb.finish()\n",
      "\n",
      "#################################################\n",
      "\n",
      "best_loss = np.inf\n",
      "\n",
      "\n",
      "\n",
      "for epoch in range(CFG.epochs):\n",
      "\n",
      "\n",
      "\n",
      "    start_time = time.time()\n",
      "\n",
      "\n",
      "\n",
      "    # train\n",
      "\n",
      "    avg_loss = train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device)\n",
      "\n",
      "\n",
      "\n",
      "    # eval\n",
      "\n",
      "    avg_val_loss, predictions = valid_fn(valid_loader, model, criterion, device)\n",
      "\n",
      "\n",
      "\n",
      "    elapsed = time.time() - start_time\n",
      "\n",
      "\n",
      "\n",
      "    print(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n",
      "\n",
      "\n",
      "\n",
      "    if best_loss > avg_val_loss:\n",
      "\n",
      "        best_loss = avg_val_loss\n",
      "\n",
      "        print(f'Epoch {epoch+1} - Save Best loss: {best_loss:.4f} Model')\n",
      "\n",
      "        torch.save({'model': model.state_dict()},\n",
      "\n",
      "                    OUTPUT_DIR+f\"{CFG.model.replace('/', '-')}_best.pth\")\n",
      "\n",
      "        \n",
      "\n",
      "    # Save model for every epoch\n",
      "\n",
      "    torch.save({'model': model.state_dict()},\n",
      "\n",
      "                OUTPUT_DIR+f\"{CFG.model.replace('/', '-')}_epoch_{epoch}.pth\")\n",
      "\n",
      "\n",
      "\n",
      "torch.cuda.empty_cache()\n",
      "\n",
      "gc.collect()\n",
      "\n",
      "#################################################\n",
      "\n",
      "%%time\n",
      "\n",
      "# You can vary number of trials to change the result\n",
      "\n",
      "study = optuna.create_study(study_name= 'SuperConductor',\n",
      "\n",
      "                            direction= 'minimize',\n",
      "\n",
      "                            sampler= TPESampler())\n",
      "\n",
      "\n",
      "\n",
      "study.optimize(lambda trial : objective(trial, X, y), n_trials= 250)\n",
      "\n",
      "#################################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for t in df[df['target'] > 10000]['source']:\n",
    "    print(t)\n",
    "    print('\\n#################################################\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: xlabel='total_execution_time', ylabel='Count'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = pd.read_csv(DATA_PATH + \"info_train.csv\")\n",
    "sns.histplot(y['total_execution_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# df = load_and_prepare_pretrain(\"../output/pl_4/df_pl_0.csv\", root=DATA_PATH, lower=False)\n",
    "\n",
    "# # df = load_and_prepare_pretrain('../output/pl_5/df_pl.csv', DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"microsoft/deberta-base\"\n",
    "name = \"microsoft/codebert-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# lens = []\n",
    "# tokenizer = AutoTokenizer.from_pretrained(name)\n",
    "\n",
    "# for i in tqdm(range(len(df.sample(1000)))):\n",
    "#     lens.append(\n",
    "#         len(tokenizer(\n",
    "#             df['clean_text'][i],\n",
    "#         )['input_ids'])\n",
    "#     )\n",
    "# sns.displot(np.clip(lens, 0, 512))\n",
    "# print('Max length :', np.max(lens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer(name, add_special_tokens=False)\n",
    "dataset = PatientNoteDataset(df, tokenizer, max_len=310)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/85249 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "for idx in tqdm(range(len(dataset))):\n",
    "    data = dataset[idx]\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NERTransformer(name, num_classes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0785]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(data[\"ids\"].unsqueeze(0), data[\"token_type_ids\"].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZES = {\n",
    "    \"microsoft/deberta-v3-base\": 32,\n",
    "    \"microsoft/codebert-base\": 32,\n",
    "    \"microsoft/deberta-v3-large\": 32,\n",
    "}\n",
    "\n",
    "LRS = {\n",
    "    \"microsoft/deberta-v3-base\": 3e-5,\n",
    "    \"microsoft/codebert-base\": 3e-5,\n",
    "    \"microsoft/deberta-v3-large\": 3e-5,\n",
    "}\n",
    "\n",
    "MAX_LENS = {\n",
    "    \"microsoft/deberta-v3-base\": 512,\n",
    "    \"microsoft/codebert-base\": 512,\n",
    "    \"microsoft/deberta-v3-large\": 512,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    # General\n",
    "    seed = 2222\n",
    "    device = \"cuda\"\n",
    "    \n",
    "    # Splits\n",
    "    k = 4\n",
    "    random_state = 2222\n",
    "    selected_folds = [0, 1, 2, 3]\n",
    "    folds_file = \"/workspace/folds_kgd_4.csv\"\n",
    "\n",
    "    # Architecture\n",
    "    name = \"microsoft/codebert-base\"\n",
    "\n",
    "    pretrained_weights = None \n",
    "\n",
    "    no_dropout = False\n",
    "    use_conv = False\n",
    "    use_lstm = False\n",
    "    nb_layers = 1\n",
    "    nb_ft = 128\n",
    "    conv_kernel = 5\n",
    "    drop_p = 0 if no_dropout else 0.1\n",
    "    multi_sample_dropout = False\n",
    "    num_classes = 1\n",
    "\n",
    "    # Texts\n",
    "    max_len_train = MAX_LENS[name]\n",
    "    max_len = 512\n",
    "    lower = True\n",
    "\n",
    "#     extra_data_path = OUT_PATH + \"pl_case5/\"\n",
    "    extra_data_path = None  # OUT_PATH + \"pl_6/df_pl.csv\"\n",
    "\n",
    "    # Training    \n",
    "    loss_config = {\n",
    "        \"name\": \"mse\",  # dice, ce, bce\n",
    "        \"smoothing\": 0,  # 0.01\n",
    "        \"activation\": \"\",  # \"sigmoid\", \"softmax\"\n",
    "    }\n",
    "\n",
    "    data_config = {\n",
    "        \"batch_size\": BATCH_SIZES[name],\n",
    "        \"val_bs\": BATCH_SIZES[name] * 2,\n",
    "        \"use_len_sampler\": True,\n",
    "        \"pad_token\": 1 if \"roberta\" in name else 0,\n",
    "    }\n",
    "\n",
    "    optimizer_config = {\n",
    "        \"name\": \"AdamW\",\n",
    "        \"lr\": 5e-5,\n",
    "        \"lr_transfo\": LRS[name],\n",
    "        \"lr_decay\": 0.99,\n",
    "        \"warmup_prop\": 0.1,\n",
    "        \"weight_decay\": 1,\n",
    "        \"betas\": (0.5, 0.99),\n",
    "        \"max_grad_norm\": 1.,\n",
    "        # AWP\n",
    "        \"use_awp\": False,\n",
    "        \"awp_start_step\": 1000,\n",
    "        \"awp_lr\": 1,\n",
    "        \"awp_eps\": 5e-5 if \"xlarge\" in name else 1e-3,\n",
    "        \"awp_period\": 3,\n",
    "        # SWA\n",
    "        \"use_swa\": False,\n",
    "        \"swa_start\": 9400,\n",
    "        \"swa_freq\": 500,\n",
    "    }\n",
    "\n",
    "    gradient_checkpointing = False\n",
    "    acc_steps = 1\n",
    "    epochs = 1\n",
    "\n",
    "    use_fp16 = True\n",
    "\n",
    "    verbose = 1\n",
    "    verbose_eval = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = True\n",
    "log_folder = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------   Fold 1 / 4  -------------\n",
      "\n",
      "    -> 64157 training texts\n",
      "    -> 21092 validation texts\n",
      "    -> 124646401 trainable parameters\n",
      "\n",
      "Epoch 01/01  (step 1000)\tlr=1.5e-05\t t=757s\t loss=1151213.417\t val_loss=913356.062\t score=954.793\n",
      "Epoch 01/01  (step 2005)\tlr=2.5e-07\t t=759s\t loss=1393382.299\t val_loss=913303.375\t score=954.949\n"
     ]
    }
   ],
   "source": [
    "if not DEBUG:\n",
    "    log_folder = prepare_log_folder(LOG_PATH)\n",
    "    print(f\"Logging results to {log_folder}\")\n",
    "    save_config(Config, log_folder + \"config.json\")\n",
    "    create_logger(directory=log_folder, name=\"logs.txt\")\n",
    "\n",
    "pred_val, pred_test = k_fold(\n",
    "    Config,\n",
    "    df,\n",
    "    df_test=df_test,\n",
    "    log_folder=log_folder\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7f05aace6a00>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 558.75x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.displot(pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.6100218"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_val.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.718819"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_val.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8501861"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_val.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
