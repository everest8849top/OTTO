{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About :** Trains XGBoost models.\n",
    "\n",
    "**TODO**:\n",
    "- better neg sampling technique ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/kaggle_otto_rs/src\n"
     ]
    }
   ],
   "source": [
    "cd ../src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 32 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import cudf\n",
    "import json\n",
    "import glob\n",
    "import numba\n",
    "import xgboost\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from numerize.numerize import numerize\n",
    "from pandarallel import pandarallel\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "pd.options.display.max_columns = 500\n",
    "pd.options.display.max_rows = 500\n",
    "pandarallel.initialize(nb_workers=32, progress_bar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from params import *\n",
    "\n",
    "from utils.metrics import get_coverage\n",
    "from utils.plot import plot_importances\n",
    "from utils.load import *\n",
    "from utils.logger import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train data\n",
    "- neg sampling could use candidates from lower versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_FOLDERS = [  # ORDERS\n",
    "#     \"../logs/2023-01-14/6/\",  #   0.6657\n",
    "    \"../logs/2023-01-14/9/\",    #  0.6668\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_FOLDERS = [  # CARTS\n",
    "#     \"../logs/2023-01-14/7/\",  #   0.4368\n",
    "    \"../logs/2023-01-14/8/\",    #  0.4382\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> Exp ../logs/2023-01-14/8/ \t Target gt_carts\n",
      "\n",
      "- Retrieved 127052488 val candidates.\n",
      "- Retrieved 119776598 test candidates.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_val, df_test = None, None\n",
    "for exp_folder in EXP_FOLDERS:\n",
    "    config = Config(json.load(open(exp_folder + \"config.json\", \"r\")))\n",
    "    print(f' -> Exp {exp_folder} \\t Target {config.target}\\n')\n",
    "    TARGET = config.target\n",
    "    dfs_val, dfs_test = [], []\n",
    "\n",
    "    for fold in range(config.k):\n",
    "        try:\n",
    "            dfs_val.append(cudf.read_parquet(exp_folder + f\"df_val_{fold}.parquet\"))\n",
    "            dfs_test.append(cudf.read_parquet(exp_folder + f\"df_test_{fold}.parquet\"))\n",
    "        except:\n",
    "            print(f'Fold {fold} missing !')\n",
    "        \n",
    "    dfs_val = cudf.concat(dfs_val, ignore_index=True)\n",
    "    dfs_test = cudf.concat(dfs_test, ignore_index=True).groupby(['session', 'candidates']).mean().reset_index()\n",
    "\n",
    "    print(f'- Retrieved {len(dfs_val)} val candidates.')\n",
    "    print(f'- Retrieved {len(dfs_test)} test candidates.\\n')\n",
    "\n",
    "    if df_val is None: \n",
    "        df_val = dfs_val\n",
    "        df_val['pred']\n",
    "    else:\n",
    "        df_val = df_val.set_index(['session', 'candidates']).add(\n",
    "            dfs_val.set_index(['session', 'candidates']), fill_value=0\n",
    "        ).reset_index()\n",
    "\n",
    "    if df_test is None:\n",
    "        df_test = dfs_test\n",
    "    else:\n",
    "        df_test = df_test.set_index(['session', 'candidates']).add(\n",
    "            dfs_test.set_index(['session', 'candidates']), fill_value=0\n",
    "        ).reset_index()\n",
    "        \n",
    "    del dfs_val\n",
    "    numba.cuda.current_context().deallocations.clear()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = df_val[['session', 'candidates', 'pred']].copy()\n",
    "\n",
    "preds = preds.sort_values(['session', 'pred'], ascending=[True, False])\n",
    "preds = preds[['session', 'candidates', 'pred']].groupby('session').agg(list).reset_index()\n",
    "\n",
    "preds = preds.to_pandas()\n",
    "preds['candidates'] = preds['candidates'].apply(lambda x: x[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill less than 20 candidates.\n",
    "\n",
    "dfs = load_sessions(f\"../output/val_parquet/*\")\n",
    "\n",
    "if config.target == \"gt_carts\":\n",
    "    top = dfs.loc[dfs[\"type\"] == 1, \"aid\"].value_counts().index.values[:20].tolist()\n",
    "elif config.target == \"gt_orders\":\n",
    "    top = dfs.loc[dfs[\"type\"] == 2, \"aid\"].value_counts().index.values[:20].tolist()\n",
    "else:\n",
    "    top = dfs.loc[dfs[\"type\"] == 0, \"aid\"].value_counts().index.values[:20].tolist()\n",
    "\n",
    "preds['candidates'] = preds['candidates'].apply(lambda x: list(x) + top[: 20 - len(x)])\n",
    "\n",
    "del dfs\n",
    "numba.cuda.current_context().deallocations.clear()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1801254, 1801251)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds = pd.read_csv(f\"../input/folds_4.csv\")\n",
    "len(folds), len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- carts\t-  Found 252.4K GTs\t-  Recall : 0.4382\n"
     ]
    }
   ],
   "source": [
    "gt = pd.read_parquet(\"../output/val_labels.parquet\")\n",
    "\n",
    "recalls = []\n",
    "print()\n",
    "for col in CLASSES:\n",
    "    if \"gt_\" + col not in [config.target]:\n",
    "        continue\n",
    "\n",
    "    if f\"gt_{col}\" not in preds.columns:\n",
    "        preds = preds.merge(gt[gt[\"type\"] == col].drop(\"type\", axis=1), how=\"left\").rename(\n",
    "            columns={\"ground_truth\": f\"gt_{col}\"}\n",
    "        )\n",
    "\n",
    "    n_preds, n_gts, n_found = get_coverage(\n",
    "        preds[\"candidates\"].values, preds[f\"gt_{col}\"].values\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"- {col}\\t-  Found {numerize(n_found)} GTs\\t-  Recall : {n_found / n_gts :.4f}\"\n",
    "    )\n",
    "    recalls.append(n_found / n_gts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> CV : 0.5869\n"
     ]
    }
   ],
   "source": [
    "cv = np.average([0.554, 0.4382, 0.6668], weights=WEIGHTS)\n",
    "# cv = np.average([0.5059, 0.4139, 0.6540], weights=WEIGHTS)\n",
    "print(f\"-> CV : {cv:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv = np.average([0.554, 0.4368, 0.6657], weights=WEIGHTS)\n",
    "# # cv = np.average([0.5059, 0.4139, 0.6540], weights=WEIGHTS)\n",
    "# print(f\"-> CV : {cv:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = df_test[['session', 'candidates', 'pred']].copy()\n",
    "\n",
    "preds = preds.sort_values(['session', 'pred'], ascending=[True, False])\n",
    "preds = preds[['session', 'candidates', 'pred']].groupby('session').agg(list).reset_index()\n",
    "\n",
    "preds = preds.to_pandas()\n",
    "preds['candidates'] = preds['candidates'].apply(lambda x: x[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill less than 20 candidates. This should be useless in the future\n",
    "\n",
    "dfs = load_sessions(f\"../output/test_parquet/*\")\n",
    "\n",
    "if config.target == \"gt_carts\":\n",
    "    top = dfs.loc[dfs[\"type\"] == 1, \"aid\"].value_counts().index.values[:20].tolist()\n",
    "elif config.target == \"gt_orders\":\n",
    "    top = dfs.loc[dfs[\"type\"] == 2, \"aid\"].value_counts().index.values[:20].tolist()\n",
    "else:\n",
    "    top = dfs.loc[dfs[\"type\"] == 0, \"aid\"].value_counts().index.values[:20].tolist()\n",
    "\n",
    "preds['candidates'] = preds['candidates'].apply(lambda x: list(x) + top[: 20 - len(x)])\n",
    "\n",
    "del dfs\n",
    "numba.cuda.current_context().deallocations.clear()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "FT_VERSION = \"c-orders-v4.7\"\n",
    "MODEL_VERSION = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_folder_2 = LOG_PATH + f\"{FT_VERSION}.{MODEL_VERSION}/\"\n",
    "\n",
    "os.makedirs(log_folder_2, exist_ok=True)\n",
    "save_config(config, log_folder_2 + 'config')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Saved sub to ../logs/c-orders-v4.7.1/sub_gt_carts.csv\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_type</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12899779_carts</td>\n",
       "      <td>59625 731692 1253524 1790770 737445 1340695 94...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12899780_carts</td>\n",
       "      <td>1142000 582732 736515 77422 1419849 618310 150...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12899781_carts</td>\n",
       "      <td>918667 199008 1200570 1248748 141736 811084 75...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12899782_carts</td>\n",
       "      <td>479970 595994 127404 1033148 834354 987399 889...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12899783_carts</td>\n",
       "      <td>1817895 1811433 300127 58861 1729553 1218 2552...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     session_type                                             labels\n",
       "0  12899779_carts  59625 731692 1253524 1790770 737445 1340695 94...\n",
       "1  12899780_carts  1142000 582732 736515 77422 1419849 618310 150...\n",
       "2  12899781_carts  918667 199008 1200570 1248748 141736 811084 75...\n",
       "3  12899782_carts  479970 595994 127404 1033148 834354 987399 889...\n",
       "4  12899783_carts  1817895 1811433 300127 58861 1729553 1218 2552..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sub = preds[['session', 'candidates']].copy()\n",
    "assert len(sub) == 1671803\n",
    "\n",
    "sub['candidates'] = sub['candidates'].parallel_apply(lambda x: \" \".join(map(str, x)))\n",
    "sub['session'] =  sub['session'].astype(str) + \"_\" + TARGET[3:]\n",
    "sub.columns = [\"session_type\", \"labels\"]\n",
    "\n",
    "sub.to_csv(log_folder_2 + f'sub_{TARGET}.csv', index=False)\n",
    "print(f\"-> Saved sub to {log_folder_2 + f'sub_{TARGET}.csv'}\\n\")\n",
    "\n",
    "display(sub.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-> Saved final sub to ../logs/c-orders-v4.7.1/submission.csv\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_type</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3496178</th>\n",
       "      <td>13052351_orders</td>\n",
       "      <td>147875 1264792 890322 1709370 1603308 153333 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3971247</th>\n",
       "      <td>13527420_orders</td>\n",
       "      <td>30503 1143 203733 446495 151116 977797 1174808...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3950659</th>\n",
       "      <td>13506832_orders</td>\n",
       "      <td>546864 1421960 1718006 538242 695040 994623 18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324387</th>\n",
       "      <td>13224166_clicks</td>\n",
       "      <td>485256 485256 152547 33343 1551213 33343 17650...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3221279</th>\n",
       "      <td>14449255_carts</td>\n",
       "      <td>544645 1406365 1809109 1680961 1325223 840655 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            session_type                                             labels\n",
       "3496178  13052351_orders  147875 1264792 890322 1709370 1603308 153333 1...\n",
       "3971247  13527420_orders  30503 1143 203733 446495 151116 977797 1174808...\n",
       "3950659  13506832_orders  546864 1421960 1718006 538242 695040 994623 18...\n",
       "324387   13224166_clicks  485256 485256 152547 33343 1551213 33343 17650...\n",
       "3221279   14449255_carts  544645 1406365 1809109 1680961 1325223 840655 ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if all([os.path.exists(log_folder_2 + f'sub_gt_{c}.csv') for c in CLASSES]):\n",
    "    sub_final = cudf.concat([\n",
    "        cudf.read_csv(log_folder_2 + f'sub_gt_{c}.csv') for c in CLASSES\n",
    "    ], ignore_index=True)\n",
    "\n",
    "    assert len(sub_final) == 5015409\n",
    "    sub_final.to_csv(log_folder_2 + f\"submission.csv\", index=False)\n",
    "\n",
    "    print(f\"\\n-> Saved final sub to {log_folder_2 + f'submission.csv'}\\n\")\n",
    "\n",
    "    display(sub_final.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaggle competitions submit -c otto-recommender-system -f submission.csv -m \"Message\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
