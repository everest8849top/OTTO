{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About :** Trains XGBoost models.\n",
    "\n",
    "**TODO**:\n",
    "- better neg sampling technique ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/kaggle_otto_rs/src\n"
     ]
    }
   ],
   "source": [
    "cd ../src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 32 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import cudf\n",
    "import json\n",
    "import glob\n",
    "import numba\n",
    "import xgboost\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from numerize.numerize import numerize\n",
    "from pandarallel import pandarallel\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "pd.options.display.max_columns = 500\n",
    "pd.options.display.max_rows = 500\n",
    "pandarallel.initialize(nb_workers=32, progress_bar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from params import *\n",
    "\n",
    "from utils.metrics import get_coverage\n",
    "from utils.plot import plot_importances\n",
    "from utils.load import *\n",
    "from utils.logger import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train data\n",
    "- neg sampling could use candidates from lower versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_FOLDERS = [  # ORDERS\n",
    "#     \"../logs/2023-01-14/6/\",  #   0.6657\n",
    "    \"../logs/2023-01-14/9/\",    #  0.6668\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_FOLDERS = [  # CARTS\n",
    "#     \"../logs/2023-01-14/7/\",  #   0.4368\n",
    "    \"../logs/2023-01-14/8/\",    #  0.4382\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_FOLDERS = [  # CARTS - 0.4392\n",
    "    \"../logs/2023-01-17/5/\",   # 0.4389\n",
    "    \"../logs/2023-01-17/7/\",   # 0.4390\n",
    "    \"../logs/2023-01-17/8/\",   # 0.4391\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_FOLDERS = [  # ORDERS - 0.6673\n",
    "    \"../logs/2023-01-17/4/\",    # 0.6674\n",
    "    \"../logs/2023-01-17/6/\",    # 0.6672\n",
    "    \"../logs/2023-01-17/9/\",    # 0.6670\n",
    "#     \"../logs/2023-01-17/11/\",     # 0.6669  -  Rank\n",
    "]  # Rank avg blend ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> Exp ../logs/2023-01-17/4/ \t Target gt_orders\n",
      "- Retrieved 128418099 val candidates.\n",
      "\n",
      " -> Exp ../logs/2023-01-17/11/ \t Target gt_orders\n",
      "- Retrieved 128418099 val candidates.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_val = None\n",
    "for exp_folder in EXP_FOLDERS:\n",
    "    config = Config(json.load(open(exp_folder + \"config.json\", \"r\")))\n",
    "    print(f' -> Exp {exp_folder} \\t Target {config.target}')\n",
    "    TARGET = config.target\n",
    "    dfs_val = []\n",
    "\n",
    "    for fold in range(config.k):\n",
    "        try:\n",
    "            dfs_val.append(cudf.read_parquet(exp_folder + f\"df_val_{fold}.parquet\"))\n",
    "        except FileNotFoundError:\n",
    "            print(f'Fold {fold} missing !')\n",
    "#         break\n",
    "        \n",
    "    dfs_val = cudf.concat(dfs_val, ignore_index=True)\n",
    "\n",
    "    dfs_val['pred'] = (dfs_val['pred'] - dfs_val['pred'].min()) / (dfs_val['pred'].max() - dfs_val['pred'].min())\n",
    "    print(f'- Retrieved {len(dfs_val)} val candidates.\\n')\n",
    "\n",
    "    if df_val is None: \n",
    "        df_val = dfs_val\n",
    "        df_val['pred']\n",
    "    else:\n",
    "        df_val = df_val.set_index(['session', 'candidates']).add(\n",
    "            dfs_val.set_index(['session', 'candidates']), fill_value=0\n",
    "        ).reset_index()\n",
    "        \n",
    "    del dfs_val\n",
    "    numba.cuda.current_context().deallocations.clear()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test = None\n",
    "# for exp_folder in EXP_FOLDERS:\n",
    "#     config = Config(json.load(open(exp_folder + \"config.json\", \"r\")))\n",
    "#     print(f' -> Exp {exp_folder} \\t Target {config.target}\\n')\n",
    "#     TARGET = config.target\n",
    "#     dfs_test = []\n",
    "\n",
    "#     for fold in range(config.k):\n",
    "#         try:\n",
    "#             dfs_test.append(cudf.read_parquet(exp_folder + f\"df_test_{fold}.parquet\"))\n",
    "#         except:\n",
    "#             print(f'Fold {fold} missing !')\n",
    "        \n",
    "#     dfs_test = cudf.concat(dfs_test, ignore_index=True).groupby(['session', 'candidates']).mean().reset_index()\n",
    "\n",
    "#     print(f'- Retrieved {len(dfs_test)} test candidates.\\n')\n",
    "\n",
    "#     if df_test is None:\n",
    "#         df_test = dfs_test\n",
    "#     else:\n",
    "#         df_test = df_test.set_index(['session', 'candidates']).add(\n",
    "#             dfs_test.set_index(['session', 'candidates']), fill_value=0\n",
    "#         ).reset_index()\n",
    "        \n",
    "#     del dfs_test\n",
    "#     numba.cuda.current_context().deallocations.clear()\n",
    "#     gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = df_val[['session', 'candidates', 'pred']].copy()\n",
    "\n",
    "preds = preds.sort_values(['session', 'pred'], ascending=[True, False])\n",
    "preds = preds[['session', 'candidates', 'pred']].groupby('session').agg(list).reset_index()\n",
    "\n",
    "preds = preds.to_pandas()\n",
    "preds['candidates'] = preds['candidates'].apply(lambda x: x[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill less than 20 candidates.\n",
    "\n",
    "dfs = load_sessions(f\"../output/val_parquet/*\")\n",
    "\n",
    "if config.target == \"gt_carts\":\n",
    "    top = dfs.loc[dfs[\"type\"] == 1, \"aid\"].value_counts().index.values[:20].tolist()\n",
    "elif config.target == \"gt_orders\":\n",
    "    top = dfs.loc[dfs[\"type\"] == 2, \"aid\"].value_counts().index.values[:20].tolist()\n",
    "else:\n",
    "    top = dfs.loc[dfs[\"type\"] == 0, \"aid\"].value_counts().index.values[:20].tolist()\n",
    "\n",
    "preds['candidates'] = preds['candidates'].apply(lambda x: list(x) + top[: 20 - len(x)])\n",
    "\n",
    "del dfs\n",
    "numba.cuda.current_context().deallocations.clear()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1801254, 1801251)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds = pd.read_csv(f\"../input/folds_4.csv\")\n",
    "len(folds), len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- orders\t-  Found 208.97K GTs\t-  Recall : 0.6671\n"
     ]
    }
   ],
   "source": [
    "gt = pd.read_parquet(\"../output/val_labels.parquet\")\n",
    "\n",
    "recalls = []\n",
    "for col in CLASSES:\n",
    "    if \"gt_\" + col not in [config.target]:\n",
    "        continue\n",
    "\n",
    "    if f\"gt_{col}\" not in preds.columns:\n",
    "        preds = preds.merge(gt[gt[\"type\"] == col].drop(\"type\", axis=1), how=\"left\").rename(\n",
    "            columns={\"ground_truth\": f\"gt_{col}\"}\n",
    "        )\n",
    "\n",
    "    n_preds, n_gts, n_found = get_coverage(\n",
    "        preds[\"candidates\"].values, preds[f\"gt_{col}\"].values\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"- {col}\\t-  Found {numerize(n_found)} GTs\\t-  Recall : {n_found / n_gts :.4f}\"\n",
    "    )\n",
    "    recalls.append(n_found / n_gts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv = np.average([0.554, 0.4392, 0.6673], weights=WEIGHTS)\n",
    "# # cv = np.average([0.5059, 0.4139, 0.6540], weights=WEIGHTS)\n",
    "# print(f\"-> CV : {cv:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv = np.average([0.554, 0.4382, 0.6668], weights=WEIGHTS)\n",
    "# # cv = np.average([0.5059, 0.4139, 0.6540], weights=WEIGHTS)\n",
    "# print(f\"-> CV : {cv:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv = np.average([0.554, 0.4368, 0.6657], weights=WEIGHTS)\n",
    "# # cv = np.average([0.5059, 0.4139, 0.6540], weights=WEIGHTS)\n",
    "# print(f\"-> CV : {cv:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = df_test[['session', 'candidates', 'pred']].copy()\n",
    "\n",
    "preds = preds.sort_values(['session', 'pred'], ascending=[True, False])\n",
    "preds = preds[['session', 'candidates', 'pred']].groupby('session').agg(list).reset_index()\n",
    "\n",
    "preds = preds.to_pandas()\n",
    "preds['candidates'] = preds['candidates'].apply(lambda x: x[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill less than 20 candidates. This should be useless in the future\n",
    "\n",
    "dfs = load_sessions(f\"../output/test_parquet/*\")\n",
    "\n",
    "if config.target == \"gt_carts\":\n",
    "    top = dfs.loc[dfs[\"type\"] == 1, \"aid\"].value_counts().index.values[:20].tolist()\n",
    "elif config.target == \"gt_orders\":\n",
    "    top = dfs.loc[dfs[\"type\"] == 2, \"aid\"].value_counts().index.values[:20].tolist()\n",
    "else:\n",
    "    top = dfs.loc[dfs[\"type\"] == 0, \"aid\"].value_counts().index.values[:20].tolist()\n",
    "\n",
    "preds['candidates'] = preds['candidates'].apply(lambda x: list(x) + top[: 20 - len(x)])\n",
    "\n",
    "del dfs\n",
    "numba.cuda.current_context().deallocations.clear()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "FT_VERSION = \"cv3-tv5.8\"\n",
    "MODEL_VERSION = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_folder_2 = LOG_PATH + f\"{FT_VERSION}.{MODEL_VERSION}/\"\n",
    "\n",
    "os.makedirs(log_folder_2, exist_ok=True)\n",
    "save_config(config, log_folder_2 + 'config')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Saved sub to ../logs/cv3-tv5.8.1/sub_gt_orders.csv\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_type</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12899779_orders</td>\n",
       "      <td>59625 731692 1253524 941596 1790770 737445 134...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12899780_orders</td>\n",
       "      <td>1142000 582732 736515 973453 487136 1758603 12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12899781_orders</td>\n",
       "      <td>199008 918667 141736 57315 1681537 754412 7594...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12899782_orders</td>\n",
       "      <td>1711180 127404 1344773 987399 740494 779477 88...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12899783_orders</td>\n",
       "      <td>1817895 1811433 255297 1729553 198385 607638 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      session_type                                             labels\n",
       "0  12899779_orders  59625 731692 1253524 941596 1790770 737445 134...\n",
       "1  12899780_orders  1142000 582732 736515 973453 487136 1758603 12...\n",
       "2  12899781_orders  199008 918667 141736 57315 1681537 754412 7594...\n",
       "3  12899782_orders  1711180 127404 1344773 987399 740494 779477 88...\n",
       "4  12899783_orders  1817895 1811433 255297 1729553 198385 607638 1..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sub = preds[['session', 'candidates']].copy()\n",
    "assert len(sub) == 1671803\n",
    "\n",
    "sub['candidates'] = sub['candidates'].parallel_apply(lambda x: \" \".join(map(str, x)))\n",
    "sub['session'] =  sub['session'].astype(str) + \"_\" + TARGET[3:]\n",
    "sub.columns = [\"session_type\", \"labels\"]\n",
    "\n",
    "sub.to_csv(log_folder_2 + f'sub_{TARGET}.csv', index=False)\n",
    "print(f\"-> Saved sub to {log_folder_2 + f'sub_{TARGET}.csv'}\\n\")\n",
    "\n",
    "display(sub.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-> Saved final sub to ../logs/cv3-tv5.8.1/submission.csv\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_type</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1516809</th>\n",
       "      <td>14416588_clicks</td>\n",
       "      <td>150132 984903 1037135 634366 1095914 291783 27...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785858</th>\n",
       "      <td>13685637_clicks</td>\n",
       "      <td>715811 148270 326863 917990 9324 402839 142615...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544760</th>\n",
       "      <td>13444539_clicks</td>\n",
       "      <td>92614 728774 1242375 462845 693368 1009427 130...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2104212</th>\n",
       "      <td>13332188_carts</td>\n",
       "      <td>342835 639277 1060697 824487 1190046 1642779 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4344909</th>\n",
       "      <td>13901082_orders</td>\n",
       "      <td>1299200 1846397 418940 843644 889595 202767 16...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            session_type                                             labels\n",
       "1516809  14416588_clicks  150132 984903 1037135 634366 1095914 291783 27...\n",
       "785858   13685637_clicks  715811 148270 326863 917990 9324 402839 142615...\n",
       "544760   13444539_clicks  92614 728774 1242375 462845 693368 1009427 130...\n",
       "2104212   13332188_carts  342835 639277 1060697 824487 1190046 1642779 8...\n",
       "4344909  13901082_orders  1299200 1846397 418940 843644 889595 202767 16..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if all([os.path.exists(log_folder_2 + f'sub_gt_{c}.csv') for c in CLASSES]):\n",
    "    sub_final = cudf.concat([\n",
    "        cudf.read_csv(log_folder_2 + f'sub_gt_{c}.csv') for c in CLASSES\n",
    "    ], ignore_index=True)\n",
    "\n",
    "    assert len(sub_final) == 5015409\n",
    "    sub_final.to_csv(log_folder_2 + f\"submission.csv\", index=False)\n",
    "\n",
    "    print(f\"\\n-> Saved final sub to {log_folder_2 + f'submission.csv'}\\n\")\n",
    "\n",
    "    display(sub_final.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaggle competitions submit -c otto-recommender-system -f submission.csv -m \"Message\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
