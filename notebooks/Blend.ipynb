{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About :** Trains XGBoost models.\n",
    "\n",
    "**TODO**:\n",
    "- better neg sampling technique ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/kaggle_otto_rs/src\n"
     ]
    }
   ],
   "source": [
    "cd ../src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 32 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import cudf\n",
    "import json\n",
    "import glob\n",
    "import numba\n",
    "import xgboost\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from numerize.numerize import numerize\n",
    "from pandarallel import pandarallel\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "pd.options.display.max_columns = 500\n",
    "pd.options.display.max_rows = 500\n",
    "pandarallel.initialize(nb_workers=32, progress_bar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from params import *\n",
    "\n",
    "from utils.metrics import get_coverage\n",
    "from utils.plot import plot_importances\n",
    "from utils.load import *\n",
    "from utils.logger import Config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = \"c-orders-v4.7\"\n",
    "GT_VERSION = \"gt.7\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train data\n",
    "- neg sampling could use candidates from lower versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "POS_RATIO = 0.2\n",
    "TARGET = \"gt_orders\"   # \"gt_clicks\", \"gt_carts\", \"gt_orders\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_FOLDERS = [\n",
    "    \"../logs/2023-01-14/6/\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Exp ../logs/2023-01-14/6/\tTarget : gt_orders \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:06<00:00,  6.23s/it]\n"
     ]
    }
   ],
   "source": [
    "df_val, df_test = None, None\n",
    "for exp_folder in tqdm(EXP_FOLDERS):\n",
    "    config = Config(json.load(open(exp_folder + \"config.json\", \"r\")))\n",
    "    print(f'-> Exp {exp_folder}', end=\"\\t\")\n",
    "    print(\"Target :\", config.target, \"\\n\")\n",
    "    dfs_val, dfs_test = [], []\n",
    "    \n",
    "    for fold in range(config.k):\n",
    "        try:\n",
    "            dfs_val.append(cudf.read_parquet(exp_folder + f\"df_val_{fold}.parquet\"))\n",
    "            dfs_test.append(cudf.read_parquet(exp_folder + f\"df_test_{fold}.parquet\"))\n",
    "        except:\n",
    "            print(f'Fold {fold} missing !')\n",
    "        \n",
    "    dfs_val = cudf.concat(dfs_val, ignore_index=True)\n",
    "    dfs_test = cudf.concat(dfs_test, ignore_index=True).groupby(['session', 'candidates']).mean().reset_index()\n",
    "\n",
    "    if df_val is None: \n",
    "        df_val = dfs_val\n",
    "    else:\n",
    "        df_val = df_val.add(dfs_val)  # TODO, probably need to set some index\n",
    "\n",
    "    if df_test is None:\n",
    "        df_test = dfs_test\n",
    "    else:\n",
    "        df_test = df_test.add(dfs_val)  # TODO, probably need to set some index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = df_val[['session', 'candidates', 'pred']].copy()\n",
    "\n",
    "preds = preds.sort_values(['session', 'pred'], ascending=[True, False])\n",
    "preds = preds[['session', 'candidates', 'pred']].groupby('session').agg(list).reset_index()\n",
    "\n",
    "preds = preds.to_pandas()\n",
    "preds['candidates'] = preds['candidates'].apply(lambda x: x[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill less than 20 candidates.\n",
    "\n",
    "dfs = load_sessions(f\"../output/val_parquet/*\")\n",
    "\n",
    "if config.target == \"gt_carts\":\n",
    "    top = dfs.loc[dfs[\"type\"] == 1, \"aid\"].value_counts().index.values[:20].tolist()\n",
    "elif config.target == \"gt_orders\":\n",
    "    top = dfs.loc[dfs[\"type\"] == 2, \"aid\"].value_counts().index.values[:20].tolist()\n",
    "else:\n",
    "    top = dfs.loc[dfs[\"type\"] == 0, \"aid\"].value_counts().index.values[:20].tolist()\n",
    "\n",
    "preds['candidates'] = preds['candidates'].apply(lambda x: list(x) + top[: 20 - len(x)])\n",
    "\n",
    "del dfs\n",
    "numba.cuda.current_context().deallocations.clear()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1801254, 1801251)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds = pd.read_csv(f\"../input/folds_4.csv\")\n",
    "len(folds), len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- orders\t-  Found 208.51K GTs\t-  Recall : 0.6657\n"
     ]
    }
   ],
   "source": [
    "gt = pd.read_parquet(\"../output/val_labels.parquet\")\n",
    "\n",
    "recalls = []\n",
    "print()\n",
    "for col in CLASSES:\n",
    "    if \"gt_\" + col not in [config.target]:\n",
    "        continue\n",
    "\n",
    "    if f\"gt_{col}\" not in preds.columns:\n",
    "        preds = preds.merge(gt[gt[\"type\"] == col].drop(\"type\", axis=1), how=\"left\").rename(\n",
    "            columns={\"ground_truth\": f\"gt_{col}\"}\n",
    "        )\n",
    "\n",
    "    n_preds, n_gts, n_found = get_coverage(\n",
    "        preds[\"candidates\"].values, preds[f\"gt_{col}\"].values\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"- {col}\\t-  Found {numerize(n_found)} GTs\\t-  Recall : {n_found / n_gts :.4f}\"\n",
    "    )\n",
    "    recalls.append(n_found / n_gts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- orders\t-  Found 51.98K GTs\t-  Recall : 0.6664  MORE CANDIDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- orders\t-  Found 207.74K GTs\t-  Recall : 0.6632\n",
    "- carts\t-  Found 242.41K GTs\t-  Recall : 0.4208\n",
    "- clicks\t-  Found 927.04K GTs\t-  Recall : 0.5281\n",
    "\n",
    "CHRIS :\n",
    "- orders - CV 0.666 - LB 0.678\n",
    "- carts - CV 0.437 - LB 0.450\n",
    "- clicks - CV 0.554 - LB 0.560"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv = np.average([0.5270, 0.4203, 0.6577], weights=WEIGHTS)\n",
    "# # cv = np.average([0.5059, 0.4139, 0.6540], weights=WEIGHTS)\n",
    "# print(f\"-> CV : {cv:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = df_test[['session', 'candidates', 'pred']].copy()\n",
    "\n",
    "preds = preds.sort_values(['session', 'pred'], ascending=[True, False])\n",
    "preds = preds[['session', 'candidates', 'pred']].groupby('session').agg(list).reset_index()\n",
    "\n",
    "preds = preds.to_pandas()\n",
    "preds['candidates'] = preds['candidates'].apply(lambda x: x[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill less than 20 candidates. This should be useless in the future\n",
    "\n",
    "dfs = load_sessions(f\"../output/test_parquet/*\")\n",
    "\n",
    "if Config.target == \"gt_carts\":\n",
    "    top = dfs.loc[dfs[\"type\"] == 1, \"aid\"].value_counts().index.values[:20].tolist()\n",
    "elif Config.target == \"gt_orders\":\n",
    "    top = dfs.loc[dfs[\"type\"] == 2, \"aid\"].value_counts().index.values[:20].tolist()\n",
    "else:\n",
    "    top = dfs.loc[dfs[\"type\"] == 0, \"aid\"].value_counts().index.values[:20].tolist()\n",
    "\n",
    "preds['candidates'] = preds['candidates'].apply(lambda x: list(x) + top[: 20 - len(x)])\n",
    "\n",
    "del dfs\n",
    "numba.cuda.current_context().deallocations.clear()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_folder_2 = LOG_PATH + f\"{VERSION}.0/\"\n",
    "os.makedirs(log_folder_2, exist_ok=True)\n",
    "save_config(Config, log_folder_2 + 'config')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not DEBUG:\n",
    "    sub = preds[['session', 'candidates']].copy()\n",
    "    assert len(sub) == 1671803\n",
    "\n",
    "    sub['candidates'] = sub['candidates'].parallel_apply(lambda x: \" \".join(map(str, x)))\n",
    "    sub['session'] =  sub['session'].astype(str) + \"_\" + TARGET[3:]\n",
    "    sub.columns = [\"session_type\", \"labels\"]\n",
    "\n",
    "    sub.to_csv(log_folder + f'sub_{TARGET}.csv', index=False)\n",
    "    print(f\"\\n-> Saved sub to {log_folder + f'sub_{TARGET}.csv'}\")\n",
    "\n",
    "    sub.to_csv(log_folder_2 + f'sub_{TARGET}.csv', index=False)\n",
    "    print(f\"-> Saved sub to {log_folder_2 + f'sub_{TARGET}.csv'}\\n\")\n",
    "\n",
    "    display(sub.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if all([os.path.exists(log_folder_2 + f'sub_gt_{c}.csv') for c in CLASSES]):\n",
    "#     sub_final = cudf.concat([\n",
    "#         cudf.read_csv(log_folder_2 + f'sub_gt_{c}.csv') for c in CLASSES\n",
    "#     ], ignore_index=True)\n",
    "\n",
    "#     assert len(sub_final) == 5015409\n",
    "#     sub_final.to_csv(log_folder_2 + f\"submission.csv\", index=False)\n",
    "\n",
    "#     print(f\"\\n-> Saved final sub to {log_folder_2 + f'submission.csv'}\\n\")\n",
    "\n",
    "#     display(sub_final.sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
