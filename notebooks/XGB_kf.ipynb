{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About :** Trains XGBoost models.\n",
    "\n",
    "**TODO**:\n",
    "- better neg sampling technique ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import cudf\n",
    "import json\n",
    "import glob\n",
    "import numba\n",
    "import xgboost\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pandarallel import pandarallel\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "pd.options.display.max_columns = 500\n",
    "pd.options.display.max_rows = 500\n",
    "pandarallel.initialize(nb_workers=32, progress_bar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from params import *\n",
    "\n",
    "from utils.metrics import get_coverage\n",
    "from utils.plot import plot_importances\n",
    "from utils.load import *\n",
    "from utils.logger import save_config, prepare_log_folder, create_logger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = \"v3.5\"\n",
    "# VERSION = \"v2.5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train data\n",
    "- neg sampling could use candidates from lower versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POS_RATIO = 0.1\n",
    "TARGET = \"gt_clicks\"   # \"gt_clicks\", \"gt_carts\", \"gt_orders\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train[TARGET].mean(), df_val[TARGET].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_sessions(regex):\n",
    "#     dfs = []\n",
    "#     for idx, chunk_file in enumerate(glob.glob(regex)):\n",
    "#         df = cudf.read_parquet(chunk_file, columns=[\"session\"])\n",
    "#         dfs.append(df.drop_duplicates(keep=\"first\"))\n",
    "\n",
    "#     return cudf.concat(dfs).reset_index(drop=True)\n",
    "\n",
    "# sessions = load_sessions( f\"../output/features/fts_val_{VERSION}/*\")\n",
    "\n",
    "# from sklearn.model_selection import KFold\n",
    "# K = 4\n",
    "\n",
    "# kf = KFold(n_splits=K, shuffle=True, random_state=42)\n",
    "# splits = kf.split(sessions)\n",
    "\n",
    "# sessions['fold'] = -1\n",
    "# for i, (_, val_idx) in enumerate(splits):\n",
    "#     sessions.loc[val_idx, \"fold\"] = i\n",
    "\n",
    "# sessions.to_csv(f\"../input/folds_{K}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if MODE == \"val\":\n",
    "\n",
    "#     val_regex = f\"../output/features/fts_val_{VERSION}/*\"\n",
    "# else:  # Test\n",
    "#     df_train = load_parquets_cudf_chunks(\n",
    "#         f\"../output/features/fts_val_{VERSION}/*\",\n",
    "#         pos_ratio=POS_RATIO,\n",
    "#         target=TARGET,\n",
    "#         n_chunks=5,\n",
    "#     )\n",
    "#     val_regex = f\"../output/features/fts_test_{VERSION}/*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train, df_val = load_parquets_cudf_chunks_folds(\n",
    "#     f\"../output/features/fts_val_{VERSION}/*\",\n",
    "#     \"../input/folds_4.csv\",\n",
    "#     fold=0,\n",
    "#     pos_ratio=POS_RATIO,\n",
    "#     target=TARGET,\n",
    "#     n_chunks=5,\n",
    "# )[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGEX = f\"../output/features/fts_val_{VERSION}/*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_REGEX = f\"../output/features/fts_test_{VERSION}/*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = cudf.concat([  # not working ??\n",
    "#     load_parquets_cudf_chunks(\n",
    "#         f\"../output/features/fts_train_v3.5/*\",\n",
    "#         pos_ratio=0.1,\n",
    "#         target=TARGET,\n",
    "#         n_chunks=5,\n",
    "#     ),\n",
    "#     load_parquets_cudf_chunks(\n",
    "#         f\"../output/features/fts_train_v4.5/*\",\n",
    "#         pos_ratio=0.,\n",
    "#         target=TARGET,\n",
    "#         n_chunks=5,\n",
    "#     ),\n",
    "# ], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_val_c = load_parquets_cudf(f\"../output/features/fts_val_c_{VERSION}/*\")\n",
    "\n",
    "# if POS_RATIO:\n",
    "#     n_neg = int(df_val_c[TARGET].sum() / POS_RATIO)\n",
    "#     pos = df_val_c.index[df_val_c[TARGET] == 1]\n",
    "# #     neg = df_val_c[[TARGET]][df_val_c[TARGET] == 0].sample(n_neg).index\n",
    "# #     df_val_c = df_val_c.iloc[cudf.concat([pos, neg])]\n",
    "#     df_val_c = df_val_c.iloc[pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = cudf.concat([df_train, df_val_c], ignore_index=True)\n",
    "\n",
    "# del df_val_c\n",
    "# numba.cuda.current_context().deallocations.clear()\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = df_train.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import optuna\n",
    "import cuml\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from numerize.numerize import numerize\n",
    "from utils.torch import seed_everything\n",
    "\n",
    "from model_zoo import TRAIN_FCTS, PREDICT_FCTS\n",
    "\n",
    "def train(df_train, val_regex, config, log_folder=None, optimize=False, fold=0):\n",
    "    seed_everything(config.seed)\n",
    "\n",
    "    txt = f\"{'Optimizing' if optimize else 'Training'} {config.model.upper()} Model\"\n",
    "    print(f\"\\n-------------   {txt}   -------------\\n\")\n",
    "\n",
    "    if optimize:  # TODO\n",
    "        study = optuna.create_study(direction=\"minimize\")\n",
    "        objective = lambda x: objective_xgb(x, df_train, val_regex, features, target)\n",
    "        study.optimize(objective, n_trials=50)\n",
    "        print(study.best_params)\n",
    "        return study.best_params\n",
    "\n",
    "    val_candids = sum([len(cudf.read_parquet(f, columns=['gt_orders'])) for f in glob.glob(val_regex)])\n",
    "    print(f\"    -> {numerize(len(df_train))} training candidates\")\n",
    "    print(f\"    -> {numerize(val_candids)} validation candidates\\n\")\n",
    "    \n",
    "    train_fct = TRAIN_FCTS[config.model]\n",
    "    df_val, model = train_fct(\n",
    "        df_train,\n",
    "        val_regex,\n",
    "        features=config.features,\n",
    "        target=config.target,\n",
    "        params=config.params,\n",
    "        use_es=config.use_es,\n",
    "        num_boost_round=config.num_boost_round,\n",
    "        folds_file=config.folds_file,\n",
    "        fold=fold\n",
    "    )\n",
    "\n",
    "    # Feature importance\n",
    "    if config.model == \"xgb\":\n",
    "        ft_imp = model.get_score()\n",
    "    else:\n",
    "        ft_imp = model.feature_importances_  # TODO\n",
    "    try:\n",
    "        ft_imp = pd.DataFrame(\n",
    "            pd.Series(ft_imp, index=config.features), columns=[\"importance\"]\n",
    "        )\n",
    "    except:\n",
    "        ft_imp = None\n",
    "        \n",
    "    if config.mode == \"test\":\n",
    "        return df_val, ft_imp, model\n",
    "\n",
    "    # Score\n",
    "    try:\n",
    "        auc = roc_auc_score(df_val[config.target], df_val[\"pred\"])\n",
    "    except:\n",
    "        auc = cuml.metrics.roc_auc_score(df_val[config.target].astype('int32'), df_val[\"pred\"].values)\n",
    "    \n",
    "    print(f'\\n -> AUC : {auc:.4f}\\n')\n",
    "\n",
    "    if log_folder is None:\n",
    "        return df_val, ft_imp, model\n",
    "\n",
    "    # Save model\n",
    "    if config.model == \"xgb\":\n",
    "        model.save_model(log_folder + f\"{config.model}_{fold}.json\")\n",
    "    elif config.model == \"lgbm\":\n",
    "        try:\n",
    "            model.booster_.save_model(log_folder + f\"{config.model}_{fold}.txt\")\n",
    "        except Exception:\n",
    "            model.save_model(log_folder + f\"{config.model}_{fold}.txt\")\n",
    "    else:   # catboost, verif\n",
    "        model.save_model(log_folder + f\"{config.model}_{fold}.txt\")\n",
    "\n",
    "    return df_val, ft_imp, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold(regex, test_regex, config, log_folder):\n",
    "    dfs_val, ft_imps, dfs_test = [], [], []\n",
    "    for fold in range(config.k):\n",
    "        print(f\"\\n-------------   Fold {fold + 1} / {config.k}  -------------\\n\")\n",
    "\n",
    "        df_train = load_parquets_cudf_chunks_folds(\n",
    "            regex,\n",
    "            config.folds_file,\n",
    "            fold=fold,\n",
    "            pos_ratio=config.pos_ratio,\n",
    "            target=config.target,\n",
    "            n_chunks=5,\n",
    "            train_only=True\n",
    "        )\n",
    "\n",
    "        df_val, ft_imp, model = train(df_train, regex, config, log_folder=log_folder, fold=fold)\n",
    "        dfs_val.append(df_val)\n",
    "        ft_imps.append(ft_imp)\n",
    "\n",
    "        predict_fct = PREDICT_FCTS[config.model]\n",
    "        pred_test = predict_fct(model, test_regex, config.features)\n",
    "        dfs_test.append(pred_test)\n",
    "        \n",
    "        if log_folder is not None:\n",
    "            df_val[['session', 'candidates', 'pred']].to_parquet(log_folder + f\"df_val_{fold}.parquet\")\n",
    "\n",
    "    dfs_test = cudf.concat(dfs_test).groupby(['session', 'candidates']).mean().reset_index()\n",
    "    dfs_val =  cudf.concat(dfs_val).sort_values(['session', 'candidates'], ignore_index=True)\n",
    "    ft_imps = pd.concat(ft_imps).reset_index().groupby('index').mean()\n",
    "\n",
    "    if log_folder is not None:\n",
    "        ft_imp.to_csv(log_folder + \"ft_imp.csv\")\n",
    "        dfs_test[['session', 'candidates', 'pred']].to_parquet(log_folder + f\"df_test.parquet\")\n",
    "\n",
    "    return dfs_val, ft_imps, dfs_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMS = {\n",
    "    \"xgb\":\n",
    "    {\n",
    "        \"learning_rate\": 0.01,\n",
    "        'max_depth': 5,\n",
    "        \"subsample\": 0.25,\n",
    "        'colsample_bytree': 0.9,\n",
    "        'reg_alpha': 0.01,\n",
    "        'reg_lambda': 0.1,\n",
    "#         \"min_child_weight\": 0.01,\n",
    "#         \"gamma\": 0.01,\n",
    "        'eval_metric':'auc',  # map\n",
    "        'objective':'binary:logistic',  # 'rank:pairwise',\n",
    "        'tree_method':'gpu_hist',\n",
    "        'predictor':'gpu_predictor',\n",
    "    },\n",
    "    \"catboost\":\n",
    "        {\n",
    "        'depth': 12,\n",
    "        \"l2_leaf_reg\": 0.1,\n",
    "        \"min_data_in_leaf\": 2000,\n",
    "        'reg_lambda': 0.1,\n",
    "        \"model_size_reg\": 0.5,\n",
    "        \"border_count\": 256,\n",
    "        },\n",
    "    \"lgbm\": {\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"num_leaves\": 511,\n",
    "        \"colsample_bytree\": 0.5,\n",
    "        \"reg_alpha\": 1,\n",
    "        \"reg_lambda\": 70,\n",
    "        \"min_child_samples\": 2000,  # MODIF  # 2000\n",
    "        \"min_split_gain\": 0.02,\n",
    "        \"min_child_weight\": 0.03,\n",
    "        \"path_smooth\": 0.2,\n",
    "#             \"min_data_in_bin\": 32,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    seed = 100\n",
    "    version = VERSION\n",
    "    \n",
    "    folds_file = \"../input/folds_4.csv\"\n",
    "    k = 4\n",
    "    mode = \"\"\n",
    "\n",
    "    features = [\n",
    "        'logspace_w', 'linspace_w', 'linspace_w_t163', 'logspace_w_t163', 'linspace_w_t191', 'logspace_w_t191',\n",
    "\n",
    "        'matrix_123_temporal_20_mean', 'matrix_123_temporal_20_sum', 'matrix_123_temporal_20_max',\n",
    "        'matrix_123_temporal_20_logspace_mean', 'matrix_123_temporal_20_logspace_sum', 'matrix_123_temporal_20_logspace_max',\n",
    "        'matrix_123_temporal_20_linspace_mean', 'matrix_123_temporal_20_linspace_sum', 'matrix_123_temporal_20_linspace_max',\n",
    "        'matrix_123_type136_20_mean', 'matrix_123_type136_20_sum', 'matrix_123_type136_20_max',\n",
    "        'matrix_123_type136_20_logspace_mean', 'matrix_123_type136_20_logspace_sum', 'matrix_123_type136_20_logspace_max',\n",
    "        'matrix_123_type136_20_linspace_mean', 'matrix_123_type136_20_linspace_sum', 'matrix_123_type136_20_linspace_max',\n",
    "        'matrix_12__20_mean', 'matrix_12__20_sum', 'matrix_12__20_max',\n",
    "        'matrix_12__20_logspace_mean', 'matrix_12__20_logspace_sum', 'matrix_12__20_logspace_max',\n",
    "        'matrix_12__20_linspace_mean', 'matrix_12__20_linspace_sum', 'matrix_12__20_linspace_max',\n",
    "        'matrix_123_type0.590.5_20_mean', 'matrix_123_type0.590.5_20_sum', 'matrix_123_type0.590.5_20_max',\n",
    "        'matrix_123_type0.590.5_20_logspace_mean', 'matrix_123_type0.590.5_20_logspace_sum', 'matrix_123_type0.590.5_20_logspace_max',\n",
    "        'matrix_123_type0.590.5_20_linspace_mean', 'matrix_123_type0.590.5_20_linspace_sum', 'matrix_123_type0.590.5_20_linspace_max',\n",
    "        \n",
    "        'clicks_popularity_w', 'carts_popularity_w', 'orders_popularity_w',\n",
    "        'view_popularity_log_w', 'view_popularity_lin_w', \n",
    "    \n",
    "        'clicks_popularity', 'carts_popularity', 'orders_popularity',\n",
    "        'view_popularity_log', 'view_popularity_lin',\n",
    "        \n",
    "        'clicks_popularity_old', 'carts_popularity_old', 'orders_popularity_old',\n",
    "        'view_popularity_log_old', 'view_popularity_lin_old',\n",
    "\n",
    "        'candidate_clicks_before', 'candidate_carts_before', 'candidate_orders_before', 'candidate_*_before',\n",
    "        'n_views', 'n_clicks', 'n_carts', 'n_orders',\n",
    "    ]\n",
    "\n",
    "    cat_features = []\n",
    "\n",
    "    target = TARGET\n",
    "    pos_ratio = POS_RATIO\n",
    "    model = \"xgb\"\n",
    "\n",
    "    params = PARAMS[model]\n",
    "\n",
    "    use_es = True\n",
    "    num_boost_round = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Config.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "log_folder = None\n",
    "if not DEBUG:\n",
    "    log_folder = prepare_log_folder(LOG_PATH)\n",
    "    print(f'Logging results to {log_folder}')\n",
    "    save_config(Config, log_folder + 'config')\n",
    "    create_logger(directory=log_folder, name=\"logs.txt\")\n",
    "else:\n",
    "    TEST_REGEX = '../output/features/fts_test_v3.5/1_005*'\n",
    "\n",
    "df_val, ft_imp, df_test = kfold(REGEX, TEST_REGEX, Config, log_folder=log_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_importances(ft_imp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process\n",
    "- I have missing sessions ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = df_val[['session', 'candidates', 'pred']].copy()\n",
    "\n",
    "preds = preds.sort_values(['session', 'pred'], ascending=[True, False])\n",
    "preds = preds[['session', 'candidates', 'pred']].groupby('session').agg(list).reset_index()\n",
    "\n",
    "preds = preds.to_pandas()\n",
    "preds['candidates'] = preds['candidates'].apply(lambda x: x[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill less than 20 candidates. This should be useless in the future\n",
    "\n",
    "dfs = load_sessions(f\"../output/val_parquet/*\")\n",
    "\n",
    "if Config.target == \"gt_carts\":\n",
    "    top = dfs.loc[dfs[\"type\"] == 1, \"aid\"].value_counts().index.values[:20].tolist()\n",
    "elif Config.target == \"gt_orders\":\n",
    "    top = dfs.loc[dfs[\"type\"] == 2, \"aid\"].value_counts().index.values[:20].tolist()\n",
    "else:\n",
    "    top = dfs.loc[dfs[\"type\"] == 0, \"aid\"].value_counts().index.values[:20].tolist()\n",
    "\n",
    "preds['candidates'] = preds['candidates'].apply(lambda x: list(x) + top[: 20 - len(x)])\n",
    "\n",
    "del dfs\n",
    "numba.cuda.current_context().deallocations.clear()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = pd.read_parquet(\"../output/val_labels.parquet\")\n",
    "\n",
    "recalls = []\n",
    "print()\n",
    "for col in CLASSES:\n",
    "    if \"gt_\" + col not in [Config.target]:\n",
    "        continue\n",
    "\n",
    "    if f\"gt_{col}\" not in preds.columns:\n",
    "        preds = preds.merge(gt[gt[\"type\"] == col].drop(\"type\", axis=1), how=\"left\").rename(\n",
    "            columns={\"ground_truth\": f\"gt_{col}\"}\n",
    "        )\n",
    "\n",
    "    n_preds, n_gts, n_found = get_coverage(\n",
    "        preds[\"candidates\"].values, preds[f\"gt_{col}\"].values\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"- {col}\\t-  Found {numerize(n_found)} GTs\\t-  Recall : {n_found / n_gts :.4f}\"\n",
    "    )\n",
    "    recalls.append(n_found / n_gts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- orders\t-  Found 206.1K GTs\t-  Recall : 0.6580\n",
    "- carts\t-  Found 242.41K GTs\t-  Recall : 0.4208\n",
    "- clicks\t-  Found 927.04K GTs\t-  Recall : 0.5281"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv = np.average([0.5270, 0.4203, 0.6577], weights=WEIGHTS)\n",
    "# # cv = np.average([0.5059, 0.4139, 0.6540], weights=WEIGHTS)\n",
    "# print(f\"-> CV : {cv:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = df_test[['session', 'candidates', 'pred']].copy()\n",
    "\n",
    "preds = preds.sort_values(['session', 'pred'], ascending=[True, False])\n",
    "preds = preds[['session', 'candidates', 'pred']].groupby('session').agg(list).reset_index()\n",
    "\n",
    "preds = preds.to_pandas()\n",
    "preds['candidates'] = preds['candidates'].apply(lambda x: x[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill less than 20 candidates. This should be useless in the future\n",
    "\n",
    "dfs = load_sessions(f\"../output/test_parquet/*\")\n",
    "\n",
    "if Config.target == \"gt_carts\":\n",
    "    top = dfs.loc[dfs[\"type\"] == 1, \"aid\"].value_counts().index.values[:20].tolist()\n",
    "elif Config.target == \"gt_orders\":\n",
    "    top = dfs.loc[dfs[\"type\"] == 2, \"aid\"].value_counts().index.values[:20].tolist()\n",
    "else:\n",
    "    top = dfs.loc[dfs[\"type\"] == 0, \"aid\"].value_counts().index.values[:20].tolist()\n",
    "\n",
    "preds['candidates'] = preds['candidates'].apply(lambda x: list(x) + top[: 20 - len(x)])\n",
    "\n",
    "del dfs\n",
    "numba.cuda.current_context().deallocations.clear()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_folder_2 = LOG_PATH + f\"{VERSION}.1/\"\n",
    "os.makedirs(log_folder_2, exist_ok=True)\n",
    "save_config(Config, log_folder_2 + 'config')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not DEBUG:\n",
    "    sub = preds[['session', 'candidates']].copy()\n",
    "    assert len(sub) == 1671803\n",
    "\n",
    "    sub['candidates'] = sub['candidates'].parallel_apply(lambda x: \" \".join(map(str, x)))\n",
    "    sub['session'] =  sub['session'].astype(str) + \"_\" + TARGET[3:]\n",
    "    sub.columns = [\"session_type\", \"labels\"]\n",
    "\n",
    "    sub.to_csv(log_folder + f'sub_{TARGET}.csv', index=False)\n",
    "    print(f\"\\n-> Saved sub to {log_folder + f'sub_{TARGET}.csv'}\")\n",
    "\n",
    "    sub.to_csv(log_folder_2 + f'sub_{TARGET}.csv', index=False)\n",
    "    print(f\"-> Saved sub to {log_folder + f'sub_{TARGET}.csv'}\\n\")\n",
    "\n",
    "    display(sub.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if all([os.path.exists(log_folder_2 + f'sub_gt_{c}.csv') for c in CLASSES]):\n",
    "#     sub_final = cudf.concat([\n",
    "#         cudf.read_csv(log_folder_2 + f'sub_gt_{c}.csv') for c in CLASSES\n",
    "#     ], ignore_index=True)\n",
    "\n",
    "#     assert len(sub_final) == 5015409\n",
    "#     sub_final.to_csv(log_folder_2 + f\"submission.csv\", index=False)\n",
    "\n",
    "#     print(f\"\\n-> Saved final sub to {log_folder_2 + f'submission.csv'}\\n\")\n",
    "\n",
    "#     display(sub_final.sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
