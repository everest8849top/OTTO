{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 32 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import cudf\n",
    "import json\n",
    "import glob\n",
    "import numba\n",
    "import pickle\n",
    "import warnings\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "from pandarallel import pandarallel\n",
    "from numerize.numerize import numerize\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "\n",
    "pandarallel.initialize(nb_workers=32, progress_bar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from params import *\n",
    "\n",
    "from data.covisitation import compute_covisitation_matrix\n",
    "from data.candidates import load_parquets, create_candidates, explode\n",
    "\n",
    "from utils.metrics import get_coverage\n",
    "from utils.chris import suggest_clicks, suggest_buys, read_file_to_cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODE = \"val\"\n",
    "SUFFIX = \"v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODE == \"val\":\n",
    "    CANDIDATE_FILE = '../output/candidates_val_593.parquet'\n",
    "#     PARQUET_FILES = \"../output/val_parquet/*\"\n",
    "    PARQUET_FILES = \"../input/chris/test_parquet/*\"\n",
    "else:  # train\n",
    "    CANDIDATE_FILE = '../output/candidates_train_593.parquet'\n",
    "    PARQUET_FILES = \"../output/train_parquet/*\"\n",
    "    \n",
    "pairs = cudf.read_parquet(CANDIDATE_FILE)\n",
    "pairs = pairs.sort_values(['session', 'candidates'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Covisitation features\n",
    "TODO :\n",
    "- time weighted agg, agg last n\n",
    "- merge rank in matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coocurence_features(pairs, matrix_file=\"\"):\n",
    "    pairs['group'] = pairs['session'] // 100000\n",
    "    \n",
    "    mat = cudf.read_parquet(matrix_file)\n",
    "    mat.columns = ['aid', 'candidates', 'w']\n",
    "\n",
    "    fts = []\n",
    "    for _, df in pairs.groupby('group'):\n",
    "        df = df[['session', 'candidates', 'aid']].explode('aid').reset_index(drop=True)\n",
    "\n",
    "        df = df.merge(mat, how=\"left\", on=[\"aid\", \"candidates\"]).reset_index().fillna(0)\n",
    "        df = df[['candidates', 'session', 'w']].groupby(['session', 'candidates']).agg([\"mean\", \"sum\", \"max\"])\n",
    "        df.columns = df.columns.get_level_values(1)\n",
    "\n",
    "        df['mean'] = df['mean'].astype(\"float32\")\n",
    "        fts.append(df.reset_index())\n",
    "\n",
    "    fts = cudf.concat(fts, ignore_index=True)\n",
    "    fts = fts.sort_values(['session', 'candidates']).reset_index(drop=True)\n",
    "\n",
    "    return fts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MATRIX_FOLDER = \"../output/matrices/\"\n",
    "MATRIX_NAMES = [\"matrix_123_temporal_20\", \"matrix_123_type_20\", \"matrix_12__15\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> Features from matrix_123_temporal_20\n",
      " -> Features from matrix_123_type_20\n",
      " -> Features from matrix_12__15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sessions = load_parquets(PARQUET_FILES)\n",
    "sessions = cudf.from_pandas(sessions)\n",
    "\n",
    "sessions = sessions.sort_values(['session', \"aid\"]).groupby('session').agg(list).reset_index()\n",
    "pairs = pairs.merge(sessions[[\"session\", \"aid\"]], how=\"left\", on=\"session\")\n",
    "pairs = pairs.sort_values(['session', 'candidates']).reset_index(drop=True)\n",
    "\n",
    "for name in MATRIX_NAMES:\n",
    "    print(f' -> Features from {name}')\n",
    "\n",
    "    fts = compute_coocurence_features(\n",
    "        pairs[['session', 'candidates', 'aid']],\n",
    "        os.path.join(MATRIX_FOLDER, name + \".pqt\")\n",
    "    )\n",
    "    \n",
    "    pairs[f'{name}_mean'] = fts[\"mean\"].values\n",
    "    pairs[f'{name}_sum'] = fts[\"sum\"].values\n",
    "    pairs[f'{name}_max'] = fts[\"max\"].values\n",
    "    \n",
    "    del fts\n",
    "    numba.cuda.current_context().deallocations.clear()\n",
    "    gc.collect()\n",
    "    \n",
    "pairs.drop('aid', axis=1, inplace=True)\n",
    "\n",
    "del sessions\n",
    "numba.cuda.current_context().deallocations.clear()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Popularity\n",
    "TODO :\n",
    "- Popularity of items in session\n",
    "- Popularity over different periods  (day / month)\n",
    "- Time weighted popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sessions = load_parquets(PARQUET_FILES)\n",
    "sessions = cudf.from_pandas(sessions)\n",
    "\n",
    "for i, c in enumerate(CLASSES):\n",
    "    popularity = cudf.DataFrame(sessions.loc[sessions[\"type\"] == i, \"aid\"].value_counts()).reset_index()\n",
    "    popularity.columns = ['candidates', f'{c}_popularity']\n",
    "    popularity[f'{c}_popularity'] = np.clip(popularity[f'{c}_popularity'], 0, 2 ** 16 - 1).astype(\"uint16\")\n",
    "\n",
    "    pairs = pairs.merge(popularity, how=\"left\", on=\"candidates\").fillna(0)\n",
    "\n",
    "del sessions, popularity\n",
    "numba.cuda.current_context().deallocations.clear()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Session features\n",
    "- Count views/clicks/carts/orders of session\n",
    "- Count views/clicks/carts/orders of each candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_actions(pairs, sessions):\n",
    "    pairs['group'] = pairs['session'] // 100000\n",
    "\n",
    "    pairs = pairs.merge(sessions[[\"session\", \"aid\"]], how=\"left\", on=\"session\")\n",
    "\n",
    "    dfp = pairs[['session', 'candidates', 'aid']].explode('aid')\n",
    "    dfp['aid'] = (dfp['aid'] == dfp['candidates']).astype(np.uint16)\n",
    "\n",
    "    n_actions = dfp.groupby(\n",
    "        [\"session\", \"candidates\"]\n",
    "    ).sum().reset_index().sort_values(['session', 'candidates'])['aid'].values\n",
    "    \n",
    "    return np.clip(n_actions, 0, 255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_actions(pairs, sessions):\n",
    "    pairs = pairs.merge(sessions[[\"session\", \"aid\"]], how=\"left\", on=\"session\")\n",
    "    pairs['group'] = pairs['session'] // 100000\n",
    "\n",
    "    fts = []\n",
    "    for _, df in pairs.groupby('group'):\n",
    "        df = df[['session', 'candidates', 'aid']].explode('aid')\n",
    "        df['aid'] = (df['aid'] == df['candidates']).astype(np.uint16)\n",
    "\n",
    "        df = df.groupby(\n",
    "            [\"session\", \"candidates\"]\n",
    "        ).sum().reset_index()\n",
    "        \n",
    "        fts.append(df)\n",
    "    \n",
    "    ft = cudf.concat(fts, ignore_index=True)\n",
    "    ft = ft.sort_values(['session', 'candidates'])['aid'].values\n",
    "\n",
    "    return np.clip(ft, 0, 255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Candidate clicks in session\n",
      "-> Candidate carts in session\n",
      "-> Candidate orders in session\n",
      "-> Candidate views in session\n"
     ]
    }
   ],
   "source": [
    "for i, c in enumerate(CLASSES + [\"*\"]):\n",
    "    print(f'-> Candidate {c if c != \"*\" else \"views\"} in session')\n",
    "\n",
    "    sessions = load_parquets(PARQUET_FILES)\n",
    "    sessions = cudf.from_pandas(sessions)\n",
    "\n",
    "    if c != \"*\":\n",
    "        sessions.loc[sessions[\"type\"] != i, \"aid\"] = -1\n",
    "\n",
    "    sessions = sessions.groupby('session').agg(list).reset_index()\n",
    "    \n",
    "    pairs[f'candidate_{c}_before'] = count_actions(pairs, sessions)\n",
    "    \n",
    "    del sessions\n",
    "    numba.cuda.current_context().deallocations.clear()\n",
    "    gc.collect()\n",
    "    \n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions = load_parquets(PARQUET_FILES)\n",
    "sessions = cudf.from_pandas(sessions)\n",
    "\n",
    "n_views = sessions[['session', 'ts']].groupby('session').count().reset_index().rename(columns={\"ts\": \"n_views\"})\n",
    "n_clicks = sessions[sessions['type'] == 0][['session', 'ts']].groupby('session').count().reset_index().rename(columns={\"ts\": \"n_clicks\"})\n",
    "n_carts = sessions[sessions['type'] == 1][['session', 'ts']].groupby('session').count().reset_index().rename(columns={\"ts\": \"n_carts\"})\n",
    "n_orders = sessions[sessions['type'] == 2][['session', 'ts']].groupby('session').count().reset_index().rename(columns={\"ts\": \"n_orders\"})\n",
    "\n",
    "# sessions = sessions.merge(n_views, how=\"left\", on=\"session\").fillna(0)\n",
    "sessions_fts = n_views.merge(n_clicks, how=\"left\", on=\"session\").fillna(0)\n",
    "sessions_fts = sessions_fts.merge(n_carts, how=\"left\", on=\"session\").fillna(0)\n",
    "sessions_fts = sessions_fts.merge(n_orders, how=\"left\", on=\"session\").fillna(0)\n",
    "\n",
    "for c in sessions_fts.columns[1:]:\n",
    "    sessions_fts[c] = np.clip(sessions_fts[c], 0, 255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = pairs.merge(sessions_fts, on=\"session\", how=\"left\")\n",
    "pairs = pairs.sort_values(['session', 'candidates'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to ../output/fts_val_v1.parquet\n"
     ]
    }
   ],
   "source": [
    "pairs.to_pandas().to_parquet(\n",
    "    f\"../output/fts_{MODE}_{SUFFIX}.parquet\", index=False\n",
    ")\n",
    "print(f\"Saved to ../output/fts_{MODE}_{SUFFIX}.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
