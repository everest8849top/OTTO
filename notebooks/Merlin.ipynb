{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import json\n",
    "import glob\n",
    "import torch\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import nvtabular as nvt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nvtabular.ops import *\n",
    "from merlin.schema.tags import Tags\n",
    "from merlin_standard_lib import Schema\n",
    "from transformers4rec import torch as tr\n",
    "from transformers4rec.torch.ranking_metric import RecallAt\n",
    "from nvtabular.loader.torch import TorchAsyncItr, DLDataLoader\n",
    "\n",
    "from trainer import Trainer\n",
    "from transformers4rec.config.trainer import T4RecTrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from data.dataset import OttoDataset\n",
    "# from data.preparation import prepare_data\n",
    "# # from training.main import k_fold\n",
    "# from models import OttoTransformer\n",
    "\n",
    "from utils.metrics import *\n",
    "from utils.logger import prepare_log_folder, save_config, create_logger\n",
    "\n",
    "from params import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for path in tqdm(glob.glob(\"../output/train_*.parquet\")):\n",
    "# for path in tqdm(glob.glob(\"../output/val.parquet\")):\n",
    "#     df = pd.read_parquet(path)\n",
    "#     print(df['aid'].apply(len).max())\n",
    "# #     df['target'] = df['type'].apply(lambda x: [CLASSES.index(c) + 1 for c in x])\n",
    "# #     df.to_parquet(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = nvt.Dataset([\"../input/parquets/train_0.parquet\"], engine=\"parquet\")\n",
    "\n",
    "CONTINUOUS_COLUMNS = ['ts']\n",
    "CATEGORICAL_COLUMNS = ['aid']\n",
    "LABEL_COLUMNS = ['target']\n",
    "\n",
    "BATCH_SIZE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TorchAsyncItr(\n",
    "   dataset,\n",
    "   cats=CATEGORICAL_COLUMNS,\n",
    "   conts=CONTINUOUS_COLUMNS,\n",
    "   labels=LABEL_COLUMNS,\n",
    "   batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DLDataLoader(\n",
    "   train_dataset,\n",
    "   batch_size=None,\n",
    "#    collate_fn=collate_fn,\n",
    "   pin_memory=False,\n",
    "   num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch in tqdm(train_loader):\n",
    "#     batch\n",
    "#     break\n",
    "#     continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NVT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tgt = ['target'] >> nvt.ops.AddMetadata(tags=[Tags.CATEGORICAL])\n",
    "# aid = ['aid'] >> nvt.ops.AddMetadata(tags=[Tags.CATEGORICAL])\n",
    "# ts = ['ts'] >> nvt.ops.AddMetadata(tags=[Tags.CONTINUOUS])\n",
    "\n",
    "\n",
    "# # Truncate\n",
    "# aid_truncated = aid >> nvt.ops.ListSlice(0, 20) >> nvt.ops.Rename(postfix = '_trim') >> TagAsItemID()\n",
    "# tgt_truncated = tgt >> nvt.ops.ListSlice(0, 20) >> nvt.ops.Rename(postfix = '_trim')\n",
    "# ts_truncated = ts >> nvt.ops.ListSlice(0, 20) >> nvt.ops.Rename(postfix = '_trim')\n",
    "\n",
    "# # Select\n",
    "# selected_features = (\n",
    "#     aid_truncated +\n",
    "#     tgt_truncated +\n",
    "#     ts_truncated\n",
    "# )\n",
    "\n",
    "# workflow = nvt.Workflow(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = nvt.Dataset(df, cpu=False)\n",
    "# workflow.fit(dataset)\n",
    "# sessions_ds = workflow.transform(dataset)\n",
    "# sessions_gdf = sessions_ds.to_ddf().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = nvt.Dataset(glob.glob(\"../output/train_*.parquet\")[:1], engine=\"parquet\", cpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_dataset = workflow.fit_transform(dataset)\n",
    "\n",
    "# new_dataset.to_parquet(\"../output/worflow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCHEMA_PATH = \"../output/schema.pb\"\n",
    "# SCHEMA_PATH = \"../output/worflow/schema.pbtxt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = Schema().from_proto_text(SCHEMA_PATH)\n",
    "schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tr.TabularSequenceFeatures.from_schema(\n",
    "        schema,\n",
    "        max_sequence_length=500,\n",
    "#         continuous_projection=64,\n",
    "        d_output=100,\n",
    "        masking=\"mlm\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define XLNetConfig class and set default parameters for HF XLNet config  \n",
    "transformer_config = tr.XLNetConfig.build(\n",
    "    d_model=64, n_head=4, n_layer=2, total_seq_length=500\n",
    ")\n",
    "# Define the model block including: inputs, masking, projection and transformer block.\n",
    "body = tr.SequentialBlock(\n",
    "    inputs,\n",
    "    tr.MLPBlock([64]),\n",
    "    tr.TransformerBlock(transformer_config, masking=inputs.masking)\n",
    ")\n",
    "\n",
    "# Defines the evaluation top-N metrics and the cut-offs\n",
    "metrics = [\n",
    "    RecallAt(top_ks=[20], labels_onehot=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a head related to next item prediction task \n",
    "head = tr.Head(\n",
    "    body,\n",
    "    tr.NextItemPredictionTask(weight_tying=True, hf_format=True, metrics=metrics),\n",
    "    inputs=inputs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the end-to-end Model class \n",
    "model = tr.Model(head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_folder = \"/workspace/logs/\"\n",
    "\n",
    "if TRAIN:\n",
    "    log_folder = prepare_log_folder(LOG_PATH)\n",
    "    print(f'Logging results to {log_folder}\\n')\n",
    "    create_logger(log_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyperparameters for training \n",
    "train_args = T4RecTrainingArguments(\n",
    "    data_loader_engine='nvtabular', \n",
    "    dataloader_drop_last=True,\n",
    "    gradient_accumulation_steps=1,\n",
    "    per_device_train_batch_size=128, \n",
    "    per_device_eval_batch_size=128,\n",
    "    output_dir=log_folder, \n",
    "    learning_rate=0.0005,\n",
    "    lr_scheduler_type='cosine', \n",
    "    learning_rate_num_cosine_cycles_by_epoch=1,\n",
    "    num_train_epochs=1,\n",
    "    max_sequence_length=500, \n",
    "    report_to=[],\n",
    "    logging_steps=1000,\n",
    "    save_steps=10000,\n",
    "    no_cuda=False,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=train_args,\n",
    "    schema=schema,\n",
    "    compute_metrics=True,\n",
    ")\n",
    "trainer.reset_lr_scheduler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paths = sorted(glob.glob(\"../input/parquets/train_*.parquet\"))\n",
    "eval_paths = sorted(glob.glob(\"../input/parquets/val.parquet\"))\n",
    "\n",
    "# train_paths = ['../input/parquets/train_0.parquet']\n",
    "# eval_paths = ['../input/parquets/train_0.parquet']\n",
    "\n",
    "trainer.train_dataset_or_path = train_paths\n",
    "trainer.eval_dataset_or_path = eval_paths\n",
    "\n",
    "print(train_paths)\n",
    "print(eval_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN:\n",
    "    trainer.train()\n",
    "    trainer._save_model_and_checkpoint(save_model_class=True)\n",
    "else:\n",
    "#     trainer.load_model_trainer_states_from_checkpoint('/workspace/logs/2022-11-08/6/checkpoint-86707')\n",
    "    trainer.load_model_trainer_states_from_checkpoint('/workspace/logs/2022-11-09/0/checkpoint-15620')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metrics = trainer.evaluate(eval_dataset=eval_paths, metric_key_prefix='eval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in sorted(train_metrics.keys()):\n",
    "    print(\" %s = %s\" % (key, str(train_metrics[key])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
