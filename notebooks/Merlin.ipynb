{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/kaggle/kaggle_otto_rs/src\n"
     ]
    }
   ],
   "source": [
    "cd ../src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import json\n",
    "import glob\n",
    "import torch\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install transformers4rec[pytorch,nvtabular]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nvtabular as nvt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from data.dataset import OttoDataset\n",
    "# from data.preparation import prepare_data\n",
    "# # from training.main import k_fold\n",
    "# from models import OttoTransformer\n",
    "\n",
    "from utils.metrics import *\n",
    "from utils.logger import prepare_log_folder, save_config, create_logger\n",
    "\n",
    "from params import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from nvtabular.loader.torch import TorchAsyncItr, DLDataLoader\n",
    "\n",
    "from transformers4rec import torch as tr\n",
    "from merlin_standard_lib import Schema\n",
    "from transformers4rec.torch.ranking_metric import RecallAt\n",
    "\n",
    "import nvtabular as nvt\n",
    "from nvtabular.ops import *\n",
    "from merlin.schema.tags import Tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for path in tqdm(glob.glob(\"../output/train_*.parquet\")):\n",
    "# for path in tqdm(glob.glob(\"../output/val.parquet\")):\n",
    "#     df = pd.read_parquet(path)\n",
    "#     print(df['aid'].apply(len).max())\n",
    "# #     df['target'] = df['type'].apply(lambda x: [CLASSES.index(c) + 1 for c in x])\n",
    "# #     df.to_parquet(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = nvt.Dataset([\"../output/train_0.parquet\"], engine=\"parquet\")\n",
    "\n",
    "CONTINUOUS_COLUMNS = ['ts']\n",
    "CATEGORICAL_COLUMNS = ['aid']\n",
    "LABEL_COLUMNS = ['target']\n",
    "\n",
    "BATCH_SIZE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TorchAsyncItr(\n",
    "   dataset,\n",
    "   cats=CATEGORICAL_COLUMNS,\n",
    "   conts=CONTINUOUS_COLUMNS,\n",
    "   labels=LABEL_COLUMNS,\n",
    "   batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DLDataLoader(\n",
    "   train_dataset,\n",
    "   batch_size=None,\n",
    "#    collate_fn=collate_fn,\n",
    "   pin_memory=False,\n",
    "   num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch in tqdm(train_loader):\n",
    "#     batch\n",
    "#     break\n",
    "#     continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NVT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tgt = ['target'] >> nvt.ops.AddMetadata(tags=[Tags.CATEGORICAL])\n",
    "# aid = ['aid'] >> nvt.ops.AddMetadata(tags=[Tags.CATEGORICAL])\n",
    "# ts = ['ts'] >> nvt.ops.AddMetadata(tags=[Tags.CONTINUOUS])\n",
    "\n",
    "\n",
    "# # Truncate\n",
    "# aid_truncated = aid >> nvt.ops.ListSlice(0, 20) >> nvt.ops.Rename(postfix = '_trim') >> TagAsItemID()\n",
    "# tgt_truncated = tgt >> nvt.ops.ListSlice(0, 20) >> nvt.ops.Rename(postfix = '_trim')\n",
    "# ts_truncated = ts >> nvt.ops.ListSlice(0, 20) >> nvt.ops.Rename(postfix = '_trim')\n",
    "\n",
    "# # Select\n",
    "# selected_features = (\n",
    "#     aid_truncated +\n",
    "#     tgt_truncated +\n",
    "#     ts_truncated\n",
    "# )\n",
    "\n",
    "# workflow = nvt.Workflow(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = nvt.Dataset(df, cpu=False)\n",
    "# workflow.fit(dataset)\n",
    "# sessions_ds = workflow.transform(dataset)\n",
    "# sessions_gdf = sessions_ds.to_ddf().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = nvt.Dataset(glob.glob(\"../output/train_*.parquet\")[:1], engine=\"parquet\", cpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_dataset = workflow.fit_transform(dataset)\n",
    "\n",
    "# new_dataset.to_parquet(\"../output/worflow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCHEMA_PATH = \"../output/schema.pb\"\n",
    "# SCHEMA_PATH = \"../output/worflow/schema.pbtxt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'aid', 'value_count': {'min': '2', 'max': '512'}, 'type': 'INT', 'int_domain': {'name': 'aid', 'max': '1855610', 'is_categorical': True}, 'annotation': {'tag': ['item_id', 'list', 'categorical', 'item']}}, {'name': 'target', 'value_count': {'min': '2', 'max': '512'}, 'type': 'INT', 'int_domain': {'name': 'target', 'min': '1', 'max': '3', 'is_categorical': True}, 'annotation': {'tag': ['list', 'categorical', 'item']}}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema = Schema().from_proto_text(SCHEMA_PATH)\n",
    "schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tr.TabularSequenceFeatures.from_schema(\n",
    "        schema,\n",
    "        max_sequence_length=500,\n",
    "#         continuous_projection=64,\n",
    "        d_output=100,\n",
    "        masking=\"mlm\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TabularSequenceFeatures(\n",
       "  (to_merge): ModuleDict(\n",
       "    (categorical_module): SequenceEmbeddingFeatures(\n",
       "      (filter_features): FilterFeatures()\n",
       "      (embedding_tables): ModuleDict(\n",
       "        (aid): Embedding(1855611, 64, padding_idx=0)\n",
       "        (target): Embedding(4, 64, padding_idx=0)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (_aggregation): ConcatFeatures()\n",
       "  (projection_module): SequentialBlock(\n",
       "    (0): DenseBlock(\n",
       "      (0): Linear(in_features=128, out_features=100, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (_masking): MaskedLanguageModeling()\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define XLNetConfig class and set default parameters for HF XLNet config  \n",
    "transformer_config = tr.XLNetConfig.build(\n",
    "    d_model=64, n_head=4, n_layer=2, total_seq_length=500\n",
    ")\n",
    "# Define the model block including: inputs, masking, projection and transformer block.\n",
    "body = tr.SequentialBlock(\n",
    "    inputs,\n",
    "    tr.MLPBlock([64]),\n",
    "    tr.TransformerBlock(transformer_config, masking=inputs.masking)\n",
    ")\n",
    "\n",
    "# Defines the evaluation top-N metrics and the cut-offs\n",
    "metrics = [\n",
    "    RecallAt(top_ks=[20], labels_onehot=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a head related to next item prediction task \n",
    "head = tr.Head(\n",
    "    body,\n",
    "    tr.NextItemPredictionTask(weight_tying=True, hf_format=True, metrics=metrics),\n",
    "    inputs=inputs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the end-to-end Model class \n",
    "model = tr.Model(head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainer import Trainer\n",
    "from transformers4rec.config.trainer import T4RecTrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging results to /workspace/logs/2022-11-08/6/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_folder = None\n",
    "if TRAIN:\n",
    "    log_folder = prepare_log_folder(LOG_PATH)\n",
    "    print(f'Logging results to {log_folder}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyperparameters for training \n",
    "train_args = T4RecTrainingArguments(\n",
    "    data_loader_engine='nvtabular', \n",
    "    dataloader_drop_last = True,\n",
    "    gradient_accumulation_steps = 1,\n",
    "    per_device_train_batch_size = 128, \n",
    "    per_device_eval_batch_size = 32,\n",
    "    output_dir = log_folder, \n",
    "    learning_rate=0.0005,\n",
    "    lr_scheduler_type='cosine', \n",
    "    learning_rate_num_cosine_cycles_by_epoch=1,\n",
    "    num_train_epochs=1,\n",
    "    max_sequence_length=500, \n",
    "    report_to = [],\n",
    "    logging_steps=500,\n",
    "    no_cuda=False\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=train_args,\n",
    "    schema=schema,\n",
    "    compute_metrics=True,\n",
    ")\n",
    "trainer.reset_lr_scheduler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../output/train_0.parquet', '../output/train_1.parquet', '../output/train_10.parquet', '../output/train_11.parquet', '../output/train_12.parquet', '../output/train_13.parquet', '../output/train_14.parquet', '../output/train_15.parquet', '../output/train_16.parquet', '../output/train_17.parquet', '../output/train_18.parquet', '../output/train_19.parquet', '../output/train_2.parquet', '../output/train_20.parquet', '../output/train_21.parquet', '../output/train_22.parquet', '../output/train_23.parquet', '../output/train_24.parquet', '../output/train_25.parquet', '../output/train_26.parquet', '../output/train_27.parquet', '../output/train_28.parquet', '../output/train_29.parquet', '../output/train_3.parquet', '../output/train_30.parquet', '../output/train_31.parquet', '../output/train_32.parquet', '../output/train_33.parquet', '../output/train_34.parquet', '../output/train_35.parquet', '../output/train_36.parquet', '../output/train_37.parquet', '../output/train_38.parquet', '../output/train_39.parquet', '../output/train_4.parquet', '../output/train_40.parquet', '../output/train_41.parquet', '../output/train_42.parquet', '../output/train_43.parquet', '../output/train_44.parquet', '../output/train_45.parquet', '../output/train_46.parquet', '../output/train_47.parquet', '../output/train_48.parquet', '../output/train_49.parquet', '../output/train_5.parquet', '../output/train_50.parquet', '../output/train_51.parquet', '../output/train_52.parquet', '../output/train_53.parquet', '../output/train_54.parquet', '../output/train_55.parquet', '../output/train_6.parquet', '../output/train_7.parquet', '../output/train_8.parquet', '../output/train_9.parquet']\n",
      "['../output/val.parquet']\n"
     ]
    }
   ],
   "source": [
    "train_paths = sorted(glob.glob(\"../output/train_*.parquet\"))\n",
    "eval_paths = sorted(glob.glob(\"../output/val.parquet\"))\n",
    "\n",
    "trainer.train_dataset_or_path = train_paths\n",
    "trainer.eval_dataset_or_path = eval_paths\n",
    "\n",
    "print(train_paths)\n",
    "print(eval_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 11098496\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 86707\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15927' max='86707' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15927/86707 1:42:54 < 7:37:21, 2.58 it/s, Epoch 0.18/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>12.999800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>11.467800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>10.829600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>10.481400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>10.282300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>10.042600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>9.847600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>9.391700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>8.953900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>8.640800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>8.375600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>8.171900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>7.969600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>7.844500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>7.669900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>7.652300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>7.544500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>7.405800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>7.254900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>7.041800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>6.975300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>6.896800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>6.976200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>6.925200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>6.833600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>6.798300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>6.785400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>6.721500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>6.640600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>6.540400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>6.536100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /workspace/logs/2022-11-08/6/checkpoint-500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /workspace/logs/2022-11-08/6/checkpoint-1000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /workspace/logs/2022-11-08/6/checkpoint-2000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /workspace/logs/2022-11-08/6/checkpoint-2500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /workspace/logs/2022-11-08/6/checkpoint-3000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /workspace/logs/2022-11-08/6/checkpoint-3500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /workspace/logs/2022-11-08/6/checkpoint-4000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /workspace/logs/2022-11-08/6/checkpoint-4500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /workspace/logs/2022-11-08/6/checkpoint-5000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /workspace/logs/2022-11-08/6/checkpoint-5500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /workspace/logs/2022-11-08/6/checkpoint-6000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /workspace/logs/2022-11-08/6/checkpoint-6500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /workspace/logs/2022-11-08/6/checkpoint-7500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /workspace/logs/2022-11-08/6/checkpoint-8000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /workspace/logs/2022-11-08/6/checkpoint-8500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /workspace/logs/2022-11-08/6/checkpoint-9000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /workspace/logs/2022-11-08/6/checkpoint-9500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /workspace/logs/2022-11-08/6/checkpoint-10000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /workspace/logs/2022-11-08/6/checkpoint-10500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /workspace/logs/2022-11-08/6/checkpoint-11000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /workspace/logs/2022-11-08/6/checkpoint-11500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /workspace/logs/2022-11-08/6/checkpoint-12000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /workspace/logs/2022-11-08/6/checkpoint-12500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /workspace/logs/2022-11-08/6/checkpoint-13000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /workspace/logs/2022-11-08/6/checkpoint-13500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /workspace/logs/2022-11-08/6/checkpoint-14000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /workspace/logs/2022-11-08/6/checkpoint-14500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /workspace/logs/2022-11-08/6/checkpoint-15000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Saving model checkpoint to /workspace/logs/2022-11-08/6/checkpoint-15500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n"
     ]
    }
   ],
   "source": [
    "if TRAIN:\n",
    "    trainer.train()\n",
    "    trainer._save_model_and_checkpoint(save_model_class=True)\n",
    "else:\n",
    "    trainer.load_model_trainer_states_from_checkpoint('/workspace/logs/2022-11-08/3/checkpoint-1562')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metrics = trainer.evaluate(eval_dataset=eval_paths, metric_key_prefix='eval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " eval_/loss = 14.359477043151855\n",
      " eval_/next-item/recall_at_20 = 0.009424999356269836\n",
      " eval_runtime = 868.6284\n",
      " eval_samples_per_second = 230.248\n",
      " eval_steps_per_second = 7.195\n"
     ]
    }
   ],
   "source": [
    "for key in sorted(train_metrics.keys()):\n",
    "    print(\" %s = %s\" % (key, str(train_metrics[key])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
